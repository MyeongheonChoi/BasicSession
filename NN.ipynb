{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPF4Jpd9kJWtI0qU+l8o5J4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MyeongheonChoi/BasicSession/blob/main/NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bDnalOEDzpF",
        "outputId": "775d3ae2-c3c1-4bff-c4df-0f537baf14bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz\n",
        "!pip install graphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCt8_otDekDR",
        "outputId": "9e6e6887-90fd-42bc-bafc-1010a01a62a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.10.0+cu111)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (3.10.0.2)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4150 sha256=c4916a7c751226dd0ad2dc26044c2225663002d89ffa8b9b579e8a3564dcfd7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/38/f5/dc4f85c3909051823df49901e72015d2d750bd26b086480ec2\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (0.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "id": "qtzU3BchD83t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score"
      ],
      "metadata": {
        "id": "1hOIAIPA5PJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_f1(test, pred, avg = None):\n",
        "    confusion = confusion_matrix(test, pred)\n",
        "    accuracy = accuracy_score(test, pred)\n",
        "    precision = precision_score(test, pred, average = avg)\n",
        "    recall = recall_score(test, pred, average = avg)\n",
        "    f1 = f1_score(test, pred, average = avg)\n",
        "    print('Confusion Matrix')\n",
        "    print(confusion)\n",
        "    print(f'Accuracy : {accuracy}, Precision : {precision}, Recall : {recall}, F1 : {f1}')\n",
        "    return precision, recall, f1"
      ],
      "metadata": {
        "id": "84zv9JFM5Q1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, b, c = get_f1([1,1,1,1,2,2,2,0,0,0,0,0], [0,1,2,0,1,2,0,1,2,0,1,2], avg = 'macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fUI59kN-P-e",
        "outputId": "1f39c2b8-9452-4b1a-c10a-2a78345eb72d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[1 2 2]\n",
            " [2 1 1]\n",
            " [1 1 1]]\n",
            "Accuracy : 0.25, Precision : 0.25, Recall : 0.2611111111111111, F1 : 0.2526455026455026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qITjfsSeEBm_",
        "outputId": "83d38d1d-cd61-4f46-fb13-222b9b2b7298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2vaggdata = pd.read_csv(\"/content/drive/Shareddrives/NLP모델링/코드 연습/문서/w2vaggver.csv\")\n",
        "w2vnormdata = pd.read_csv(\"/content/drive/Shareddrives/NLP모델링/코드 연습/문서/w2vnormver.csv\")\n",
        "d2vnormdata = pd.read_csv(\"/content/drive/Shareddrives/NLP모델링/코드 연습/문서/w2vnormver.csv\")\n",
        "w2vaggdata['input'] = [list(map(float, w2vaggdata['input'].iloc[i][1:-1].split(', '))) for i in range(len(w2vaggdata))]\n",
        "w2vnormdata['input'] = [list(map(float, w2vnormdata['input'].iloc[i][1:-1].split(', '))) for i in range(len(w2vnormdata))]\n",
        "d2vnormdata['input'] = [list(map(float, d2vnormdata['input'].iloc[i][1:-1].split(', '))) for i in range(len(d2vnormdata))]\n",
        "w2vaggdata['target'] = [list(map(float, w2vaggdata['target'].iloc[i][1:-1].split(', '))) for i in range(len(w2vaggdata))]\n",
        "w2vnormdata['target'] = [list(map(float, w2vnormdata['target'].iloc[i][1:-1].split(', '))) for i in range(len(w2vnormdata))]\n",
        "d2vnormdata['target'] = [list(map(float, d2vnormdata['target'].iloc[i][1:-1].split(', '))) for i in range(len(d2vnormdata))]"
      ],
      "metadata": {
        "id": "wKMA-jtoEOd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = pd.DataFrame(list(w2vnormdata['target']), columns = ['c1','c2','c3','c4','c5','c6'])\n",
        "criteria = criteria.astype('str')"
      ],
      "metadata": {
        "id": "p4eyQbLAVt1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c11 = LabelBinarizer().fit_transform(criteria['c1'])\n",
        "c12 = LabelBinarizer().fit_transform(criteria['c2'])\n",
        "c13 = LabelBinarizer().fit_transform(criteria['c3'])\n",
        "c14 = LabelBinarizer().fit_transform(criteria['c4'])\n",
        "c15 = LabelBinarizer().fit_transform(criteria['c5'])\n",
        "c16 = LabelBinarizer().fit_transform(criteria['c6'])"
      ],
      "metadata": {
        "id": "ZsvxItzkklFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criteria['c1'] = list(c11)\n",
        "criteria['c2'] = list(c12)\n",
        "criteria['c3'] = list(c13)\n",
        "criteria['c4'] = list(c14)\n",
        "criteria['c5'] = list(c15)\n",
        "criteria['c6'] = list(c16)"
      ],
      "metadata": {
        "id": "KxrPVI8nlWj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GetDataset(Dataset):\n",
        "    def __init__(self, data, criteria, index):\n",
        "        self.x_data = data['input'].values\n",
        "        self.y_data = criteria[index].values\n",
        "  \n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "  \n",
        "    def __getitem__(self,idx):\n",
        "        x = torch.FloatTensor(self.x_data[idx])\n",
        "        y = torch.FloatTensor(self.y_data[idx])\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "FKBzx3ezFHxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class nnn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(nnn, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(100,20),\n",
        "            nn.BatchNorm1d(20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 3),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        o1 = self.layer1(x)\n",
        "\n",
        "        return o1"
      ],
      "metadata": {
        "id": "XQsn8N6KLbGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aa = nnn().to(device)\n",
        "summary(aa, (100,), batch_size = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spKnKht-ha9N",
        "outputId": "566a26c4-cb53-4f5c-9bdf-e2ad7ad0ee52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                   [10, 64]           6,464\n",
            "       BatchNorm1d-2                   [10, 64]             128\n",
            "              ReLU-3                   [10, 64]               0\n",
            "            Linear-4                   [10, 32]           2,080\n",
            "       BatchNorm1d-5                   [10, 32]              64\n",
            "              ReLU-6                   [10, 32]               0\n",
            "            Linear-7                   [10, 16]             528\n",
            "       BatchNorm1d-8                   [10, 16]              32\n",
            "              ReLU-9                   [10, 16]               0\n",
            "           Linear-10                    [10, 8]             136\n",
            "      BatchNorm1d-11                    [10, 8]              16\n",
            "             ReLU-12                    [10, 8]               0\n",
            "           Linear-13                    [10, 3]              27\n",
            "================================================================\n",
            "Total params: 9,475\n",
            "Trainable params: 9,475\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.03\n",
            "Params size (MB): 0.04\n",
            "Estimated Total Size (MB): 0.07\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = Variable(torch.randn(1,100)).to(device)\n",
        "make_dot(aa(x), params=dict(aa.named_parameters()))"
      ],
      "metadata": {
        "id": "3wSquM-ZdXlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_weights(m):\n",
        "    for layer in m.children():\n",
        "        if hasattr(layer, 'reset_parameters'):\n",
        "            print(f'Reset trainable parameters of layer = {layer}')\n",
        "            layer.reset_parameters()"
      ],
      "metadata": {
        "id": "ro5jUvogMm2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    k_folds = 5\n",
        "    num_epochs = 50\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # w2v_train1 = GetDataset(w2vaggdata);w2v_test1 = GetDataset(w2vaggdata)\n",
        "    # w2v_train2 = GetDataset(w2vnormdata);w2v_test2 = GetDataset(w2vnormdata)\n",
        "    # d2v_train1 = GetDataset(d2vnormdata);d2v_test1 = GetDataset(d2vnormdata)\n",
        "    # w2v_dataset1 = ConcatDataset([w2v_train1, w2v_test1])\n",
        "    # w2v_dataset2 = ConcatDataset([w2v_train2, w2v_test2])\n",
        "    # d2v_dataset1 = ConcatDataset([d2v_train1, d2v_test1])\n",
        "\n",
        "    train = GetDataset(w2v, criteria, 'c1');test = GetDataset(w2v, criteria, 'c1')\n",
        "    dataset = ConcatDataset([train, test])     \n",
        "\n",
        "    kfold = KFold(n_splits = k_folds, shuffle = True)\n",
        "\n",
        "    for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
        "        print(f'FOLD {fold+1}')\n",
        "        print('-' * 30)\n",
        "\n",
        "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "\n",
        "        trainloader = DataLoader(dataset, batch_size = 10, sampler = train_subsampler)\n",
        "        testloader = DataLoader(dataset, batch_size = 10, sampler = test_subsampler)\n",
        "\n",
        "        model = nnn().to(device)\n",
        "        model.apply(reset_weights)\n",
        "    \n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "        for epoch in range(0, num_epochs):\n",
        "\n",
        "            print(f'Starting epoch {epoch + 1}')\n",
        "\n",
        "            current_loss = 0.0\n",
        "            n = 0\n",
        "            for i, data in enumerate(trainloader, 0):\n",
        "                inputs, targets = data\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs.to(device))\n",
        "                loss = loss_function(outputs, targets.to(device))\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                current_loss += loss.item()\n",
        "                n += 1\n",
        "                \n",
        "            print('Loss after epoch %5d: %.3f'%(epoch, current_loss / n))\n",
        "        \n",
        "        print('Training process has finished. Saving trained model.')\n",
        "\n",
        "        print('Start Testing')\n",
        "        save_path = f'/content/drive/Shareddrives/NLP모델링/코드 연습/문서/model-fold-{fold}.pth'\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(testloader, 0):\n",
        "                inputs, targets = data\n",
        "                outputs = model(inputs.to(device))\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                _, target = torch.max(targets.data, 1)\n",
        "                total += targets.size(0)\n",
        "                correct += (predicted == target.to(device)).sum().item()\n",
        "\n",
        "            print('Accuracy for fold %d : %d %%' % (fold, 100.0 * correct/total))\n",
        "            print('-'*30)\n",
        "            results[fold] = 100.0 * (correct / total)\n",
        "        \n",
        "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
        "    print('-'*30)\n",
        "    sum = 0.0\n",
        "    for key, value in results.items():\n",
        "        print(f'Fold {key}: {value} %')\n",
        "        sum += value\n",
        "    print(f'Average : {sum/len(results.items())} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtYHwhSAG1sO",
        "outputId": "1a6f6289-e2a3-4d88-e2a3-2132319bf305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 1\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Starting epoch 1\n",
            "Loss after epoch     0: 1.005\n",
            "Starting epoch 2\n",
            "Loss after epoch     1: 0.896\n",
            "Starting epoch 3\n",
            "Loss after epoch     2: 0.851\n",
            "Starting epoch 4\n",
            "Loss after epoch     3: 0.793\n",
            "Starting epoch 5\n",
            "Loss after epoch     4: 0.746\n",
            "Starting epoch 6\n",
            "Loss after epoch     5: 0.744\n",
            "Starting epoch 7\n",
            "Loss after epoch     6: 0.705\n",
            "Starting epoch 8\n",
            "Loss after epoch     7: 0.705\n",
            "Starting epoch 9\n",
            "Loss after epoch     8: 0.663\n",
            "Starting epoch 10\n",
            "Loss after epoch     9: 0.665\n",
            "Starting epoch 11\n",
            "Loss after epoch    10: 0.651\n",
            "Starting epoch 12\n",
            "Loss after epoch    11: 0.655\n",
            "Starting epoch 13\n",
            "Loss after epoch    12: 0.646\n",
            "Starting epoch 14\n",
            "Loss after epoch    13: 0.677\n",
            "Starting epoch 15\n",
            "Loss after epoch    14: 0.663\n",
            "Starting epoch 16\n",
            "Loss after epoch    15: 0.630\n",
            "Starting epoch 17\n",
            "Loss after epoch    16: 0.588\n",
            "Starting epoch 18\n",
            "Loss after epoch    17: 0.592\n",
            "Starting epoch 19\n",
            "Loss after epoch    18: 0.602\n",
            "Starting epoch 20\n",
            "Loss after epoch    19: 0.559\n",
            "Starting epoch 21\n",
            "Loss after epoch    20: 0.614\n",
            "Starting epoch 22\n",
            "Loss after epoch    21: 0.573\n",
            "Starting epoch 23\n",
            "Loss after epoch    22: 0.587\n",
            "Starting epoch 24\n",
            "Loss after epoch    23: 0.519\n",
            "Starting epoch 25\n",
            "Loss after epoch    24: 0.564\n",
            "Starting epoch 26\n",
            "Loss after epoch    25: 0.540\n",
            "Starting epoch 27\n",
            "Loss after epoch    26: 0.538\n",
            "Starting epoch 28\n",
            "Loss after epoch    27: 0.526\n",
            "Starting epoch 29\n",
            "Loss after epoch    28: 0.535\n",
            "Starting epoch 30\n",
            "Loss after epoch    29: 0.535\n",
            "Starting epoch 31\n",
            "Loss after epoch    30: 0.444\n",
            "Starting epoch 32\n",
            "Loss after epoch    31: 0.522\n",
            "Starting epoch 33\n",
            "Loss after epoch    32: 0.532\n",
            "Starting epoch 34\n",
            "Loss after epoch    33: 0.498\n",
            "Starting epoch 35\n",
            "Loss after epoch    34: 0.488\n",
            "Starting epoch 36\n",
            "Loss after epoch    35: 0.489\n",
            "Starting epoch 37\n",
            "Loss after epoch    36: 0.492\n",
            "Starting epoch 38\n",
            "Loss after epoch    37: 0.498\n",
            "Starting epoch 39\n",
            "Loss after epoch    38: 0.472\n",
            "Starting epoch 40\n",
            "Loss after epoch    39: 0.459\n",
            "Starting epoch 41\n",
            "Loss after epoch    40: 0.484\n",
            "Starting epoch 42\n",
            "Loss after epoch    41: 0.494\n",
            "Starting epoch 43\n",
            "Loss after epoch    42: 0.448\n",
            "Starting epoch 44\n",
            "Loss after epoch    43: 0.429\n",
            "Starting epoch 45\n",
            "Loss after epoch    44: 0.456\n",
            "Starting epoch 46\n",
            "Loss after epoch    45: 0.392\n",
            "Starting epoch 47\n",
            "Loss after epoch    46: 0.446\n",
            "Starting epoch 48\n",
            "Loss after epoch    47: 0.514\n",
            "Starting epoch 49\n",
            "Loss after epoch    48: 0.435\n",
            "Starting epoch 50\n",
            "Loss after epoch    49: 0.415\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "tensor([2, 1, 1, 1, 1, 1, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([2, 2, 0, 1, 1, 1, 2, 2, 2, 2])\n",
            "tensor([1, 2, 2, 2, 2, 1, 2, 1, 1, 2], device='cuda:0')\n",
            "tensor([1, 1, 2, 2, 2, 1, 2, 1, 1, 2])\n",
            "tensor([1, 2, 1, 2, 2, 2, 1, 2, 1, 2], device='cuda:0')\n",
            "tensor([1, 2, 1, 1, 2, 2, 1, 2, 2, 1])\n",
            "tensor([2, 2, 2, 1, 1, 1, 2, 0, 1, 2], device='cuda:0')\n",
            "tensor([2, 2, 2, 0, 1, 2, 2, 0, 1, 2])\n",
            "tensor([2, 1, 2, 1, 2, 2, 2, 2, 0, 2], device='cuda:0')\n",
            "tensor([1, 2, 2, 1, 1, 1, 2, 1, 0, 1])\n",
            "tensor([1, 1, 2, 2, 0, 2, 1, 1, 2, 2], device='cuda:0')\n",
            "tensor([1, 1, 2, 2, 2, 2, 0, 2, 2, 1])\n",
            "tensor([2, 2, 2, 1, 2, 1, 1, 2, 1, 2], device='cuda:0')\n",
            "tensor([2, 2, 2, 0, 1, 1, 1, 2, 1, 2])\n",
            "tensor([1, 1, 2, 2, 2, 1, 1, 2, 1, 2], device='cuda:0')\n",
            "tensor([1, 1, 2, 2, 1, 1, 1, 2, 1, 2])\n",
            "tensor([1, 2, 2, 1, 2, 2, 2, 1, 1, 2], device='cuda:0')\n",
            "tensor([1, 2, 2, 0, 2, 2, 2, 1, 1, 2])\n",
            "tensor([1, 2, 2, 2, 2, 2, 2, 2, 0, 2], device='cuda:0')\n",
            "tensor([1, 2, 1, 2, 2, 2, 2, 1, 1, 2])\n",
            "tensor([2, 2, 2, 2, 2, 1, 2, 2, 1, 1], device='cuda:0')\n",
            "tensor([1, 1, 2, 1, 2, 1, 2, 2, 1, 1])\n",
            "tensor([1, 1, 2, 2, 1, 2, 2, 2, 1, 2], device='cuda:0')\n",
            "tensor([1, 0, 2, 2, 2, 2, 2, 2, 1, 2])\n",
            "tensor([2, 2, 0, 1, 2, 2, 2, 1, 2, 1], device='cuda:0')\n",
            "tensor([2, 1, 0, 1, 2, 2, 2, 1, 1, 1])\n",
            "tensor([2, 2, 2, 1, 2, 2, 1, 1, 1, 2], device='cuda:0')\n",
            "tensor([2, 1, 2, 1, 2, 2, 1, 1, 1, 2])\n",
            "tensor([2, 1, 1, 1, 1, 2, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([2, 1, 1, 1, 1, 2, 1, 2, 1, 2])\n",
            "tensor([2, 2, 2, 2, 1], device='cuda:0')\n",
            "tensor([2, 1, 2, 1, 1])\n",
            "Accuracy for fold 0 : 76 %\n",
            "------------------------------\n",
            "FOLD 2\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Starting epoch 1\n",
            "Loss after epoch     0: 1.027\n",
            "Starting epoch 2\n",
            "Loss after epoch     1: 0.903\n",
            "Starting epoch 3\n",
            "Loss after epoch     2: 0.822\n",
            "Starting epoch 4\n",
            "Loss after epoch     3: 0.814\n",
            "Starting epoch 5\n",
            "Loss after epoch     4: 0.777\n",
            "Starting epoch 6\n",
            "Loss after epoch     5: 0.754\n",
            "Starting epoch 7\n",
            "Loss after epoch     6: 0.737\n",
            "Starting epoch 8\n",
            "Loss after epoch     7: 0.714\n",
            "Starting epoch 9\n",
            "Loss after epoch     8: 0.696\n",
            "Starting epoch 10\n",
            "Loss after epoch     9: 0.701\n",
            "Starting epoch 11\n",
            "Loss after epoch    10: 0.629\n",
            "Starting epoch 12\n",
            "Loss after epoch    11: 0.668\n",
            "Starting epoch 13\n",
            "Loss after epoch    12: 0.647\n",
            "Starting epoch 14\n",
            "Loss after epoch    13: 0.658\n",
            "Starting epoch 15\n",
            "Loss after epoch    14: 0.631\n",
            "Starting epoch 16\n",
            "Loss after epoch    15: 0.680\n",
            "Starting epoch 17\n",
            "Loss after epoch    16: 0.643\n",
            "Starting epoch 18\n",
            "Loss after epoch    17: 0.629\n",
            "Starting epoch 19\n",
            "Loss after epoch    18: 0.593\n",
            "Starting epoch 20\n",
            "Loss after epoch    19: 0.604\n",
            "Starting epoch 21\n",
            "Loss after epoch    20: 0.580\n",
            "Starting epoch 22\n",
            "Loss after epoch    21: 0.599\n",
            "Starting epoch 23\n",
            "Loss after epoch    22: 0.572\n",
            "Starting epoch 24\n",
            "Loss after epoch    23: 0.577\n",
            "Starting epoch 25\n",
            "Loss after epoch    24: 0.550\n",
            "Starting epoch 26\n",
            "Loss after epoch    25: 0.618\n",
            "Starting epoch 27\n",
            "Loss after epoch    26: 0.554\n",
            "Starting epoch 28\n",
            "Loss after epoch    27: 0.565\n",
            "Starting epoch 29\n",
            "Loss after epoch    28: 0.538\n",
            "Starting epoch 30\n",
            "Loss after epoch    29: 0.560\n",
            "Starting epoch 31\n",
            "Loss after epoch    30: 0.599\n",
            "Starting epoch 32\n",
            "Loss after epoch    31: 0.515\n",
            "Starting epoch 33\n",
            "Loss after epoch    32: 0.546\n",
            "Starting epoch 34\n",
            "Loss after epoch    33: 0.483\n",
            "Starting epoch 35\n",
            "Loss after epoch    34: 0.479\n",
            "Starting epoch 36\n",
            "Loss after epoch    35: 0.489\n",
            "Starting epoch 37\n",
            "Loss after epoch    36: 0.492\n",
            "Starting epoch 38\n",
            "Loss after epoch    37: 0.498\n",
            "Starting epoch 39\n",
            "Loss after epoch    38: 0.526\n",
            "Starting epoch 40\n",
            "Loss after epoch    39: 0.492\n",
            "Starting epoch 41\n",
            "Loss after epoch    40: 0.470\n",
            "Starting epoch 42\n",
            "Loss after epoch    41: 0.471\n",
            "Starting epoch 43\n",
            "Loss after epoch    42: 0.433\n",
            "Starting epoch 44\n",
            "Loss after epoch    43: 0.469\n",
            "Starting epoch 45\n",
            "Loss after epoch    44: 0.487\n",
            "Starting epoch 46\n",
            "Loss after epoch    45: 0.429\n",
            "Starting epoch 47\n",
            "Loss after epoch    46: 0.401\n",
            "Starting epoch 48\n",
            "Loss after epoch    47: 0.390\n",
            "Starting epoch 49\n",
            "Loss after epoch    48: 0.439\n",
            "Starting epoch 50\n",
            "Loss after epoch    49: 0.418\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "tensor([1, 2, 2, 1, 2, 2, 0, 1, 2, 2], device='cuda:0')\n",
            "tensor([1, 2, 2, 1, 2, 2, 0, 2, 2, 2])\n",
            "tensor([2, 1, 2, 0, 2, 1, 1, 2, 1, 2], device='cuda:0')\n",
            "tensor([1, 1, 2, 0, 2, 1, 2, 2, 2, 1])\n",
            "tensor([2, 2, 1, 1, 2, 1, 2, 2, 2, 1], device='cuda:0')\n",
            "tensor([2, 2, 1, 1, 2, 2, 2, 2, 1, 1])\n",
            "tensor([2, 1, 1, 1, 1, 2, 2, 1, 2, 2], device='cuda:0')\n",
            "tensor([2, 2, 1, 2, 1, 2, 2, 1, 2, 0])\n",
            "tensor([2, 2, 2, 2, 1, 1, 2, 1, 1, 2], device='cuda:0')\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2])\n",
            "tensor([1, 2, 2, 1, 1, 1, 2, 1, 2, 2], device='cuda:0')\n",
            "tensor([1, 2, 2, 1, 1, 1, 2, 0, 2, 2])\n",
            "tensor([2, 2, 2, 1, 2, 2, 1, 2, 1, 0], device='cuda:0')\n",
            "tensor([2, 2, 2, 1, 2, 2, 1, 2, 1, 0])\n",
            "tensor([2, 2, 2, 2, 1, 2, 1, 1, 1, 2], device='cuda:0')\n",
            "tensor([2, 2, 2, 2, 2, 2, 1, 2, 1, 2])\n",
            "tensor([1, 2, 2, 2, 2, 1, 1, 2, 1, 1], device='cuda:0')\n",
            "tensor([1, 2, 2, 1, 2, 1, 0, 2, 1, 1])\n",
            "tensor([1, 2, 2, 2, 2, 1, 2, 2, 1, 1], device='cuda:0')\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1])\n",
            "tensor([2, 1, 1, 2, 2, 2, 1, 2, 1, 1], device='cuda:0')\n",
            "tensor([2, 1, 1, 2, 2, 0, 1, 2, 1, 1])\n",
            "tensor([1, 2, 2, 2, 1, 1, 2, 1, 2, 2], device='cuda:0')\n",
            "tensor([1, 2, 2, 2, 2, 1, 1, 1, 2, 1])\n",
            "tensor([1, 2, 1, 2, 2, 2, 1, 2, 1, 1], device='cuda:0')\n",
            "tensor([0, 1, 1, 2, 1, 2, 1, 2, 1, 0])\n",
            "tensor([2, 1, 2, 2, 2, 2, 2, 2, 1, 1], device='cuda:0')\n",
            "tensor([1, 0, 2, 2, 2, 1, 2, 2, 0, 2])\n",
            "tensor([1, 2, 2, 2, 1, 1, 1, 2, 1, 2], device='cuda:0')\n",
            "tensor([1, 2, 1, 2, 1, 1, 2, 2, 1, 2])\n",
            "tensor([1, 2, 1, 2, 2], device='cuda:0')\n",
            "tensor([1, 2, 2, 2, 2])\n",
            "Accuracy for fold 1 : 76 %\n",
            "------------------------------\n",
            "FOLD 3\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Starting epoch 1\n",
            "Loss after epoch     0: 1.044\n",
            "Starting epoch 2\n",
            "Loss after epoch     1: 0.928\n",
            "Starting epoch 3\n",
            "Loss after epoch     2: 0.864\n",
            "Starting epoch 4\n",
            "Loss after epoch     3: 0.834\n",
            "Starting epoch 5\n",
            "Loss after epoch     4: 0.784\n",
            "Starting epoch 6\n",
            "Loss after epoch     5: 0.763\n",
            "Starting epoch 7\n",
            "Loss after epoch     6: 0.721\n",
            "Starting epoch 8\n",
            "Loss after epoch     7: 0.725\n",
            "Starting epoch 9\n",
            "Loss after epoch     8: 0.691\n",
            "Starting epoch 10\n",
            "Loss after epoch     9: 0.698\n",
            "Starting epoch 11\n",
            "Loss after epoch    10: 0.666\n",
            "Starting epoch 12\n",
            "Loss after epoch    11: 0.634\n",
            "Starting epoch 13\n",
            "Loss after epoch    12: 0.647\n",
            "Starting epoch 14\n",
            "Loss after epoch    13: 0.641\n",
            "Starting epoch 15\n",
            "Loss after epoch    14: 0.610\n",
            "Starting epoch 16\n",
            "Loss after epoch    15: 0.602\n",
            "Starting epoch 17\n",
            "Loss after epoch    16: 0.605\n",
            "Starting epoch 18\n",
            "Loss after epoch    17: 0.624\n",
            "Starting epoch 19\n",
            "Loss after epoch    18: 0.641\n",
            "Starting epoch 20\n",
            "Loss after epoch    19: 0.614\n",
            "Starting epoch 21\n",
            "Loss after epoch    20: 0.626\n",
            "Starting epoch 22\n",
            "Loss after epoch    21: 0.559\n",
            "Starting epoch 23\n",
            "Loss after epoch    22: 0.610\n",
            "Starting epoch 24\n",
            "Loss after epoch    23: 0.571\n",
            "Starting epoch 25\n",
            "Loss after epoch    24: 0.543\n",
            "Starting epoch 26\n",
            "Loss after epoch    25: 0.619\n",
            "Starting epoch 27\n",
            "Loss after epoch    26: 0.507\n",
            "Starting epoch 28\n",
            "Loss after epoch    27: 0.515\n",
            "Starting epoch 29\n",
            "Loss after epoch    28: 0.560\n",
            "Starting epoch 30\n",
            "Loss after epoch    29: 0.521\n",
            "Starting epoch 31\n",
            "Loss after epoch    30: 0.491\n",
            "Starting epoch 32\n",
            "Loss after epoch    31: 0.523\n",
            "Starting epoch 33\n",
            "Loss after epoch    32: 0.506\n",
            "Starting epoch 34\n",
            "Loss after epoch    33: 0.505\n",
            "Starting epoch 35\n",
            "Loss after epoch    34: 0.480\n",
            "Starting epoch 36\n",
            "Loss after epoch    35: 0.494\n",
            "Starting epoch 37\n",
            "Loss after epoch    36: 0.491\n",
            "Starting epoch 38\n",
            "Loss after epoch    37: 0.486\n",
            "Starting epoch 39\n",
            "Loss after epoch    38: 0.547\n",
            "Starting epoch 40\n",
            "Loss after epoch    39: 0.491\n",
            "Starting epoch 41\n",
            "Loss after epoch    40: 0.464\n",
            "Starting epoch 42\n",
            "Loss after epoch    41: 0.465\n",
            "Starting epoch 43\n",
            "Loss after epoch    42: 0.411\n",
            "Starting epoch 44\n",
            "Loss after epoch    43: 0.408\n",
            "Starting epoch 45\n",
            "Loss after epoch    44: 0.432\n",
            "Starting epoch 46\n",
            "Loss after epoch    45: 0.471\n",
            "Starting epoch 47\n",
            "Loss after epoch    46: 0.393\n",
            "Starting epoch 48\n",
            "Loss after epoch    47: 0.460\n",
            "Starting epoch 49\n",
            "Loss after epoch    48: 0.438\n",
            "Starting epoch 50\n",
            "Loss after epoch    49: 0.401\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "tensor([2, 2, 2, 2, 2, 2, 1, 1, 1, 1], device='cuda:0')\n",
            "tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "tensor([2, 0, 2, 2, 2, 1, 1, 2, 2, 1], device='cuda:0')\n",
            "tensor([2, 1, 2, 2, 1, 1, 1, 2, 2, 1])\n",
            "tensor([2, 1, 0, 2, 2, 2, 1, 1, 2, 1], device='cuda:0')\n",
            "tensor([2, 1, 1, 2, 2, 2, 0, 2, 2, 1])\n",
            "tensor([2, 2, 1, 2, 1, 2, 0, 2, 1, 2], device='cuda:0')\n",
            "tensor([2, 2, 1, 2, 1, 2, 2, 2, 1, 2])\n",
            "tensor([2, 2, 1, 2, 1, 1, 0, 0, 2, 2], device='cuda:0')\n",
            "tensor([2, 2, 1, 2, 1, 1, 1, 1, 2, 2])\n",
            "tensor([1, 1, 2, 2, 2, 2, 1, 2, 2, 1], device='cuda:0')\n",
            "tensor([1, 1, 2, 2, 2, 1, 1, 2, 2, 1])\n",
            "tensor([2, 2, 2, 2, 2, 2, 1, 2, 1, 2], device='cuda:0')\n",
            "tensor([0, 2, 2, 2, 2, 2, 1, 2, 1, 2])\n",
            "tensor([2, 2, 2, 1, 2, 2, 1, 0, 2, 1], device='cuda:0')\n",
            "tensor([2, 2, 2, 1, 2, 2, 0, 0, 2, 1])\n",
            "tensor([1, 2, 2, 2, 2, 1, 1, 0, 2, 2], device='cuda:0')\n",
            "tensor([2, 2, 1, 1, 2, 1, 1, 2, 0, 1])\n",
            "tensor([1, 2, 1, 2, 0, 2, 2, 1, 1, 2], device='cuda:0')\n",
            "tensor([1, 2, 2, 2, 2, 2, 2, 1, 1, 2])\n",
            "tensor([2, 1, 2, 2, 1, 1, 1, 2, 1, 2], device='cuda:0')\n",
            "tensor([2, 1, 2, 2, 1, 1, 1, 2, 2, 1])\n",
            "tensor([1, 1, 1, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([1, 1, 2, 2, 2, 2, 1, 2, 2, 2])\n",
            "tensor([2, 2, 2, 2, 2, 0, 1, 1, 2, 1], device='cuda:0')\n",
            "tensor([2, 1, 2, 2, 1, 2, 1, 2, 1, 2])\n",
            "tensor([2, 2, 2, 1, 2, 2, 2, 0, 2, 0], device='cuda:0')\n",
            "tensor([2, 2, 1, 2, 1, 2, 2, 1, 2, 2])\n",
            "tensor([1, 1, 1, 1, 2, 2, 0, 2, 2, 1], device='cuda:0')\n",
            "tensor([2, 1, 1, 1, 2, 2, 1, 2, 2, 2])\n",
            "tensor([2, 2, 1, 2], device='cuda:0')\n",
            "tensor([2, 2, 2, 2])\n",
            "Accuracy for fold 2 : 73 %\n",
            "------------------------------\n",
            "FOLD 4\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Starting epoch 1\n",
            "Loss after epoch     0: 1.040\n",
            "Starting epoch 2\n",
            "Loss after epoch     1: 0.929\n",
            "Starting epoch 3\n",
            "Loss after epoch     2: 0.874\n",
            "Starting epoch 4\n",
            "Loss after epoch     3: 0.802\n",
            "Starting epoch 5\n",
            "Loss after epoch     4: 0.778\n",
            "Starting epoch 6\n",
            "Loss after epoch     5: 0.741\n",
            "Starting epoch 7\n",
            "Loss after epoch     6: 0.730\n",
            "Starting epoch 8\n",
            "Loss after epoch     7: 0.712\n",
            "Starting epoch 9\n",
            "Loss after epoch     8: 0.689\n",
            "Starting epoch 10\n",
            "Loss after epoch     9: 0.720\n",
            "Starting epoch 11\n",
            "Loss after epoch    10: 0.658\n",
            "Starting epoch 12\n",
            "Loss after epoch    11: 0.665\n",
            "Starting epoch 13\n",
            "Loss after epoch    12: 0.657\n",
            "Starting epoch 14\n",
            "Loss after epoch    13: 0.644\n",
            "Starting epoch 15\n",
            "Loss after epoch    14: 0.677\n",
            "Starting epoch 16\n",
            "Loss after epoch    15: 0.643\n",
            "Starting epoch 17\n",
            "Loss after epoch    16: 0.602\n",
            "Starting epoch 18\n",
            "Loss after epoch    17: 0.635\n",
            "Starting epoch 19\n",
            "Loss after epoch    18: 0.591\n",
            "Starting epoch 20\n",
            "Loss after epoch    19: 0.612\n",
            "Starting epoch 21\n",
            "Loss after epoch    20: 0.603\n",
            "Starting epoch 22\n",
            "Loss after epoch    21: 0.582\n",
            "Starting epoch 23\n",
            "Loss after epoch    22: 0.594\n",
            "Starting epoch 24\n",
            "Loss after epoch    23: 0.579\n",
            "Starting epoch 25\n",
            "Loss after epoch    24: 0.567\n",
            "Starting epoch 26\n",
            "Loss after epoch    25: 0.545\n",
            "Starting epoch 27\n",
            "Loss after epoch    26: 0.531\n",
            "Starting epoch 28\n",
            "Loss after epoch    27: 0.537\n",
            "Starting epoch 29\n",
            "Loss after epoch    28: 0.554\n",
            "Starting epoch 30\n",
            "Loss after epoch    29: 0.493\n",
            "Starting epoch 31\n",
            "Loss after epoch    30: 0.498\n",
            "Starting epoch 32\n",
            "Loss after epoch    31: 0.522\n",
            "Starting epoch 33\n",
            "Loss after epoch    32: 0.496\n",
            "Starting epoch 34\n",
            "Loss after epoch    33: 0.473\n",
            "Starting epoch 35\n",
            "Loss after epoch    34: 0.512\n",
            "Starting epoch 36\n",
            "Loss after epoch    35: 0.481\n",
            "Starting epoch 37\n",
            "Loss after epoch    36: 0.480\n",
            "Starting epoch 38\n",
            "Loss after epoch    37: 0.505\n",
            "Starting epoch 39\n",
            "Loss after epoch    38: 0.467\n",
            "Starting epoch 40\n",
            "Loss after epoch    39: 0.450\n",
            "Starting epoch 41\n",
            "Loss after epoch    40: 0.517\n",
            "Starting epoch 42\n",
            "Loss after epoch    41: 0.435\n",
            "Starting epoch 43\n",
            "Loss after epoch    42: 0.428\n",
            "Starting epoch 44\n",
            "Loss after epoch    43: 0.426\n",
            "Starting epoch 45\n",
            "Loss after epoch    44: 0.466\n",
            "Starting epoch 46\n",
            "Loss after epoch    45: 0.389\n",
            "Starting epoch 47\n",
            "Loss after epoch    46: 0.424\n",
            "Starting epoch 48\n",
            "Loss after epoch    47: 0.426\n",
            "Starting epoch 49\n",
            "Loss after epoch    48: 0.447\n",
            "Starting epoch 50\n",
            "Loss after epoch    49: 0.424\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "tensor([2, 0, 2, 1, 1, 2, 2, 2, 0, 1], device='cuda:0')\n",
            "tensor([2, 1, 2, 1, 1, 2, 2, 1, 0, 1])\n",
            "tensor([2, 0, 2, 2, 2, 1, 1, 2, 2, 1], device='cuda:0')\n",
            "tensor([2, 0, 2, 2, 2, 1, 2, 2, 2, 1])\n",
            "tensor([2, 2, 2, 1, 1, 2, 1, 2, 1, 2], device='cuda:0')\n",
            "tensor([2, 2, 2, 2, 2, 2, 0, 1, 1, 2])\n",
            "tensor([2, 2, 1, 2, 1, 1, 2, 2, 1, 1], device='cuda:0')\n",
            "tensor([2, 2, 2, 2, 2, 1, 0, 2, 2, 1])\n",
            "tensor([1, 2, 2, 1, 1, 2, 2, 2, 2, 1], device='cuda:0')\n",
            "tensor([1, 2, 2, 2, 1, 2, 2, 2, 1, 1])\n",
            "tensor([1, 2, 1, 2, 2, 2, 2, 2, 2, 1], device='cuda:0')\n",
            "tensor([2, 0, 2, 2, 2, 2, 2, 1, 2, 1])\n",
            "tensor([2, 0, 2, 1, 2, 1, 2, 1, 2, 1], device='cuda:0')\n",
            "tensor([2, 2, 1, 1, 2, 0, 2, 1, 2, 2])\n",
            "tensor([1, 1, 2, 1, 2, 2, 2, 0, 2, 2], device='cuda:0')\n",
            "tensor([1, 2, 2, 1, 1, 2, 1, 2, 1, 2])\n",
            "tensor([2, 2, 2, 1, 2, 1, 2, 2, 1, 0], device='cuda:0')\n",
            "tensor([2, 2, 2, 2, 1, 2, 2, 2, 1, 0])\n",
            "tensor([2, 2, 1, 1, 1, 2, 1, 2, 0, 2], device='cuda:0')\n",
            "tensor([2, 2, 1, 1, 1, 2, 1, 2, 1, 2])\n",
            "tensor([2, 2, 1, 2, 1, 2, 1, 2, 2, 1], device='cuda:0')\n",
            "tensor([2, 2, 1, 1, 0, 2, 2, 2, 2, 1])\n",
            "tensor([1, 1, 2, 2, 1, 2, 1, 0, 2, 2], device='cuda:0')\n",
            "tensor([1, 1, 2, 2, 1, 2, 1, 1, 2, 0])\n",
            "tensor([1, 1, 2, 2, 2, 1, 2, 2, 2, 0], device='cuda:0')\n",
            "tensor([1, 2, 2, 2, 2, 2, 2, 2, 2, 0])\n",
            "tensor([2, 2, 1, 2, 2, 2, 2, 1, 2, 1], device='cuda:0')\n",
            "tensor([2, 2, 1, 2, 2, 2, 0, 1, 1, 1])\n",
            "tensor([2, 2, 2, 0, 0, 2, 2, 2, 1, 1], device='cuda:0')\n",
            "tensor([2, 1, 2, 1, 1, 2, 0, 2, 1, 1])\n",
            "tensor([2, 2, 1, 1], device='cuda:0')\n",
            "tensor([2, 2, 1, 1])\n",
            "Accuracy for fold 3 : 72 %\n",
            "------------------------------\n",
            "FOLD 5\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Starting epoch 1\n",
            "Loss after epoch     0: 1.079\n",
            "Starting epoch 2\n",
            "Loss after epoch     1: 0.957\n",
            "Starting epoch 3\n",
            "Loss after epoch     2: 0.871\n",
            "Starting epoch 4\n",
            "Loss after epoch     3: 0.805\n",
            "Starting epoch 5\n",
            "Loss after epoch     4: 0.761\n",
            "Starting epoch 6\n",
            "Loss after epoch     5: 0.744\n",
            "Starting epoch 7\n",
            "Loss after epoch     6: 0.742\n",
            "Starting epoch 8\n",
            "Loss after epoch     7: 0.701\n",
            "Starting epoch 9\n",
            "Loss after epoch     8: 0.699\n",
            "Starting epoch 10\n",
            "Loss after epoch     9: 0.686\n",
            "Starting epoch 11\n",
            "Loss after epoch    10: 0.680\n",
            "Starting epoch 12\n",
            "Loss after epoch    11: 0.676\n",
            "Starting epoch 13\n",
            "Loss after epoch    12: 0.640\n",
            "Starting epoch 14\n",
            "Loss after epoch    13: 0.577\n",
            "Starting epoch 15\n",
            "Loss after epoch    14: 0.624\n",
            "Starting epoch 16\n",
            "Loss after epoch    15: 0.595\n",
            "Starting epoch 17\n",
            "Loss after epoch    16: 0.623\n",
            "Starting epoch 18\n",
            "Loss after epoch    17: 0.592\n",
            "Starting epoch 19\n",
            "Loss after epoch    18: 0.582\n",
            "Starting epoch 20\n",
            "Loss after epoch    19: 0.590\n",
            "Starting epoch 21\n",
            "Loss after epoch    20: 0.613\n",
            "Starting epoch 22\n",
            "Loss after epoch    21: 0.605\n",
            "Starting epoch 23\n",
            "Loss after epoch    22: 0.606\n",
            "Starting epoch 24\n",
            "Loss after epoch    23: 0.590\n",
            "Starting epoch 25\n",
            "Loss after epoch    24: 0.572\n",
            "Starting epoch 26\n",
            "Loss after epoch    25: 0.576\n",
            "Starting epoch 27\n",
            "Loss after epoch    26: 0.558\n",
            "Starting epoch 28\n",
            "Loss after epoch    27: 0.552\n",
            "Starting epoch 29\n",
            "Loss after epoch    28: 0.550\n",
            "Starting epoch 30\n",
            "Loss after epoch    29: 0.572\n",
            "Starting epoch 31\n",
            "Loss after epoch    30: 0.490\n",
            "Starting epoch 32\n",
            "Loss after epoch    31: 0.546\n",
            "Starting epoch 33\n",
            "Loss after epoch    32: 0.491\n",
            "Starting epoch 34\n",
            "Loss after epoch    33: 0.523\n",
            "Starting epoch 35\n",
            "Loss after epoch    34: 0.506\n",
            "Starting epoch 36\n",
            "Loss after epoch    35: 0.458\n",
            "Starting epoch 37\n",
            "Loss after epoch    36: 0.503\n",
            "Starting epoch 38\n",
            "Loss after epoch    37: 0.526\n",
            "Starting epoch 39\n",
            "Loss after epoch    38: 0.464\n",
            "Starting epoch 40\n",
            "Loss after epoch    39: 0.536\n",
            "Starting epoch 41\n",
            "Loss after epoch    40: 0.435\n",
            "Starting epoch 42\n",
            "Loss after epoch    41: 0.516\n",
            "Starting epoch 43\n",
            "Loss after epoch    42: 0.485\n",
            "Starting epoch 44\n",
            "Loss after epoch    43: 0.466\n",
            "Starting epoch 45\n",
            "Loss after epoch    44: 0.483\n",
            "Starting epoch 46\n",
            "Loss after epoch    45: 0.478\n",
            "Starting epoch 47\n",
            "Loss after epoch    46: 0.390\n",
            "Starting epoch 48\n",
            "Loss after epoch    47: 0.435\n",
            "Starting epoch 49\n",
            "Loss after epoch    48: 0.415\n",
            "Starting epoch 50\n",
            "Loss after epoch    49: 0.450\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "tensor([1, 2, 2, 2, 2, 1, 2, 1, 1, 2], device='cuda:0')\n",
            "tensor([2, 2, 2, 2, 2, 1, 2, 2, 2, 2])\n",
            "tensor([2, 1, 1, 1, 1, 1, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([2, 2, 2, 1, 1, 2, 1, 1, 2, 2])\n",
            "tensor([1, 1, 2, 1, 2, 2, 2, 2, 2, 1], device='cuda:0')\n",
            "tensor([2, 1, 1, 2, 2, 0, 2, 1, 2, 2])\n",
            "tensor([2, 2, 1, 1, 2, 2, 2, 2, 1, 2], device='cuda:0')\n",
            "tensor([2, 2, 1, 1, 2, 2, 2, 2, 2, 2])\n",
            "tensor([2, 2, 2, 2, 2, 1, 2, 2, 2, 1], device='cuda:0')\n",
            "tensor([2, 2, 2, 2, 2, 1, 2, 2, 0, 0])\n",
            "tensor([1, 2, 2, 1, 2, 2, 1, 2, 2, 1], device='cuda:0')\n",
            "tensor([1, 2, 2, 1, 2, 2, 1, 2, 1, 1])\n",
            "tensor([1, 1, 2, 2, 1, 1, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([2, 2, 2, 2, 1, 2, 2, 2, 1, 2])\n",
            "tensor([1, 2, 1, 2, 2, 2, 1, 2, 2, 1], device='cuda:0')\n",
            "tensor([1, 2, 1, 1, 2, 1, 2, 2, 2, 1])\n",
            "tensor([2, 2, 2, 1, 2, 2, 1, 2, 1, 1], device='cuda:0')\n",
            "tensor([1, 1, 2, 1, 2, 2, 1, 2, 1, 1])\n",
            "tensor([2, 2, 1, 2, 1, 1, 1, 2, 2, 2], device='cuda:0')\n",
            "tensor([2, 2, 1, 2, 2, 2, 0, 2, 2, 2])\n",
            "tensor([2, 1, 2, 2, 2, 2, 1, 2, 1, 2], device='cuda:0')\n",
            "tensor([2, 2, 2, 2, 2, 2, 1, 2, 1, 2])\n",
            "tensor([2, 2, 1, 1, 1, 1, 1, 2, 2, 2], device='cuda:0')\n",
            "tensor([2, 2, 1, 1, 1, 2, 2, 2, 2, 2])\n",
            "tensor([2, 1, 1, 2, 2, 2, 2, 2, 1, 2], device='cuda:0')\n",
            "tensor([1, 1, 0, 1, 2, 0, 1, 2, 0, 2])\n",
            "tensor([2, 1, 2, 2, 2, 1, 2, 2, 1, 2], device='cuda:0')\n",
            "tensor([2, 0, 2, 2, 2, 1, 2, 2, 1, 2])\n",
            "tensor([1, 1, 2, 2, 1, 1, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([2, 1, 2, 2, 1, 2, 2, 2, 1, 2])\n",
            "tensor([1, 2, 2, 2], device='cuda:0')\n",
            "tensor([1, 1, 1, 0])\n",
            "Accuracy for fold 4 : 70 %\n",
            "------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "------------------------------\n",
            "Fold 0: 76.12903225806451 %\n",
            "Fold 1: 76.12903225806451 %\n",
            "Fold 2: 73.37662337662337 %\n",
            "Fold 3: 72.07792207792207 %\n",
            "Fold 4: 70.12987012987013 %\n",
            "Average : 73.56849602010892 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    k_folds = 5\n",
        "    num_epochs = 50\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # w2v_train1 = GetDataset(w2vaggdata);w2v_test1 = GetDataset(w2vaggdata)\n",
        "    # w2v_train2 = GetDataset(w2vnormdata);w2v_test2 = GetDataset(w2vnormdata)\n",
        "    # d2v_train1 = GetDataset(d2vnormdata);d2v_test1 = GetDataset(d2vnormdata)\n",
        "    # w2v_dataset1 = ConcatDataset([w2v_train1, w2v_test1])\n",
        "    # w2v_dataset2 = ConcatDataset([w2v_train2, w2v_test2])\n",
        "    # d2v_dataset1 = ConcatDataset([d2v_train1, d2v_test1])\n",
        "    for c in [1,2,3,4,5,6]:\n",
        "        train = GetDataset(w2v, criteria, 'c'+str(c));test = GetDataset(w2v, criteria, 'c'+str(c))\n",
        "        dataset = ConcatDataset([train, test])     \n",
        "\n",
        "        kfold = KFold(n_splits = k_folds, shuffle = True)\n",
        "\n",
        "        for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
        "            print(f'FOLD {fold+1} for Criteria{c}')\n",
        "            print('-' * 30)\n",
        "\n",
        "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "            test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "\n",
        "            trainloader = DataLoader(dataset, batch_size = 10, sampler = train_subsampler)\n",
        "            testloader = DataLoader(dataset, batch_size = 10, sampler = test_subsampler)\n",
        "\n",
        "            model = nnn().to(device)\n",
        "            model.apply(reset_weights)\n",
        "        \n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "            for epoch in range(0, num_epochs):\n",
        "\n",
        "                current_loss = 0.0\n",
        "                n = 0\n",
        "                for i, data in enumerate(trainloader, 0):\n",
        "                    inputs, targets = data\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs.to(device))\n",
        "                    loss = loss_function(outputs, targets.to(device))\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    current_loss += loss.item()\n",
        "                    n += 1\n",
        "                    \n",
        "                print('Loss after epoch %5d: %.3f'%(epoch, current_loss / n))\n",
        "            \n",
        "            print('Training process has finished. Saving trained model.')\n",
        "\n",
        "            print('Start Testing')\n",
        "            save_path = f'/content/drive/Shareddrives/NLP모델링/코드 연습/문서/model-fold-{fold}-c{c}.pth'\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "            correct, total = 0, 0\n",
        "            with torch.no_grad():\n",
        "                for i, data in enumerate(testloader, 0):\n",
        "                    inputs, targets = data\n",
        "                    outputs = model(inputs.to(device))\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    _, target = torch.max(targets.data, 1)\n",
        "                    total += targets.size(0)\n",
        "                    correct += (predicted == target.to(device)).sum().item()\n",
        "\n",
        "                print('Accuracy for fold %d criteria%d: %d %%' % (fold, c, 100.0 * correct/total))\n",
        "                print('-'*30)\n",
        "                results[fold] = 100.0 * (correct / total)\n",
        "            \n",
        "        print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS for CRITERIA{c}')\n",
        "        print('-'*30)\n",
        "        sum = 0.0\n",
        "        for key, value in results.items():\n",
        "            print(f'Fold {key} for Criteria{c}: {value} %')\n",
        "            sum += value\n",
        "        print(f'Average : {sum/len(results.items())} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lhbfWPZIe9W",
        "outputId": "78dc0d5e-44af-4be6-f7c3-b1ab28d74b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 1 for Criteria1\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.457\n",
            "Loss after epoch     1: 1.197\n",
            "Loss after epoch     2: 1.050\n",
            "Loss after epoch     3: 0.940\n",
            "Loss after epoch     4: 0.840\n",
            "Loss after epoch     5: 0.785\n",
            "Loss after epoch     6: 0.756\n",
            "Loss after epoch     7: 0.722\n",
            "Loss after epoch     8: 0.693\n",
            "Loss after epoch     9: 0.696\n",
            "Loss after epoch    10: 0.665\n",
            "Loss after epoch    11: 0.657\n",
            "Loss after epoch    12: 0.658\n",
            "Loss after epoch    13: 0.629\n",
            "Loss after epoch    14: 0.629\n",
            "Loss after epoch    15: 0.643\n",
            "Loss after epoch    16: 0.599\n",
            "Loss after epoch    17: 0.634\n",
            "Loss after epoch    18: 0.606\n",
            "Loss after epoch    19: 0.620\n",
            "Loss after epoch    20: 0.599\n",
            "Loss after epoch    21: 0.593\n",
            "Loss after epoch    22: 0.552\n",
            "Loss after epoch    23: 0.552\n",
            "Loss after epoch    24: 0.560\n",
            "Loss after epoch    25: 0.544\n",
            "Loss after epoch    26: 0.561\n",
            "Loss after epoch    27: 0.555\n",
            "Loss after epoch    28: 0.553\n",
            "Loss after epoch    29: 0.540\n",
            "Loss after epoch    30: 0.567\n",
            "Loss after epoch    31: 0.519\n",
            "Loss after epoch    32: 0.537\n",
            "Loss after epoch    33: 0.492\n",
            "Loss after epoch    34: 0.533\n",
            "Loss after epoch    35: 0.519\n",
            "Loss after epoch    36: 0.509\n",
            "Loss after epoch    37: 0.480\n",
            "Loss after epoch    38: 0.516\n",
            "Loss after epoch    39: 0.497\n",
            "Loss after epoch    40: 0.531\n",
            "Loss after epoch    41: 0.528\n",
            "Loss after epoch    42: 0.503\n",
            "Loss after epoch    43: 0.486\n",
            "Loss after epoch    44: 0.478\n",
            "Loss after epoch    45: 0.468\n",
            "Loss after epoch    46: 0.493\n",
            "Loss after epoch    47: 0.433\n",
            "Loss after epoch    48: 0.434\n",
            "Loss after epoch    49: 0.439\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 0 criteria1: 72 %\n",
            "------------------------------\n",
            "FOLD 2 for Criteria1\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.020\n",
            "Loss after epoch     1: 0.908\n",
            "Loss after epoch     2: 0.851\n",
            "Loss after epoch     3: 0.799\n",
            "Loss after epoch     4: 0.751\n",
            "Loss after epoch     5: 0.737\n",
            "Loss after epoch     6: 0.742\n",
            "Loss after epoch     7: 0.709\n",
            "Loss after epoch     8: 0.696\n",
            "Loss after epoch     9: 0.655\n",
            "Loss after epoch    10: 0.657\n",
            "Loss after epoch    11: 0.624\n",
            "Loss after epoch    12: 0.646\n",
            "Loss after epoch    13: 0.649\n",
            "Loss after epoch    14: 0.620\n",
            "Loss after epoch    15: 0.606\n",
            "Loss after epoch    16: 0.615\n",
            "Loss after epoch    17: 0.542\n",
            "Loss after epoch    18: 0.585\n",
            "Loss after epoch    19: 0.601\n",
            "Loss after epoch    20: 0.623\n",
            "Loss after epoch    21: 0.563\n",
            "Loss after epoch    22: 0.568\n",
            "Loss after epoch    23: 0.535\n",
            "Loss after epoch    24: 0.542\n",
            "Loss after epoch    25: 0.543\n",
            "Loss after epoch    26: 0.526\n",
            "Loss after epoch    27: 0.529\n",
            "Loss after epoch    28: 0.531\n",
            "Loss after epoch    29: 0.477\n",
            "Loss after epoch    30: 0.561\n",
            "Loss after epoch    31: 0.536\n",
            "Loss after epoch    32: 0.546\n",
            "Loss after epoch    33: 0.498\n",
            "Loss after epoch    34: 0.495\n",
            "Loss after epoch    35: 0.459\n",
            "Loss after epoch    36: 0.500\n",
            "Loss after epoch    37: 0.510\n",
            "Loss after epoch    38: 0.444\n",
            "Loss after epoch    39: 0.435\n",
            "Loss after epoch    40: 0.465\n",
            "Loss after epoch    41: 0.434\n",
            "Loss after epoch    42: 0.398\n",
            "Loss after epoch    43: 0.417\n",
            "Loss after epoch    44: 0.385\n",
            "Loss after epoch    45: 0.444\n",
            "Loss after epoch    46: 0.453\n",
            "Loss after epoch    47: 0.382\n",
            "Loss after epoch    48: 0.472\n",
            "Loss after epoch    49: 0.442\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 1 criteria1: 78 %\n",
            "------------------------------\n",
            "FOLD 3 for Criteria1\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.056\n",
            "Loss after epoch     1: 0.932\n",
            "Loss after epoch     2: 0.863\n",
            "Loss after epoch     3: 0.829\n",
            "Loss after epoch     4: 0.778\n",
            "Loss after epoch     5: 0.763\n",
            "Loss after epoch     6: 0.735\n",
            "Loss after epoch     7: 0.720\n",
            "Loss after epoch     8: 0.727\n",
            "Loss after epoch     9: 0.695\n",
            "Loss after epoch    10: 0.710\n",
            "Loss after epoch    11: 0.698\n",
            "Loss after epoch    12: 0.700\n",
            "Loss after epoch    13: 0.677\n",
            "Loss after epoch    14: 0.626\n",
            "Loss after epoch    15: 0.675\n",
            "Loss after epoch    16: 0.653\n",
            "Loss after epoch    17: 0.623\n",
            "Loss after epoch    18: 0.633\n",
            "Loss after epoch    19: 0.593\n",
            "Loss after epoch    20: 0.579\n",
            "Loss after epoch    21: 0.595\n",
            "Loss after epoch    22: 0.563\n",
            "Loss after epoch    23: 0.579\n",
            "Loss after epoch    24: 0.510\n",
            "Loss after epoch    25: 0.566\n",
            "Loss after epoch    26: 0.572\n",
            "Loss after epoch    27: 0.524\n",
            "Loss after epoch    28: 0.548\n",
            "Loss after epoch    29: 0.517\n",
            "Loss after epoch    30: 0.534\n",
            "Loss after epoch    31: 0.494\n",
            "Loss after epoch    32: 0.528\n",
            "Loss after epoch    33: 0.504\n",
            "Loss after epoch    34: 0.468\n",
            "Loss after epoch    35: 0.499\n",
            "Loss after epoch    36: 0.458\n",
            "Loss after epoch    37: 0.467\n",
            "Loss after epoch    38: 0.443\n",
            "Loss after epoch    39: 0.430\n",
            "Loss after epoch    40: 0.396\n",
            "Loss after epoch    41: 0.478\n",
            "Loss after epoch    42: 0.460\n",
            "Loss after epoch    43: 0.490\n",
            "Loss after epoch    44: 0.477\n",
            "Loss after epoch    45: 0.413\n",
            "Loss after epoch    46: 0.444\n",
            "Loss after epoch    47: 0.472\n",
            "Loss after epoch    48: 0.395\n",
            "Loss after epoch    49: 0.404\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 2 criteria1: 75 %\n",
            "------------------------------\n",
            "FOLD 4 for Criteria1\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.050\n",
            "Loss after epoch     1: 0.910\n",
            "Loss after epoch     2: 0.839\n",
            "Loss after epoch     3: 0.785\n",
            "Loss after epoch     4: 0.735\n",
            "Loss after epoch     5: 0.754\n",
            "Loss after epoch     6: 0.693\n",
            "Loss after epoch     7: 0.660\n",
            "Loss after epoch     8: 0.650\n",
            "Loss after epoch     9: 0.637\n",
            "Loss after epoch    10: 0.642\n",
            "Loss after epoch    11: 0.642\n",
            "Loss after epoch    12: 0.633\n",
            "Loss after epoch    13: 0.628\n",
            "Loss after epoch    14: 0.578\n",
            "Loss after epoch    15: 0.618\n",
            "Loss after epoch    16: 0.612\n",
            "Loss after epoch    17: 0.596\n",
            "Loss after epoch    18: 0.585\n",
            "Loss after epoch    19: 0.596\n",
            "Loss after epoch    20: 0.573\n",
            "Loss after epoch    21: 0.571\n",
            "Loss after epoch    22: 0.541\n",
            "Loss after epoch    23: 0.550\n",
            "Loss after epoch    24: 0.573\n",
            "Loss after epoch    25: 0.569\n",
            "Loss after epoch    26: 0.573\n",
            "Loss after epoch    27: 0.555\n",
            "Loss after epoch    28: 0.546\n",
            "Loss after epoch    29: 0.504\n",
            "Loss after epoch    30: 0.540\n",
            "Loss after epoch    31: 0.524\n",
            "Loss after epoch    32: 0.524\n",
            "Loss after epoch    33: 0.524\n",
            "Loss after epoch    34: 0.471\n",
            "Loss after epoch    35: 0.469\n",
            "Loss after epoch    36: 0.526\n",
            "Loss after epoch    37: 0.505\n",
            "Loss after epoch    38: 0.509\n",
            "Loss after epoch    39: 0.502\n",
            "Loss after epoch    40: 0.527\n",
            "Loss after epoch    41: 0.524\n",
            "Loss after epoch    42: 0.530\n",
            "Loss after epoch    43: 0.487\n",
            "Loss after epoch    44: 0.472\n",
            "Loss after epoch    45: 0.488\n",
            "Loss after epoch    46: 0.469\n",
            "Loss after epoch    47: 0.443\n",
            "Loss after epoch    48: 0.413\n",
            "Loss after epoch    49: 0.411\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 3 criteria1: 74 %\n",
            "------------------------------\n",
            "FOLD 5 for Criteria1\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.079\n",
            "Loss after epoch     1: 0.958\n",
            "Loss after epoch     2: 0.881\n",
            "Loss after epoch     3: 0.830\n",
            "Loss after epoch     4: 0.774\n",
            "Loss after epoch     5: 0.758\n",
            "Loss after epoch     6: 0.727\n",
            "Loss after epoch     7: 0.707\n",
            "Loss after epoch     8: 0.693\n",
            "Loss after epoch     9: 0.662\n",
            "Loss after epoch    10: 0.648\n",
            "Loss after epoch    11: 0.641\n",
            "Loss after epoch    12: 0.628\n",
            "Loss after epoch    13: 0.601\n",
            "Loss after epoch    14: 0.560\n",
            "Loss after epoch    15: 0.645\n",
            "Loss after epoch    16: 0.620\n",
            "Loss after epoch    17: 0.587\n",
            "Loss after epoch    18: 0.578\n",
            "Loss after epoch    19: 0.576\n",
            "Loss after epoch    20: 0.566\n",
            "Loss after epoch    21: 0.550\n",
            "Loss after epoch    22: 0.531\n",
            "Loss after epoch    23: 0.495\n",
            "Loss after epoch    24: 0.527\n",
            "Loss after epoch    25: 0.528\n",
            "Loss after epoch    26: 0.563\n",
            "Loss after epoch    27: 0.543\n",
            "Loss after epoch    28: 0.514\n",
            "Loss after epoch    29: 0.460\n",
            "Loss after epoch    30: 0.481\n",
            "Loss after epoch    31: 0.459\n",
            "Loss after epoch    32: 0.440\n",
            "Loss after epoch    33: 0.442\n",
            "Loss after epoch    34: 0.411\n",
            "Loss after epoch    35: 0.451\n",
            "Loss after epoch    36: 0.407\n",
            "Loss after epoch    37: 0.432\n",
            "Loss after epoch    38: 0.417\n",
            "Loss after epoch    39: 0.484\n",
            "Loss after epoch    40: 0.426\n",
            "Loss after epoch    41: 0.434\n",
            "Loss after epoch    42: 0.415\n",
            "Loss after epoch    43: 0.433\n",
            "Loss after epoch    44: 0.375\n",
            "Loss after epoch    45: 0.348\n",
            "Loss after epoch    46: 0.398\n",
            "Loss after epoch    47: 0.435\n",
            "Loss after epoch    48: 0.375\n",
            "Loss after epoch    49: 0.420\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 4 criteria1: 66 %\n",
            "------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS for CRITERIA1\n",
            "------------------------------\n",
            "Fold 0 for Criteria1: 72.25806451612902 %\n",
            "Fold 1 for Criteria1: 78.06451612903226 %\n",
            "Fold 2 for Criteria1: 75.97402597402598 %\n",
            "Fold 3 for Criteria1: 74.67532467532467 %\n",
            "Fold 4 for Criteria1: 66.23376623376623 %\n",
            "Average : 73.44113950565563 %\n",
            "FOLD 1 for Criteria2\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.076\n",
            "Loss after epoch     1: 0.996\n",
            "Loss after epoch     2: 0.941\n",
            "Loss after epoch     3: 0.910\n",
            "Loss after epoch     4: 0.872\n",
            "Loss after epoch     5: 0.859\n",
            "Loss after epoch     6: 0.848\n",
            "Loss after epoch     7: 0.828\n",
            "Loss after epoch     8: 0.793\n",
            "Loss after epoch     9: 0.791\n",
            "Loss after epoch    10: 0.774\n",
            "Loss after epoch    11: 0.779\n",
            "Loss after epoch    12: 0.775\n",
            "Loss after epoch    13: 0.753\n",
            "Loss after epoch    14: 0.726\n",
            "Loss after epoch    15: 0.741\n",
            "Loss after epoch    16: 0.716\n",
            "Loss after epoch    17: 0.684\n",
            "Loss after epoch    18: 0.709\n",
            "Loss after epoch    19: 0.704\n",
            "Loss after epoch    20: 0.693\n",
            "Loss after epoch    21: 0.664\n",
            "Loss after epoch    22: 0.629\n",
            "Loss after epoch    23: 0.668\n",
            "Loss after epoch    24: 0.654\n",
            "Loss after epoch    25: 0.649\n",
            "Loss after epoch    26: 0.645\n",
            "Loss after epoch    27: 0.594\n",
            "Loss after epoch    28: 0.605\n",
            "Loss after epoch    29: 0.611\n",
            "Loss after epoch    30: 0.595\n",
            "Loss after epoch    31: 0.599\n",
            "Loss after epoch    32: 0.555\n",
            "Loss after epoch    33: 0.574\n",
            "Loss after epoch    34: 0.594\n",
            "Loss after epoch    35: 0.549\n",
            "Loss after epoch    36: 0.529\n",
            "Loss after epoch    37: 0.551\n",
            "Loss after epoch    38: 0.539\n",
            "Loss after epoch    39: 0.535\n",
            "Loss after epoch    40: 0.495\n",
            "Loss after epoch    41: 0.545\n",
            "Loss after epoch    42: 0.536\n",
            "Loss after epoch    43: 0.535\n",
            "Loss after epoch    44: 0.484\n",
            "Loss after epoch    45: 0.477\n",
            "Loss after epoch    46: 0.505\n",
            "Loss after epoch    47: 0.431\n",
            "Loss after epoch    48: 0.451\n",
            "Loss after epoch    49: 0.471\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 0 criteria2: 74 %\n",
            "------------------------------\n",
            "FOLD 2 for Criteria2\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.042\n",
            "Loss after epoch     1: 0.946\n",
            "Loss after epoch     2: 0.913\n",
            "Loss after epoch     3: 0.880\n",
            "Loss after epoch     4: 0.866\n",
            "Loss after epoch     5: 0.827\n",
            "Loss after epoch     6: 0.821\n",
            "Loss after epoch     7: 0.812\n",
            "Loss after epoch     8: 0.781\n",
            "Loss after epoch     9: 0.760\n",
            "Loss after epoch    10: 0.761\n",
            "Loss after epoch    11: 0.765\n",
            "Loss after epoch    12: 0.762\n",
            "Loss after epoch    13: 0.725\n",
            "Loss after epoch    14: 0.780\n",
            "Loss after epoch    15: 0.706\n",
            "Loss after epoch    16: 0.683\n",
            "Loss after epoch    17: 0.700\n",
            "Loss after epoch    18: 0.685\n",
            "Loss after epoch    19: 0.679\n",
            "Loss after epoch    20: 0.661\n",
            "Loss after epoch    21: 0.639\n",
            "Loss after epoch    22: 0.654\n",
            "Loss after epoch    23: 0.587\n",
            "Loss after epoch    24: 0.610\n",
            "Loss after epoch    25: 0.608\n",
            "Loss after epoch    26: 0.613\n",
            "Loss after epoch    27: 0.635\n",
            "Loss after epoch    28: 0.614\n",
            "Loss after epoch    29: 0.625\n",
            "Loss after epoch    30: 0.610\n",
            "Loss after epoch    31: 0.627\n",
            "Loss after epoch    32: 0.627\n",
            "Loss after epoch    33: 0.524\n",
            "Loss after epoch    34: 0.536\n",
            "Loss after epoch    35: 0.530\n",
            "Loss after epoch    36: 0.559\n",
            "Loss after epoch    37: 0.564\n",
            "Loss after epoch    38: 0.583\n",
            "Loss after epoch    39: 0.557\n",
            "Loss after epoch    40: 0.536\n",
            "Loss after epoch    41: 0.511\n",
            "Loss after epoch    42: 0.535\n",
            "Loss after epoch    43: 0.520\n",
            "Loss after epoch    44: 0.544\n",
            "Loss after epoch    45: 0.451\n",
            "Loss after epoch    46: 0.471\n",
            "Loss after epoch    47: 0.497\n",
            "Loss after epoch    48: 0.453\n",
            "Loss after epoch    49: 0.455\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 1 criteria2: 66 %\n",
            "------------------------------\n",
            "FOLD 3 for Criteria2\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.026\n",
            "Loss after epoch     1: 0.956\n",
            "Loss after epoch     2: 0.913\n",
            "Loss after epoch     3: 0.884\n",
            "Loss after epoch     4: 0.893\n",
            "Loss after epoch     5: 0.844\n",
            "Loss after epoch     6: 0.813\n",
            "Loss after epoch     7: 0.816\n",
            "Loss after epoch     8: 0.811\n",
            "Loss after epoch     9: 0.799\n",
            "Loss after epoch    10: 0.814\n",
            "Loss after epoch    11: 0.770\n",
            "Loss after epoch    12: 0.768\n",
            "Loss after epoch    13: 0.769\n",
            "Loss after epoch    14: 0.753\n",
            "Loss after epoch    15: 0.738\n",
            "Loss after epoch    16: 0.720\n",
            "Loss after epoch    17: 0.726\n",
            "Loss after epoch    18: 0.718\n",
            "Loss after epoch    19: 0.687\n",
            "Loss after epoch    20: 0.721\n",
            "Loss after epoch    21: 0.703\n",
            "Loss after epoch    22: 0.685\n",
            "Loss after epoch    23: 0.675\n",
            "Loss after epoch    24: 0.659\n",
            "Loss after epoch    25: 0.699\n",
            "Loss after epoch    26: 0.632\n",
            "Loss after epoch    27: 0.671\n",
            "Loss after epoch    28: 0.679\n",
            "Loss after epoch    29: 0.669\n",
            "Loss after epoch    30: 0.612\n",
            "Loss after epoch    31: 0.631\n",
            "Loss after epoch    32: 0.565\n",
            "Loss after epoch    33: 0.643\n",
            "Loss after epoch    34: 0.600\n",
            "Loss after epoch    35: 0.626\n",
            "Loss after epoch    36: 0.610\n",
            "Loss after epoch    37: 0.571\n",
            "Loss after epoch    38: 0.601\n",
            "Loss after epoch    39: 0.541\n",
            "Loss after epoch    40: 0.567\n",
            "Loss after epoch    41: 0.522\n",
            "Loss after epoch    42: 0.560\n",
            "Loss after epoch    43: 0.510\n",
            "Loss after epoch    44: 0.516\n",
            "Loss after epoch    45: 0.530\n",
            "Loss after epoch    46: 0.503\n",
            "Loss after epoch    47: 0.484\n",
            "Loss after epoch    48: 0.550\n",
            "Loss after epoch    49: 0.551\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 2 criteria2: 68 %\n",
            "------------------------------\n",
            "FOLD 4 for Criteria2\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.046\n",
            "Loss after epoch     1: 0.917\n",
            "Loss after epoch     2: 0.886\n",
            "Loss after epoch     3: 0.872\n",
            "Loss after epoch     4: 0.854\n",
            "Loss after epoch     5: 0.817\n",
            "Loss after epoch     6: 0.817\n",
            "Loss after epoch     7: 0.822\n",
            "Loss after epoch     8: 0.818\n",
            "Loss after epoch     9: 0.779\n",
            "Loss after epoch    10: 0.767\n",
            "Loss after epoch    11: 0.767\n",
            "Loss after epoch    12: 0.760\n",
            "Loss after epoch    13: 0.741\n",
            "Loss after epoch    14: 0.748\n",
            "Loss after epoch    15: 0.706\n",
            "Loss after epoch    16: 0.682\n",
            "Loss after epoch    17: 0.709\n",
            "Loss after epoch    18: 0.705\n",
            "Loss after epoch    19: 0.698\n",
            "Loss after epoch    20: 0.671\n",
            "Loss after epoch    21: 0.688\n",
            "Loss after epoch    22: 0.656\n",
            "Loss after epoch    23: 0.674\n",
            "Loss after epoch    24: 0.699\n",
            "Loss after epoch    25: 0.630\n",
            "Loss after epoch    26: 0.704\n",
            "Loss after epoch    27: 0.724\n",
            "Loss after epoch    28: 0.640\n",
            "Loss after epoch    29: 0.639\n",
            "Loss after epoch    30: 0.597\n",
            "Loss after epoch    31: 0.560\n",
            "Loss after epoch    32: 0.584\n",
            "Loss after epoch    33: 0.587\n",
            "Loss after epoch    34: 0.599\n",
            "Loss after epoch    35: 0.576\n",
            "Loss after epoch    36: 0.541\n",
            "Loss after epoch    37: 0.555\n",
            "Loss after epoch    38: 0.520\n",
            "Loss after epoch    39: 0.527\n",
            "Loss after epoch    40: 0.530\n",
            "Loss after epoch    41: 0.531\n",
            "Loss after epoch    42: 0.565\n",
            "Loss after epoch    43: 0.552\n",
            "Loss after epoch    44: 0.540\n",
            "Loss after epoch    45: 0.490\n",
            "Loss after epoch    46: 0.524\n",
            "Loss after epoch    47: 0.576\n",
            "Loss after epoch    48: 0.568\n",
            "Loss after epoch    49: 0.446\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 3 criteria2: 72 %\n",
            "------------------------------\n",
            "FOLD 5 for Criteria2\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.029\n",
            "Loss after epoch     1: 0.938\n",
            "Loss after epoch     2: 0.917\n",
            "Loss after epoch     3: 0.897\n",
            "Loss after epoch     4: 0.844\n",
            "Loss after epoch     5: 0.865\n",
            "Loss after epoch     6: 0.828\n",
            "Loss after epoch     7: 0.807\n",
            "Loss after epoch     8: 0.778\n",
            "Loss after epoch     9: 0.778\n",
            "Loss after epoch    10: 0.767\n",
            "Loss after epoch    11: 0.759\n",
            "Loss after epoch    12: 0.711\n",
            "Loss after epoch    13: 0.737\n",
            "Loss after epoch    14: 0.790\n",
            "Loss after epoch    15: 0.729\n",
            "Loss after epoch    16: 0.713\n",
            "Loss after epoch    17: 0.707\n",
            "Loss after epoch    18: 0.739\n",
            "Loss after epoch    19: 0.683\n",
            "Loss after epoch    20: 0.650\n",
            "Loss after epoch    21: 0.686\n",
            "Loss after epoch    22: 0.683\n",
            "Loss after epoch    23: 0.712\n",
            "Loss after epoch    24: 0.708\n",
            "Loss after epoch    25: 0.614\n",
            "Loss after epoch    26: 0.615\n",
            "Loss after epoch    27: 0.605\n",
            "Loss after epoch    28: 0.612\n",
            "Loss after epoch    29: 0.626\n",
            "Loss after epoch    30: 0.617\n",
            "Loss after epoch    31: 0.649\n",
            "Loss after epoch    32: 0.621\n",
            "Loss after epoch    33: 0.604\n",
            "Loss after epoch    34: 0.587\n",
            "Loss after epoch    35: 0.568\n",
            "Loss after epoch    36: 0.540\n",
            "Loss after epoch    37: 0.583\n",
            "Loss after epoch    38: 0.576\n",
            "Loss after epoch    39: 0.540\n",
            "Loss after epoch    40: 0.561\n",
            "Loss after epoch    41: 0.523\n",
            "Loss after epoch    42: 0.529\n",
            "Loss after epoch    43: 0.527\n",
            "Loss after epoch    44: 0.504\n",
            "Loss after epoch    45: 0.477\n",
            "Loss after epoch    46: 0.470\n",
            "Loss after epoch    47: 0.470\n",
            "Loss after epoch    48: 0.483\n",
            "Loss after epoch    49: 0.502\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 4 criteria2: 69 %\n",
            "------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS for CRITERIA2\n",
            "------------------------------\n",
            "Fold 0 for Criteria2: 74.83870967741936 %\n",
            "Fold 1 for Criteria2: 66.45161290322581 %\n",
            "Fold 2 for Criteria2: 68.83116883116884 %\n",
            "Fold 3 for Criteria2: 72.72727272727273 %\n",
            "Fold 4 for Criteria2: 69.48051948051948 %\n",
            "Average : 70.46585672392125 %\n",
            "FOLD 1 for Criteria3\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.131\n",
            "Loss after epoch     1: 1.037\n",
            "Loss after epoch     2: 0.995\n",
            "Loss after epoch     3: 0.948\n",
            "Loss after epoch     4: 0.929\n",
            "Loss after epoch     5: 0.900\n",
            "Loss after epoch     6: 0.860\n",
            "Loss after epoch     7: 0.876\n",
            "Loss after epoch     8: 0.834\n",
            "Loss after epoch     9: 0.872\n",
            "Loss after epoch    10: 0.823\n",
            "Loss after epoch    11: 0.813\n",
            "Loss after epoch    12: 0.759\n",
            "Loss after epoch    13: 0.782\n",
            "Loss after epoch    14: 0.790\n",
            "Loss after epoch    15: 0.765\n",
            "Loss after epoch    16: 0.748\n",
            "Loss after epoch    17: 0.766\n",
            "Loss after epoch    18: 0.759\n",
            "Loss after epoch    19: 0.743\n",
            "Loss after epoch    20: 0.710\n",
            "Loss after epoch    21: 0.730\n",
            "Loss after epoch    22: 0.701\n",
            "Loss after epoch    23: 0.702\n",
            "Loss after epoch    24: 0.730\n",
            "Loss after epoch    25: 0.692\n",
            "Loss after epoch    26: 0.670\n",
            "Loss after epoch    27: 0.666\n",
            "Loss after epoch    28: 0.642\n",
            "Loss after epoch    29: 0.647\n",
            "Loss after epoch    30: 0.675\n",
            "Loss after epoch    31: 0.618\n",
            "Loss after epoch    32: 0.608\n",
            "Loss after epoch    33: 0.647\n",
            "Loss after epoch    34: 0.589\n",
            "Loss after epoch    35: 0.555\n",
            "Loss after epoch    36: 0.566\n",
            "Loss after epoch    37: 0.551\n",
            "Loss after epoch    38: 0.541\n",
            "Loss after epoch    39: 0.512\n",
            "Loss after epoch    40: 0.519\n",
            "Loss after epoch    41: 0.511\n",
            "Loss after epoch    42: 0.487\n",
            "Loss after epoch    43: 0.534\n",
            "Loss after epoch    44: 0.526\n",
            "Loss after epoch    45: 0.509\n",
            "Loss after epoch    46: 0.495\n",
            "Loss after epoch    47: 0.510\n",
            "Loss after epoch    48: 0.503\n",
            "Loss after epoch    49: 0.490\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 0 criteria3: 64 %\n",
            "------------------------------\n",
            "FOLD 2 for Criteria3\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.095\n",
            "Loss after epoch     1: 1.038\n",
            "Loss after epoch     2: 1.016\n",
            "Loss after epoch     3: 0.976\n",
            "Loss after epoch     4: 0.976\n",
            "Loss after epoch     5: 0.953\n",
            "Loss after epoch     6: 0.921\n",
            "Loss after epoch     7: 0.905\n",
            "Loss after epoch     8: 0.908\n",
            "Loss after epoch     9: 0.909\n",
            "Loss after epoch    10: 0.870\n",
            "Loss after epoch    11: 0.874\n",
            "Loss after epoch    12: 0.826\n",
            "Loss after epoch    13: 0.829\n",
            "Loss after epoch    14: 0.809\n",
            "Loss after epoch    15: 0.798\n",
            "Loss after epoch    16: 0.778\n",
            "Loss after epoch    17: 0.805\n",
            "Loss after epoch    18: 0.780\n",
            "Loss after epoch    19: 0.788\n",
            "Loss after epoch    20: 0.726\n",
            "Loss after epoch    21: 0.764\n",
            "Loss after epoch    22: 0.780\n",
            "Loss after epoch    23: 0.746\n",
            "Loss after epoch    24: 0.728\n",
            "Loss after epoch    25: 0.746\n",
            "Loss after epoch    26: 0.701\n",
            "Loss after epoch    27: 0.700\n",
            "Loss after epoch    28: 0.753\n",
            "Loss after epoch    29: 0.728\n",
            "Loss after epoch    30: 0.695\n",
            "Loss after epoch    31: 0.663\n",
            "Loss after epoch    32: 0.699\n",
            "Loss after epoch    33: 0.597\n",
            "Loss after epoch    34: 0.684\n",
            "Loss after epoch    35: 0.692\n",
            "Loss after epoch    36: 0.668\n",
            "Loss after epoch    37: 0.638\n",
            "Loss after epoch    38: 0.645\n",
            "Loss after epoch    39: 0.651\n",
            "Loss after epoch    40: 0.599\n",
            "Loss after epoch    41: 0.602\n",
            "Loss after epoch    42: 0.595\n",
            "Loss after epoch    43: 0.605\n",
            "Loss after epoch    44: 0.565\n",
            "Loss after epoch    45: 0.543\n",
            "Loss after epoch    46: 0.544\n",
            "Loss after epoch    47: 0.576\n",
            "Loss after epoch    48: 0.551\n",
            "Loss after epoch    49: 0.591\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 1 criteria3: 68 %\n",
            "------------------------------\n",
            "FOLD 3 for Criteria3\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.188\n",
            "Loss after epoch     1: 1.070\n",
            "Loss after epoch     2: 0.998\n",
            "Loss after epoch     3: 0.978\n",
            "Loss after epoch     4: 0.951\n",
            "Loss after epoch     5: 0.929\n",
            "Loss after epoch     6: 0.881\n",
            "Loss after epoch     7: 0.860\n",
            "Loss after epoch     8: 0.862\n",
            "Loss after epoch     9: 0.834\n",
            "Loss after epoch    10: 0.841\n",
            "Loss after epoch    11: 0.797\n",
            "Loss after epoch    12: 0.797\n",
            "Loss after epoch    13: 0.768\n",
            "Loss after epoch    14: 0.790\n",
            "Loss after epoch    15: 0.757\n",
            "Loss after epoch    16: 0.742\n",
            "Loss after epoch    17: 0.760\n",
            "Loss after epoch    18: 0.714\n",
            "Loss after epoch    19: 0.682\n",
            "Loss after epoch    20: 0.661\n",
            "Loss after epoch    21: 0.616\n",
            "Loss after epoch    22: 0.685\n",
            "Loss after epoch    23: 0.666\n",
            "Loss after epoch    24: 0.632\n",
            "Loss after epoch    25: 0.655\n",
            "Loss after epoch    26: 0.640\n",
            "Loss after epoch    27: 0.650\n",
            "Loss after epoch    28: 0.655\n",
            "Loss after epoch    29: 0.663\n",
            "Loss after epoch    30: 0.632\n",
            "Loss after epoch    31: 0.603\n",
            "Loss after epoch    32: 0.590\n",
            "Loss after epoch    33: 0.585\n",
            "Loss after epoch    34: 0.621\n",
            "Loss after epoch    35: 0.631\n",
            "Loss after epoch    36: 0.552\n",
            "Loss after epoch    37: 0.512\n",
            "Loss after epoch    38: 0.531\n",
            "Loss after epoch    39: 0.542\n",
            "Loss after epoch    40: 0.524\n",
            "Loss after epoch    41: 0.534\n",
            "Loss after epoch    42: 0.478\n",
            "Loss after epoch    43: 0.531\n",
            "Loss after epoch    44: 0.495\n",
            "Loss after epoch    45: 0.471\n",
            "Loss after epoch    46: 0.536\n",
            "Loss after epoch    47: 0.485\n",
            "Loss after epoch    48: 0.427\n",
            "Loss after epoch    49: 0.431\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 2 criteria3: 66 %\n",
            "------------------------------\n",
            "FOLD 4 for Criteria3\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.118\n",
            "Loss after epoch     1: 1.049\n",
            "Loss after epoch     2: 1.008\n",
            "Loss after epoch     3: 1.001\n",
            "Loss after epoch     4: 0.949\n",
            "Loss after epoch     5: 0.931\n",
            "Loss after epoch     6: 0.921\n",
            "Loss after epoch     7: 0.945\n",
            "Loss after epoch     8: 0.924\n",
            "Loss after epoch     9: 0.906\n",
            "Loss after epoch    10: 0.875\n",
            "Loss after epoch    11: 0.864\n",
            "Loss after epoch    12: 0.859\n",
            "Loss after epoch    13: 0.844\n",
            "Loss after epoch    14: 0.825\n",
            "Loss after epoch    15: 0.818\n",
            "Loss after epoch    16: 0.786\n",
            "Loss after epoch    17: 0.758\n",
            "Loss after epoch    18: 0.765\n",
            "Loss after epoch    19: 0.802\n",
            "Loss after epoch    20: 0.756\n",
            "Loss after epoch    21: 0.738\n",
            "Loss after epoch    22: 0.741\n",
            "Loss after epoch    23: 0.770\n",
            "Loss after epoch    24: 0.742\n",
            "Loss after epoch    25: 0.761\n",
            "Loss after epoch    26: 0.748\n",
            "Loss after epoch    27: 0.727\n",
            "Loss after epoch    28: 0.731\n",
            "Loss after epoch    29: 0.693\n",
            "Loss after epoch    30: 0.685\n",
            "Loss after epoch    31: 0.703\n",
            "Loss after epoch    32: 0.662\n",
            "Loss after epoch    33: 0.666\n",
            "Loss after epoch    34: 0.652\n",
            "Loss after epoch    35: 0.595\n",
            "Loss after epoch    36: 0.545\n",
            "Loss after epoch    37: 0.598\n",
            "Loss after epoch    38: 0.628\n",
            "Loss after epoch    39: 0.593\n",
            "Loss after epoch    40: 0.631\n",
            "Loss after epoch    41: 0.602\n",
            "Loss after epoch    42: 0.582\n",
            "Loss after epoch    43: 0.533\n",
            "Loss after epoch    44: 0.544\n",
            "Loss after epoch    45: 0.595\n",
            "Loss after epoch    46: 0.591\n",
            "Loss after epoch    47: 0.613\n",
            "Loss after epoch    48: 0.502\n",
            "Loss after epoch    49: 0.484\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 3 criteria3: 73 %\n",
            "------------------------------\n",
            "FOLD 5 for Criteria3\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.069\n",
            "Loss after epoch     1: 1.032\n",
            "Loss after epoch     2: 0.995\n",
            "Loss after epoch     3: 0.974\n",
            "Loss after epoch     4: 0.959\n",
            "Loss after epoch     5: 0.948\n",
            "Loss after epoch     6: 0.886\n",
            "Loss after epoch     7: 0.887\n",
            "Loss after epoch     8: 0.849\n",
            "Loss after epoch     9: 0.867\n",
            "Loss after epoch    10: 0.839\n",
            "Loss after epoch    11: 0.836\n",
            "Loss after epoch    12: 0.833\n",
            "Loss after epoch    13: 0.853\n",
            "Loss after epoch    14: 0.851\n",
            "Loss after epoch    15: 0.869\n",
            "Loss after epoch    16: 0.812\n",
            "Loss after epoch    17: 0.798\n",
            "Loss after epoch    18: 0.774\n",
            "Loss after epoch    19: 0.827\n",
            "Loss after epoch    20: 0.759\n",
            "Loss after epoch    21: 0.750\n",
            "Loss after epoch    22: 0.746\n",
            "Loss after epoch    23: 0.770\n",
            "Loss after epoch    24: 0.731\n",
            "Loss after epoch    25: 0.724\n",
            "Loss after epoch    26: 0.740\n",
            "Loss after epoch    27: 0.657\n",
            "Loss after epoch    28: 0.679\n",
            "Loss after epoch    29: 0.673\n",
            "Loss after epoch    30: 0.637\n",
            "Loss after epoch    31: 0.659\n",
            "Loss after epoch    32: 0.650\n",
            "Loss after epoch    33: 0.596\n",
            "Loss after epoch    34: 0.566\n",
            "Loss after epoch    35: 0.568\n",
            "Loss after epoch    36: 0.608\n",
            "Loss after epoch    37: 0.607\n",
            "Loss after epoch    38: 0.606\n",
            "Loss after epoch    39: 0.600\n",
            "Loss after epoch    40: 0.570\n",
            "Loss after epoch    41: 0.584\n",
            "Loss after epoch    42: 0.624\n",
            "Loss after epoch    43: 0.562\n",
            "Loss after epoch    44: 0.545\n",
            "Loss after epoch    45: 0.538\n",
            "Loss after epoch    46: 0.539\n",
            "Loss after epoch    47: 0.547\n",
            "Loss after epoch    48: 0.473\n",
            "Loss after epoch    49: 0.546\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 4 criteria3: 68 %\n",
            "------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS for CRITERIA3\n",
            "------------------------------\n",
            "Fold 0 for Criteria3: 64.51612903225806 %\n",
            "Fold 1 for Criteria3: 68.38709677419355 %\n",
            "Fold 2 for Criteria3: 66.88311688311688 %\n",
            "Fold 3 for Criteria3: 73.37662337662337 %\n",
            "Fold 4 for Criteria3: 68.83116883116884 %\n",
            "Average : 68.39882697947215 %\n",
            "FOLD 1 for Criteria4\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 0.954\n",
            "Loss after epoch     1: 0.861\n",
            "Loss after epoch     2: 0.815\n",
            "Loss after epoch     3: 0.788\n",
            "Loss after epoch     4: 0.728\n",
            "Loss after epoch     5: 0.708\n",
            "Loss after epoch     6: 0.704\n",
            "Loss after epoch     7: 0.657\n",
            "Loss after epoch     8: 0.668\n",
            "Loss after epoch     9: 0.660\n",
            "Loss after epoch    10: 0.650\n",
            "Loss after epoch    11: 0.569\n",
            "Loss after epoch    12: 0.614\n",
            "Loss after epoch    13: 0.563\n",
            "Loss after epoch    14: 0.585\n",
            "Loss after epoch    15: 0.584\n",
            "Loss after epoch    16: 0.589\n",
            "Loss after epoch    17: 0.571\n",
            "Loss after epoch    18: 0.548\n",
            "Loss after epoch    19: 0.536\n",
            "Loss after epoch    20: 0.578\n",
            "Loss after epoch    21: 0.578\n",
            "Loss after epoch    22: 0.559\n",
            "Loss after epoch    23: 0.557\n",
            "Loss after epoch    24: 0.521\n",
            "Loss after epoch    25: 0.535\n",
            "Loss after epoch    26: 0.505\n",
            "Loss after epoch    27: 0.502\n",
            "Loss after epoch    28: 0.498\n",
            "Loss after epoch    29: 0.465\n",
            "Loss after epoch    30: 0.494\n",
            "Loss after epoch    31: 0.453\n",
            "Loss after epoch    32: 0.430\n",
            "Loss after epoch    33: 0.491\n",
            "Loss after epoch    34: 0.533\n",
            "Loss after epoch    35: 0.492\n",
            "Loss after epoch    36: 0.465\n",
            "Loss after epoch    37: 0.483\n",
            "Loss after epoch    38: 0.469\n",
            "Loss after epoch    39: 0.438\n",
            "Loss after epoch    40: 0.532\n",
            "Loss after epoch    41: 0.435\n",
            "Loss after epoch    42: 0.418\n",
            "Loss after epoch    43: 0.476\n",
            "Loss after epoch    44: 0.445\n",
            "Loss after epoch    45: 0.416\n",
            "Loss after epoch    46: 0.383\n",
            "Loss after epoch    47: 0.417\n",
            "Loss after epoch    48: 0.391\n",
            "Loss after epoch    49: 0.423\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 0 criteria4: 71 %\n",
            "------------------------------\n",
            "FOLD 2 for Criteria4\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.280\n",
            "Loss after epoch     1: 1.067\n",
            "Loss after epoch     2: 0.933\n",
            "Loss after epoch     3: 0.851\n",
            "Loss after epoch     4: 0.797\n",
            "Loss after epoch     5: 0.786\n",
            "Loss after epoch     6: 0.763\n",
            "Loss after epoch     7: 0.712\n",
            "Loss after epoch     8: 0.706\n",
            "Loss after epoch     9: 0.674\n",
            "Loss after epoch    10: 0.666\n",
            "Loss after epoch    11: 0.647\n",
            "Loss after epoch    12: 0.652\n",
            "Loss after epoch    13: 0.647\n",
            "Loss after epoch    14: 0.669\n",
            "Loss after epoch    15: 0.625\n",
            "Loss after epoch    16: 0.626\n",
            "Loss after epoch    17: 0.618\n",
            "Loss after epoch    18: 0.621\n",
            "Loss after epoch    19: 0.599\n",
            "Loss after epoch    20: 0.581\n",
            "Loss after epoch    21: 0.618\n",
            "Loss after epoch    22: 0.554\n",
            "Loss after epoch    23: 0.589\n",
            "Loss after epoch    24: 0.538\n",
            "Loss after epoch    25: 0.554\n",
            "Loss after epoch    26: 0.529\n",
            "Loss after epoch    27: 0.534\n",
            "Loss after epoch    28: 0.526\n",
            "Loss after epoch    29: 0.510\n",
            "Loss after epoch    30: 0.549\n",
            "Loss after epoch    31: 0.498\n",
            "Loss after epoch    32: 0.510\n",
            "Loss after epoch    33: 0.518\n",
            "Loss after epoch    34: 0.539\n",
            "Loss after epoch    35: 0.485\n",
            "Loss after epoch    36: 0.492\n",
            "Loss after epoch    37: 0.483\n",
            "Loss after epoch    38: 0.449\n",
            "Loss after epoch    39: 0.471\n",
            "Loss after epoch    40: 0.512\n",
            "Loss after epoch    41: 0.475\n",
            "Loss after epoch    42: 0.437\n",
            "Loss after epoch    43: 0.445\n",
            "Loss after epoch    44: 0.468\n",
            "Loss after epoch    45: 0.439\n",
            "Loss after epoch    46: 0.391\n",
            "Loss after epoch    47: 0.435\n",
            "Loss after epoch    48: 0.456\n",
            "Loss after epoch    49: 0.426\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 1 criteria4: 80 %\n",
            "------------------------------\n",
            "FOLD 3 for Criteria4\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.016\n",
            "Loss after epoch     1: 0.909\n",
            "Loss after epoch     2: 0.866\n",
            "Loss after epoch     3: 0.821\n",
            "Loss after epoch     4: 0.782\n",
            "Loss after epoch     5: 0.755\n",
            "Loss after epoch     6: 0.741\n",
            "Loss after epoch     7: 0.749\n",
            "Loss after epoch     8: 0.719\n",
            "Loss after epoch     9: 0.705\n",
            "Loss after epoch    10: 0.682\n",
            "Loss after epoch    11: 0.667\n",
            "Loss after epoch    12: 0.683\n",
            "Loss after epoch    13: 0.658\n",
            "Loss after epoch    14: 0.674\n",
            "Loss after epoch    15: 0.657\n",
            "Loss after epoch    16: 0.656\n",
            "Loss after epoch    17: 0.638\n",
            "Loss after epoch    18: 0.628\n",
            "Loss after epoch    19: 0.622\n",
            "Loss after epoch    20: 0.630\n",
            "Loss after epoch    21: 0.618\n",
            "Loss after epoch    22: 0.614\n",
            "Loss after epoch    23: 0.603\n",
            "Loss after epoch    24: 0.585\n",
            "Loss after epoch    25: 0.601\n",
            "Loss after epoch    26: 0.585\n",
            "Loss after epoch    27: 0.584\n",
            "Loss after epoch    28: 0.585\n",
            "Loss after epoch    29: 0.550\n",
            "Loss after epoch    30: 0.531\n",
            "Loss after epoch    31: 0.554\n",
            "Loss after epoch    32: 0.543\n",
            "Loss after epoch    33: 0.551\n",
            "Loss after epoch    34: 0.506\n",
            "Loss after epoch    35: 0.534\n",
            "Loss after epoch    36: 0.533\n",
            "Loss after epoch    37: 0.524\n",
            "Loss after epoch    38: 0.474\n",
            "Loss after epoch    39: 0.508\n",
            "Loss after epoch    40: 0.483\n",
            "Loss after epoch    41: 0.497\n",
            "Loss after epoch    42: 0.505\n",
            "Loss after epoch    43: 0.454\n",
            "Loss after epoch    44: 0.416\n",
            "Loss after epoch    45: 0.463\n",
            "Loss after epoch    46: 0.433\n",
            "Loss after epoch    47: 0.443\n",
            "Loss after epoch    48: 0.437\n",
            "Loss after epoch    49: 0.430\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 2 criteria4: 72 %\n",
            "------------------------------\n",
            "FOLD 4 for Criteria4\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.215\n",
            "Loss after epoch     1: 1.033\n",
            "Loss after epoch     2: 0.911\n",
            "Loss after epoch     3: 0.832\n",
            "Loss after epoch     4: 0.783\n",
            "Loss after epoch     5: 0.756\n",
            "Loss after epoch     6: 0.707\n",
            "Loss after epoch     7: 0.700\n",
            "Loss after epoch     8: 0.651\n",
            "Loss after epoch     9: 0.678\n",
            "Loss after epoch    10: 0.648\n",
            "Loss after epoch    11: 0.661\n",
            "Loss after epoch    12: 0.654\n",
            "Loss after epoch    13: 0.637\n",
            "Loss after epoch    14: 0.650\n",
            "Loss after epoch    15: 0.615\n",
            "Loss after epoch    16: 0.628\n",
            "Loss after epoch    17: 0.608\n",
            "Loss after epoch    18: 0.562\n",
            "Loss after epoch    19: 0.580\n",
            "Loss after epoch    20: 0.552\n",
            "Loss after epoch    21: 0.581\n",
            "Loss after epoch    22: 0.550\n",
            "Loss after epoch    23: 0.533\n",
            "Loss after epoch    24: 0.564\n",
            "Loss after epoch    25: 0.535\n",
            "Loss after epoch    26: 0.541\n",
            "Loss after epoch    27: 0.538\n",
            "Loss after epoch    28: 0.538\n",
            "Loss after epoch    29: 0.519\n",
            "Loss after epoch    30: 0.533\n",
            "Loss after epoch    31: 0.489\n",
            "Loss after epoch    32: 0.480\n",
            "Loss after epoch    33: 0.523\n",
            "Loss after epoch    34: 0.530\n",
            "Loss after epoch    35: 0.470\n",
            "Loss after epoch    36: 0.488\n",
            "Loss after epoch    37: 0.493\n",
            "Loss after epoch    38: 0.508\n",
            "Loss after epoch    39: 0.470\n",
            "Loss after epoch    40: 0.447\n",
            "Loss after epoch    41: 0.447\n",
            "Loss after epoch    42: 0.436\n",
            "Loss after epoch    43: 0.456\n",
            "Loss after epoch    44: 0.428\n",
            "Loss after epoch    45: 0.412\n",
            "Loss after epoch    46: 0.399\n",
            "Loss after epoch    47: 0.430\n",
            "Loss after epoch    48: 0.403\n",
            "Loss after epoch    49: 0.447\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 3 criteria4: 77 %\n",
            "------------------------------\n",
            "FOLD 5 for Criteria4\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.113\n",
            "Loss after epoch     1: 0.956\n",
            "Loss after epoch     2: 0.885\n",
            "Loss after epoch     3: 0.834\n",
            "Loss after epoch     4: 0.789\n",
            "Loss after epoch     5: 0.757\n",
            "Loss after epoch     6: 0.743\n",
            "Loss after epoch     7: 0.717\n",
            "Loss after epoch     8: 0.700\n",
            "Loss after epoch     9: 0.675\n",
            "Loss after epoch    10: 0.679\n",
            "Loss after epoch    11: 0.660\n",
            "Loss after epoch    12: 0.631\n",
            "Loss after epoch    13: 0.639\n",
            "Loss after epoch    14: 0.644\n",
            "Loss after epoch    15: 0.641\n",
            "Loss after epoch    16: 0.629\n",
            "Loss after epoch    17: 0.621\n",
            "Loss after epoch    18: 0.629\n",
            "Loss after epoch    19: 0.645\n",
            "Loss after epoch    20: 0.593\n",
            "Loss after epoch    21: 0.585\n",
            "Loss after epoch    22: 0.528\n",
            "Loss after epoch    23: 0.547\n",
            "Loss after epoch    24: 0.526\n",
            "Loss after epoch    25: 0.583\n",
            "Loss after epoch    26: 0.521\n",
            "Loss after epoch    27: 0.490\n",
            "Loss after epoch    28: 0.512\n",
            "Loss after epoch    29: 0.565\n",
            "Loss after epoch    30: 0.534\n",
            "Loss after epoch    31: 0.499\n",
            "Loss after epoch    32: 0.498\n",
            "Loss after epoch    33: 0.479\n",
            "Loss after epoch    34: 0.482\n",
            "Loss after epoch    35: 0.505\n",
            "Loss after epoch    36: 0.453\n",
            "Loss after epoch    37: 0.497\n",
            "Loss after epoch    38: 0.507\n",
            "Loss after epoch    39: 0.470\n",
            "Loss after epoch    40: 0.443\n",
            "Loss after epoch    41: 0.448\n",
            "Loss after epoch    42: 0.432\n",
            "Loss after epoch    43: 0.463\n",
            "Loss after epoch    44: 0.408\n",
            "Loss after epoch    45: 0.433\n",
            "Loss after epoch    46: 0.433\n",
            "Loss after epoch    47: 0.460\n",
            "Loss after epoch    48: 0.405\n",
            "Loss after epoch    49: 0.427\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 4 criteria4: 76 %\n",
            "------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS for CRITERIA4\n",
            "------------------------------\n",
            "Fold 0 for Criteria4: 71.61290322580646 %\n",
            "Fold 1 for Criteria4: 80.0 %\n",
            "Fold 2 for Criteria4: 72.72727272727273 %\n",
            "Fold 3 for Criteria4: 77.27272727272727 %\n",
            "Fold 4 for Criteria4: 76.62337662337663 %\n",
            "Average : 75.64725596983662 %\n",
            "FOLD 1 for Criteria5\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.045\n",
            "Loss after epoch     1: 0.960\n",
            "Loss after epoch     2: 0.928\n",
            "Loss after epoch     3: 0.903\n",
            "Loss after epoch     4: 0.867\n",
            "Loss after epoch     5: 0.825\n",
            "Loss after epoch     6: 0.805\n",
            "Loss after epoch     7: 0.787\n",
            "Loss after epoch     8: 0.813\n",
            "Loss after epoch     9: 0.740\n",
            "Loss after epoch    10: 0.772\n",
            "Loss after epoch    11: 0.741\n",
            "Loss after epoch    12: 0.763\n",
            "Loss after epoch    13: 0.727\n",
            "Loss after epoch    14: 0.741\n",
            "Loss after epoch    15: 0.724\n",
            "Loss after epoch    16: 0.686\n",
            "Loss after epoch    17: 0.684\n",
            "Loss after epoch    18: 0.670\n",
            "Loss after epoch    19: 0.643\n",
            "Loss after epoch    20: 0.660\n",
            "Loss after epoch    21: 0.626\n",
            "Loss after epoch    22: 0.609\n",
            "Loss after epoch    23: 0.612\n",
            "Loss after epoch    24: 0.634\n",
            "Loss after epoch    25: 0.614\n",
            "Loss after epoch    26: 0.603\n",
            "Loss after epoch    27: 0.589\n",
            "Loss after epoch    28: 0.580\n",
            "Loss after epoch    29: 0.554\n",
            "Loss after epoch    30: 0.585\n",
            "Loss after epoch    31: 0.551\n",
            "Loss after epoch    32: 0.557\n",
            "Loss after epoch    33: 0.533\n",
            "Loss after epoch    34: 0.502\n",
            "Loss after epoch    35: 0.479\n",
            "Loss after epoch    36: 0.483\n",
            "Loss after epoch    37: 0.523\n",
            "Loss after epoch    38: 0.569\n",
            "Loss after epoch    39: 0.495\n",
            "Loss after epoch    40: 0.593\n",
            "Loss after epoch    41: 0.567\n",
            "Loss after epoch    42: 0.532\n",
            "Loss after epoch    43: 0.491\n",
            "Loss after epoch    44: 0.515\n",
            "Loss after epoch    45: 0.494\n",
            "Loss after epoch    46: 0.441\n",
            "Loss after epoch    47: 0.463\n",
            "Loss after epoch    48: 0.471\n",
            "Loss after epoch    49: 0.427\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 0 criteria5: 75 %\n",
            "------------------------------\n",
            "FOLD 2 for Criteria5\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.198\n",
            "Loss after epoch     1: 1.070\n",
            "Loss after epoch     2: 1.011\n",
            "Loss after epoch     3: 0.944\n",
            "Loss after epoch     4: 0.902\n",
            "Loss after epoch     5: 0.870\n",
            "Loss after epoch     6: 0.840\n",
            "Loss after epoch     7: 0.843\n",
            "Loss after epoch     8: 0.811\n",
            "Loss after epoch     9: 0.780\n",
            "Loss after epoch    10: 0.785\n",
            "Loss after epoch    11: 0.803\n",
            "Loss after epoch    12: 0.730\n",
            "Loss after epoch    13: 0.744\n",
            "Loss after epoch    14: 0.726\n",
            "Loss after epoch    15: 0.641\n",
            "Loss after epoch    16: 0.692\n",
            "Loss after epoch    17: 0.671\n",
            "Loss after epoch    18: 0.713\n",
            "Loss after epoch    19: 0.692\n",
            "Loss after epoch    20: 0.652\n",
            "Loss after epoch    21: 0.649\n",
            "Loss after epoch    22: 0.658\n",
            "Loss after epoch    23: 0.637\n",
            "Loss after epoch    24: 0.598\n",
            "Loss after epoch    25: 0.624\n",
            "Loss after epoch    26: 0.631\n",
            "Loss after epoch    27: 0.571\n",
            "Loss after epoch    28: 0.630\n",
            "Loss after epoch    29: 0.577\n",
            "Loss after epoch    30: 0.556\n",
            "Loss after epoch    31: 0.573\n",
            "Loss after epoch    32: 0.553\n",
            "Loss after epoch    33: 0.538\n",
            "Loss after epoch    34: 0.471\n",
            "Loss after epoch    35: 0.579\n",
            "Loss after epoch    36: 0.519\n",
            "Loss after epoch    37: 0.432\n",
            "Loss after epoch    38: 0.499\n",
            "Loss after epoch    39: 0.532\n",
            "Loss after epoch    40: 0.503\n",
            "Loss after epoch    41: 0.463\n",
            "Loss after epoch    42: 0.472\n",
            "Loss after epoch    43: 0.471\n",
            "Loss after epoch    44: 0.459\n",
            "Loss after epoch    45: 0.511\n",
            "Loss after epoch    46: 0.496\n",
            "Loss after epoch    47: 0.474\n",
            "Loss after epoch    48: 0.469\n",
            "Loss after epoch    49: 0.375\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 1 criteria5: 72 %\n",
            "------------------------------\n",
            "FOLD 3 for Criteria5\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.038\n",
            "Loss after epoch     1: 0.975\n",
            "Loss after epoch     2: 0.928\n",
            "Loss after epoch     3: 0.903\n",
            "Loss after epoch     4: 0.850\n",
            "Loss after epoch     5: 0.843\n",
            "Loss after epoch     6: 0.819\n",
            "Loss after epoch     7: 0.839\n",
            "Loss after epoch     8: 0.828\n",
            "Loss after epoch     9: 0.805\n",
            "Loss after epoch    10: 0.777\n",
            "Loss after epoch    11: 0.729\n",
            "Loss after epoch    12: 0.739\n",
            "Loss after epoch    13: 0.742\n",
            "Loss after epoch    14: 0.705\n",
            "Loss after epoch    15: 0.734\n",
            "Loss after epoch    16: 0.679\n",
            "Loss after epoch    17: 0.672\n",
            "Loss after epoch    18: 0.709\n",
            "Loss after epoch    19: 0.642\n",
            "Loss after epoch    20: 0.686\n",
            "Loss after epoch    21: 0.675\n",
            "Loss after epoch    22: 0.673\n",
            "Loss after epoch    23: 0.618\n",
            "Loss after epoch    24: 0.621\n",
            "Loss after epoch    25: 0.590\n",
            "Loss after epoch    26: 0.556\n",
            "Loss after epoch    27: 0.577\n",
            "Loss after epoch    28: 0.599\n",
            "Loss after epoch    29: 0.579\n",
            "Loss after epoch    30: 0.573\n",
            "Loss after epoch    31: 0.584\n",
            "Loss after epoch    32: 0.588\n",
            "Loss after epoch    33: 0.499\n",
            "Loss after epoch    34: 0.611\n",
            "Loss after epoch    35: 0.561\n",
            "Loss after epoch    36: 0.559\n",
            "Loss after epoch    37: 0.553\n",
            "Loss after epoch    38: 0.557\n",
            "Loss after epoch    39: 0.532\n",
            "Loss after epoch    40: 0.536\n",
            "Loss after epoch    41: 0.524\n",
            "Loss after epoch    42: 0.498\n",
            "Loss after epoch    43: 0.484\n",
            "Loss after epoch    44: 0.482\n",
            "Loss after epoch    45: 0.580\n",
            "Loss after epoch    46: 0.504\n",
            "Loss after epoch    47: 0.475\n",
            "Loss after epoch    48: 0.438\n",
            "Loss after epoch    49: 0.572\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 2 criteria5: 75 %\n",
            "------------------------------\n",
            "FOLD 4 for Criteria5\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.093\n",
            "Loss after epoch     1: 0.980\n",
            "Loss after epoch     2: 0.928\n",
            "Loss after epoch     3: 0.903\n",
            "Loss after epoch     4: 0.858\n",
            "Loss after epoch     5: 0.854\n",
            "Loss after epoch     6: 0.816\n",
            "Loss after epoch     7: 0.800\n",
            "Loss after epoch     8: 0.814\n",
            "Loss after epoch     9: 0.792\n",
            "Loss after epoch    10: 0.747\n",
            "Loss after epoch    11: 0.744\n",
            "Loss after epoch    12: 0.758\n",
            "Loss after epoch    13: 0.758\n",
            "Loss after epoch    14: 0.754\n",
            "Loss after epoch    15: 0.693\n",
            "Loss after epoch    16: 0.701\n",
            "Loss after epoch    17: 0.735\n",
            "Loss after epoch    18: 0.715\n",
            "Loss after epoch    19: 0.689\n",
            "Loss after epoch    20: 0.669\n",
            "Loss after epoch    21: 0.679\n",
            "Loss after epoch    22: 0.659\n",
            "Loss after epoch    23: 0.651\n",
            "Loss after epoch    24: 0.667\n",
            "Loss after epoch    25: 0.619\n",
            "Loss after epoch    26: 0.625\n",
            "Loss after epoch    27: 0.633\n",
            "Loss after epoch    28: 0.625\n",
            "Loss after epoch    29: 0.597\n",
            "Loss after epoch    30: 0.596\n",
            "Loss after epoch    31: 0.609\n",
            "Loss after epoch    32: 0.535\n",
            "Loss after epoch    33: 0.559\n",
            "Loss after epoch    34: 0.523\n",
            "Loss after epoch    35: 0.505\n",
            "Loss after epoch    36: 0.532\n",
            "Loss after epoch    37: 0.491\n",
            "Loss after epoch    38: 0.537\n",
            "Loss after epoch    39: 0.525\n",
            "Loss after epoch    40: 0.526\n",
            "Loss after epoch    41: 0.553\n",
            "Loss after epoch    42: 0.526\n",
            "Loss after epoch    43: 0.526\n",
            "Loss after epoch    44: 0.520\n",
            "Loss after epoch    45: 0.500\n",
            "Loss after epoch    46: 0.493\n",
            "Loss after epoch    47: 0.476\n",
            "Loss after epoch    48: 0.447\n",
            "Loss after epoch    49: 0.489\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 3 criteria5: 74 %\n",
            "------------------------------\n",
            "FOLD 5 for Criteria5\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.099\n",
            "Loss after epoch     1: 1.024\n",
            "Loss after epoch     2: 0.955\n",
            "Loss after epoch     3: 0.923\n",
            "Loss after epoch     4: 0.881\n",
            "Loss after epoch     5: 0.852\n",
            "Loss after epoch     6: 0.839\n",
            "Loss after epoch     7: 0.829\n",
            "Loss after epoch     8: 0.801\n",
            "Loss after epoch     9: 0.817\n",
            "Loss after epoch    10: 0.790\n",
            "Loss after epoch    11: 0.771\n",
            "Loss after epoch    12: 0.756\n",
            "Loss after epoch    13: 0.739\n",
            "Loss after epoch    14: 0.771\n",
            "Loss after epoch    15: 0.733\n",
            "Loss after epoch    16: 0.701\n",
            "Loss after epoch    17: 0.747\n",
            "Loss after epoch    18: 0.673\n",
            "Loss after epoch    19: 0.689\n",
            "Loss after epoch    20: 0.665\n",
            "Loss after epoch    21: 0.683\n",
            "Loss after epoch    22: 0.696\n",
            "Loss after epoch    23: 0.619\n",
            "Loss after epoch    24: 0.645\n",
            "Loss after epoch    25: 0.591\n",
            "Loss after epoch    26: 0.600\n",
            "Loss after epoch    27: 0.588\n",
            "Loss after epoch    28: 0.617\n",
            "Loss after epoch    29: 0.606\n",
            "Loss after epoch    30: 0.579\n",
            "Loss after epoch    31: 0.630\n",
            "Loss after epoch    32: 0.626\n",
            "Loss after epoch    33: 0.564\n",
            "Loss after epoch    34: 0.597\n",
            "Loss after epoch    35: 0.589\n",
            "Loss after epoch    36: 0.584\n",
            "Loss after epoch    37: 0.589\n",
            "Loss after epoch    38: 0.513\n",
            "Loss after epoch    39: 0.573\n",
            "Loss after epoch    40: 0.578\n",
            "Loss after epoch    41: 0.501\n",
            "Loss after epoch    42: 0.529\n",
            "Loss after epoch    43: 0.523\n",
            "Loss after epoch    44: 0.520\n",
            "Loss after epoch    45: 0.501\n",
            "Loss after epoch    46: 0.473\n",
            "Loss after epoch    47: 0.487\n",
            "Loss after epoch    48: 0.469\n",
            "Loss after epoch    49: 0.453\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 4 criteria5: 72 %\n",
            "------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS for CRITERIA5\n",
            "------------------------------\n",
            "Fold 0 for Criteria5: 75.48387096774194 %\n",
            "Fold 1 for Criteria5: 72.90322580645162 %\n",
            "Fold 2 for Criteria5: 75.32467532467533 %\n",
            "Fold 3 for Criteria5: 74.02597402597402 %\n",
            "Fold 4 for Criteria5: 72.07792207792207 %\n",
            "Average : 73.963133640553 %\n",
            "FOLD 1 for Criteria6\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.392\n",
            "Loss after epoch     1: 1.016\n",
            "Loss after epoch     2: 0.781\n",
            "Loss after epoch     3: 0.613\n",
            "Loss after epoch     4: 0.522\n",
            "Loss after epoch     5: 0.480\n",
            "Loss after epoch     6: 0.448\n",
            "Loss after epoch     7: 0.459\n",
            "Loss after epoch     8: 0.445\n",
            "Loss after epoch     9: 0.420\n",
            "Loss after epoch    10: 0.402\n",
            "Loss after epoch    11: 0.408\n",
            "Loss after epoch    12: 0.414\n",
            "Loss after epoch    13: 0.419\n",
            "Loss after epoch    14: 0.397\n",
            "Loss after epoch    15: 0.396\n",
            "Loss after epoch    16: 0.388\n",
            "Loss after epoch    17: 0.371\n",
            "Loss after epoch    18: 0.378\n",
            "Loss after epoch    19: 0.356\n",
            "Loss after epoch    20: 0.343\n",
            "Loss after epoch    21: 0.330\n",
            "Loss after epoch    22: 0.345\n",
            "Loss after epoch    23: 0.359\n",
            "Loss after epoch    24: 0.351\n",
            "Loss after epoch    25: 0.365\n",
            "Loss after epoch    26: 0.333\n",
            "Loss after epoch    27: 0.328\n",
            "Loss after epoch    28: 0.345\n",
            "Loss after epoch    29: 0.283\n",
            "Loss after epoch    30: 0.300\n",
            "Loss after epoch    31: 0.289\n",
            "Loss after epoch    32: 0.311\n",
            "Loss after epoch    33: 0.310\n",
            "Loss after epoch    34: 0.311\n",
            "Loss after epoch    35: 0.309\n",
            "Loss after epoch    36: 0.260\n",
            "Loss after epoch    37: 0.279\n",
            "Loss after epoch    38: 0.257\n",
            "Loss after epoch    39: 0.281\n",
            "Loss after epoch    40: 0.247\n",
            "Loss after epoch    41: 0.227\n",
            "Loss after epoch    42: 0.257\n",
            "Loss after epoch    43: 0.305\n",
            "Loss after epoch    44: 0.252\n",
            "Loss after epoch    45: 0.248\n",
            "Loss after epoch    46: 0.245\n",
            "Loss after epoch    47: 0.242\n",
            "Loss after epoch    48: 0.228\n",
            "Loss after epoch    49: 0.203\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 0 criteria6: 89 %\n",
            "------------------------------\n",
            "FOLD 2 for Criteria6\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.094\n",
            "Loss after epoch     1: 0.805\n",
            "Loss after epoch     2: 0.651\n",
            "Loss after epoch     3: 0.541\n",
            "Loss after epoch     4: 0.479\n",
            "Loss after epoch     5: 0.491\n",
            "Loss after epoch     6: 0.451\n",
            "Loss after epoch     7: 0.452\n",
            "Loss after epoch     8: 0.436\n",
            "Loss after epoch     9: 0.428\n",
            "Loss after epoch    10: 0.414\n",
            "Loss after epoch    11: 0.400\n",
            "Loss after epoch    12: 0.417\n",
            "Loss after epoch    13: 0.391\n",
            "Loss after epoch    14: 0.394\n",
            "Loss after epoch    15: 0.395\n",
            "Loss after epoch    16: 0.375\n",
            "Loss after epoch    17: 0.375\n",
            "Loss after epoch    18: 0.370\n",
            "Loss after epoch    19: 0.366\n",
            "Loss after epoch    20: 0.355\n",
            "Loss after epoch    21: 0.349\n",
            "Loss after epoch    22: 0.384\n",
            "Loss after epoch    23: 0.329\n",
            "Loss after epoch    24: 0.353\n",
            "Loss after epoch    25: 0.355\n",
            "Loss after epoch    26: 0.330\n",
            "Loss after epoch    27: 0.304\n",
            "Loss after epoch    28: 0.308\n",
            "Loss after epoch    29: 0.298\n",
            "Loss after epoch    30: 0.317\n",
            "Loss after epoch    31: 0.323\n",
            "Loss after epoch    32: 0.279\n",
            "Loss after epoch    33: 0.251\n",
            "Loss after epoch    34: 0.263\n",
            "Loss after epoch    35: 0.308\n",
            "Loss after epoch    36: 0.286\n",
            "Loss after epoch    37: 0.294\n",
            "Loss after epoch    38: 0.261\n",
            "Loss after epoch    39: 0.277\n",
            "Loss after epoch    40: 0.263\n",
            "Loss after epoch    41: 0.266\n",
            "Loss after epoch    42: 0.233\n",
            "Loss after epoch    43: 0.258\n",
            "Loss after epoch    44: 0.234\n",
            "Loss after epoch    45: 0.277\n",
            "Loss after epoch    46: 0.243\n",
            "Loss after epoch    47: 0.246\n",
            "Loss after epoch    48: 0.208\n",
            "Loss after epoch    49: 0.238\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 1 criteria6: 93 %\n",
            "------------------------------\n",
            "FOLD 3 for Criteria6\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.155\n",
            "Loss after epoch     1: 0.845\n",
            "Loss after epoch     2: 0.650\n",
            "Loss after epoch     3: 0.530\n",
            "Loss after epoch     4: 0.486\n",
            "Loss after epoch     5: 0.455\n",
            "Loss after epoch     6: 0.437\n",
            "Loss after epoch     7: 0.425\n",
            "Loss after epoch     8: 0.412\n",
            "Loss after epoch     9: 0.385\n",
            "Loss after epoch    10: 0.387\n",
            "Loss after epoch    11: 0.372\n",
            "Loss after epoch    12: 0.382\n",
            "Loss after epoch    13: 0.385\n",
            "Loss after epoch    14: 0.358\n",
            "Loss after epoch    15: 0.366\n",
            "Loss after epoch    16: 0.345\n",
            "Loss after epoch    17: 0.339\n",
            "Loss after epoch    18: 0.341\n",
            "Loss after epoch    19: 0.349\n",
            "Loss after epoch    20: 0.350\n",
            "Loss after epoch    21: 0.358\n",
            "Loss after epoch    22: 0.352\n",
            "Loss after epoch    23: 0.366\n",
            "Loss after epoch    24: 0.364\n",
            "Loss after epoch    25: 0.336\n",
            "Loss after epoch    26: 0.357\n",
            "Loss after epoch    27: 0.342\n",
            "Loss after epoch    28: 0.322\n",
            "Loss after epoch    29: 0.361\n",
            "Loss after epoch    30: 0.315\n",
            "Loss after epoch    31: 0.345\n",
            "Loss after epoch    32: 0.329\n",
            "Loss after epoch    33: 0.299\n",
            "Loss after epoch    34: 0.299\n",
            "Loss after epoch    35: 0.324\n",
            "Loss after epoch    36: 0.294\n",
            "Loss after epoch    37: 0.302\n",
            "Loss after epoch    38: 0.305\n",
            "Loss after epoch    39: 0.317\n",
            "Loss after epoch    40: 0.303\n",
            "Loss after epoch    41: 0.321\n",
            "Loss after epoch    42: 0.283\n",
            "Loss after epoch    43: 0.284\n",
            "Loss after epoch    44: 0.316\n",
            "Loss after epoch    45: 0.267\n",
            "Loss after epoch    46: 0.275\n",
            "Loss after epoch    47: 0.283\n",
            "Loss after epoch    48: 0.266\n",
            "Loss after epoch    49: 0.256\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 2 criteria6: 85 %\n",
            "------------------------------\n",
            "FOLD 4 for Criteria6\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 0.978\n",
            "Loss after epoch     1: 0.742\n",
            "Loss after epoch     2: 0.586\n",
            "Loss after epoch     3: 0.508\n",
            "Loss after epoch     4: 0.472\n",
            "Loss after epoch     5: 0.459\n",
            "Loss after epoch     6: 0.445\n",
            "Loss after epoch     7: 0.426\n",
            "Loss after epoch     8: 0.427\n",
            "Loss after epoch     9: 0.407\n",
            "Loss after epoch    10: 0.401\n",
            "Loss after epoch    11: 0.394\n",
            "Loss after epoch    12: 0.402\n",
            "Loss after epoch    13: 0.393\n",
            "Loss after epoch    14: 0.377\n",
            "Loss after epoch    15: 0.377\n",
            "Loss after epoch    16: 0.368\n",
            "Loss after epoch    17: 0.383\n",
            "Loss after epoch    18: 0.350\n",
            "Loss after epoch    19: 0.355\n",
            "Loss after epoch    20: 0.332\n",
            "Loss after epoch    21: 0.346\n",
            "Loss after epoch    22: 0.359\n",
            "Loss after epoch    23: 0.341\n",
            "Loss after epoch    24: 0.312\n",
            "Loss after epoch    25: 0.331\n",
            "Loss after epoch    26: 0.319\n",
            "Loss after epoch    27: 0.293\n",
            "Loss after epoch    28: 0.309\n",
            "Loss after epoch    29: 0.314\n",
            "Loss after epoch    30: 0.293\n",
            "Loss after epoch    31: 0.279\n",
            "Loss after epoch    32: 0.285\n",
            "Loss after epoch    33: 0.277\n",
            "Loss after epoch    34: 0.281\n",
            "Loss after epoch    35: 0.262\n",
            "Loss after epoch    36: 0.244\n",
            "Loss after epoch    37: 0.277\n",
            "Loss after epoch    38: 0.246\n",
            "Loss after epoch    39: 0.214\n",
            "Loss after epoch    40: 0.217\n",
            "Loss after epoch    41: 0.204\n",
            "Loss after epoch    42: 0.200\n",
            "Loss after epoch    43: 0.204\n",
            "Loss after epoch    44: 0.234\n",
            "Loss after epoch    45: 0.183\n",
            "Loss after epoch    46: 0.204\n",
            "Loss after epoch    47: 0.193\n",
            "Loss after epoch    48: 0.192\n",
            "Loss after epoch    49: 0.213\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 3 criteria6: 82 %\n",
            "------------------------------\n",
            "FOLD 5 for Criteria6\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.134\n",
            "Loss after epoch     1: 0.861\n",
            "Loss after epoch     2: 0.658\n",
            "Loss after epoch     3: 0.546\n",
            "Loss after epoch     4: 0.479\n",
            "Loss after epoch     5: 0.461\n",
            "Loss after epoch     6: 0.428\n",
            "Loss after epoch     7: 0.421\n",
            "Loss after epoch     8: 0.426\n",
            "Loss after epoch     9: 0.390\n",
            "Loss after epoch    10: 0.376\n",
            "Loss after epoch    11: 0.403\n",
            "Loss after epoch    12: 0.392\n",
            "Loss after epoch    13: 0.374\n",
            "Loss after epoch    14: 0.361\n",
            "Loss after epoch    15: 0.362\n",
            "Loss after epoch    16: 0.366\n",
            "Loss after epoch    17: 0.365\n",
            "Loss after epoch    18: 0.335\n",
            "Loss after epoch    19: 0.339\n",
            "Loss after epoch    20: 0.322\n",
            "Loss after epoch    21: 0.350\n",
            "Loss after epoch    22: 0.311\n",
            "Loss after epoch    23: 0.337\n",
            "Loss after epoch    24: 0.309\n",
            "Loss after epoch    25: 0.326\n",
            "Loss after epoch    26: 0.349\n",
            "Loss after epoch    27: 0.379\n",
            "Loss after epoch    28: 0.342\n",
            "Loss after epoch    29: 0.318\n",
            "Loss after epoch    30: 0.292\n",
            "Loss after epoch    31: 0.273\n",
            "Loss after epoch    32: 0.272\n",
            "Loss after epoch    33: 0.312\n",
            "Loss after epoch    34: 0.291\n",
            "Loss after epoch    35: 0.261\n",
            "Loss after epoch    36: 0.266\n",
            "Loss after epoch    37: 0.248\n",
            "Loss after epoch    38: 0.255\n",
            "Loss after epoch    39: 0.306\n",
            "Loss after epoch    40: 0.277\n",
            "Loss after epoch    41: 0.260\n",
            "Loss after epoch    42: 0.245\n",
            "Loss after epoch    43: 0.273\n",
            "Loss after epoch    44: 0.256\n",
            "Loss after epoch    45: 0.227\n",
            "Loss after epoch    46: 0.235\n",
            "Loss after epoch    47: 0.223\n",
            "Loss after epoch    48: 0.260\n",
            "Loss after epoch    49: 0.213\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 4 criteria6: 87 %\n",
            "------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS for CRITERIA6\n",
            "------------------------------\n",
            "Fold 0 for Criteria6: 89.03225806451613 %\n",
            "Fold 1 for Criteria6: 93.54838709677419 %\n",
            "Fold 2 for Criteria6: 85.71428571428571 %\n",
            "Fold 3 for Criteria6: 82.46753246753246 %\n",
            "Fold 4 for Criteria6: 87.01298701298701 %\n",
            "Average : 87.5550900712191 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criteria1 = pd.DataFrame(list(w2vaggdata['target']), columns = ['c1','c2','c3','c4','c5','c6'])\n",
        "criteria1 = criteria1.astype('str')\n",
        "\n",
        "c21 = LabelBinarizer().fit_transform(criteria1['c1'])\n",
        "c22 = LabelBinarizer().fit_transform(criteria1['c2'])\n",
        "c23 = LabelBinarizer().fit_transform(criteria1['c3'])\n",
        "c24 = LabelBinarizer().fit_transform(criteria1['c4'])\n",
        "c25 = LabelBinarizer().fit_transform(criteria1['c5'])\n",
        "c26 = LabelBinarizer().fit_transform(criteria1['c6'])\n",
        "\n",
        "criteria1['c1'] = list(c21)\n",
        "criteria1['c2'] = list(c22)\n",
        "criteria1['c3'] = list(c23)\n",
        "criteria1['c4'] = list(c24)\n",
        "criteria1['c5'] = list(c25)\n",
        "criteria1['c6'] = list(c26)"
      ],
      "metadata": {
        "id": "UinRq0th4n6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    k_folds = 5\n",
        "    num_epochs = 100\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # w2v_train1 = GetDataset(w2vaggdata);w2v_test1 = GetDataset(w2vaggdata)\n",
        "    # w2v_train2 = GetDataset(w2vnormdata);w2v_test2 = GetDataset(w2vnormdata)\n",
        "    # d2v_train1 = GetDataset(d2vnormdata);d2v_test1 = GetDataset(d2vnormdata)\n",
        "    # w2v_dataset1 = ConcatDataset([w2v_train1, w2v_test1])\n",
        "    # w2v_dataset2 = ConcatDataset([w2v_train2, w2v_test2])\n",
        "    # d2v_dataset1 = ConcatDataset([d2v_train1, d2v_test1])\n",
        "    for c in [1,2,3,4,5,6]:\n",
        "\n",
        "        results = {}\n",
        "        pre = []\n",
        "        rec = []\n",
        "        f1s = []\n",
        "\n",
        "        train = GetDataset(w2vaggdata, criteria1, 'c'+str(c));test = GetDataset(w2vaggdata, criteria1, 'c'+str(c))\n",
        "        dataset = ConcatDataset([train, test])     \n",
        "\n",
        "        kfold = KFold(n_splits = k_folds, shuffle = True)\n",
        "\n",
        "        for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
        "            print(f'FOLD {fold+1} for Criteria{c}')\n",
        "            print('-' * 30)\n",
        "\n",
        "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "            test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "\n",
        "            trainloader = DataLoader(dataset, batch_size = 10, sampler = train_subsampler)\n",
        "            testloader = DataLoader(dataset, batch_size = 10, sampler = test_subsampler)\n",
        "\n",
        "            model = nnn().to(device)\n",
        "            model.apply(reset_weights)\n",
        "        \n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "            for epoch in range(0, num_epochs):\n",
        "\n",
        "                current_loss = 0.0\n",
        "                n = 0\n",
        "                for i, data in enumerate(trainloader, 0):\n",
        "                    inputs, targets = data\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs.to(device))\n",
        "                    loss = loss_function(outputs, targets.to(device))\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    current_loss += loss.item()\n",
        "                    n += 1\n",
        "                    \n",
        "                print('Loss after epoch %5d: %.3f'%(epoch, current_loss / n))\n",
        "            \n",
        "            print('Training process has finished. Saving trained model.')\n",
        "\n",
        "            print('Start Testing')\n",
        "            save_path = f'/content/drive/Shareddrives/NLP모델링/코드 연습/문서/model-fold-{fold}-c{c}.pth'\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "            correct, total = 0, 0\n",
        "            test = []\n",
        "            pred = []\n",
        "            with torch.no_grad():\n",
        "                for i, data in enumerate(testloader, 0):\n",
        "                    inputs, targets = data\n",
        "                    outputs = model(inputs.to(device))\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    _, target = torch.max(targets.data, 1)\n",
        "                    total += targets.size(0)\n",
        "                    correct += (predicted == target.to(device)).sum().item()\n",
        "                    test.append(target)\n",
        "                    pred.append(predicted)\n",
        "\n",
        "                print('Accuracy for fold %d criteria%d: %d %%' % (fold, c, 100.0 * correct/total))\n",
        "                print('-'*30)\n",
        "                results[fold] = 100.0 * (correct / total)\n",
        "\n",
        "                test = [j.item() for i in test for j in i.cpu()]\n",
        "                pred = [j.item() for i in pred for j in i.cpu()]\n",
        "                print('='*50)\n",
        "                p, r, f = get_f1(test, pred, avg = 'macro')\n",
        "                print('='*50)\n",
        "                pre.append(p)\n",
        "                rec.append(r)\n",
        "                f1s.append(f)\n",
        "\n",
        "            \n",
        "        print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS for CRITERIA{c}')\n",
        "        print('-'*30)\n",
        "        s = 0.0\n",
        "        for key, value in results.items():\n",
        "            print(f'Fold {key} for Criteria{c}: {value} %')\n",
        "            s += value\n",
        "        print(f'Average : {s/len(results.items())} %')\n",
        "        print(f'Average precision, recall, f1 : {sum(pre)/len(pre)}, {sum(rec) / len(rec)}, {sum(f1s) / len(f1s)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Uj042w3n4bvj",
        "outputId": "1fb3f5ab-848e-49dc-842e-44142da97e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 1 for Criteria1\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=20, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=20, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.059\n",
            "Loss after epoch     1: 1.001\n",
            "Loss after epoch     2: 0.965\n",
            "Loss after epoch     3: 0.932\n",
            "Loss after epoch     4: 0.905\n",
            "Loss after epoch     5: 0.890\n",
            "Loss after epoch     6: 0.878\n",
            "Loss after epoch     7: 0.862\n",
            "Loss after epoch     8: 0.845\n",
            "Loss after epoch     9: 0.841\n",
            "Loss after epoch    10: 0.829\n",
            "Loss after epoch    11: 0.811\n",
            "Loss after epoch    12: 0.822\n",
            "Loss after epoch    13: 0.795\n",
            "Loss after epoch    14: 0.798\n",
            "Loss after epoch    15: 0.795\n",
            "Loss after epoch    16: 0.808\n",
            "Loss after epoch    17: 0.795\n",
            "Loss after epoch    18: 0.791\n",
            "Loss after epoch    19: 0.788\n",
            "Loss after epoch    20: 0.776\n",
            "Loss after epoch    21: 0.766\n",
            "Loss after epoch    22: 0.772\n",
            "Loss after epoch    23: 0.761\n",
            "Loss after epoch    24: 0.762\n",
            "Loss after epoch    25: 0.758\n",
            "Loss after epoch    26: 0.752\n",
            "Loss after epoch    27: 0.744\n",
            "Loss after epoch    28: 0.750\n",
            "Loss after epoch    29: 0.753\n",
            "Loss after epoch    30: 0.734\n",
            "Loss after epoch    31: 0.743\n",
            "Loss after epoch    32: 0.734\n",
            "Loss after epoch    33: 0.733\n",
            "Loss after epoch    34: 0.749\n",
            "Loss after epoch    35: 0.744\n",
            "Loss after epoch    36: 0.728\n",
            "Loss after epoch    37: 0.733\n",
            "Loss after epoch    38: 0.741\n",
            "Loss after epoch    39: 0.720\n",
            "Loss after epoch    40: 0.727\n",
            "Loss after epoch    41: 0.741\n",
            "Loss after epoch    42: 0.728\n",
            "Loss after epoch    43: 0.727\n",
            "Loss after epoch    44: 0.728\n",
            "Loss after epoch    45: 0.707\n",
            "Loss after epoch    46: 0.704\n",
            "Loss after epoch    47: 0.709\n",
            "Loss after epoch    48: 0.700\n",
            "Loss after epoch    49: 0.701\n",
            "Loss after epoch    50: 0.704\n",
            "Loss after epoch    51: 0.697\n",
            "Loss after epoch    52: 0.710\n",
            "Loss after epoch    53: 0.697\n",
            "Loss after epoch    54: 0.697\n",
            "Loss after epoch    55: 0.697\n",
            "Loss after epoch    56: 0.681\n",
            "Loss after epoch    57: 0.695\n",
            "Loss after epoch    58: 0.682\n",
            "Loss after epoch    59: 0.685\n",
            "Loss after epoch    60: 0.681\n",
            "Loss after epoch    61: 0.695\n",
            "Loss after epoch    62: 0.705\n",
            "Loss after epoch    63: 0.688\n",
            "Loss after epoch    64: 0.679\n",
            "Loss after epoch    65: 0.678\n",
            "Loss after epoch    66: 0.671\n",
            "Loss after epoch    67: 0.672\n",
            "Loss after epoch    68: 0.674\n",
            "Loss after epoch    69: 0.665\n",
            "Loss after epoch    70: 0.698\n",
            "Loss after epoch    71: 0.684\n",
            "Loss after epoch    72: 0.653\n",
            "Loss after epoch    73: 0.671\n",
            "Loss after epoch    74: 0.671\n",
            "Loss after epoch    75: 0.650\n",
            "Loss after epoch    76: 0.679\n",
            "Loss after epoch    77: 0.676\n",
            "Loss after epoch    78: 0.661\n",
            "Loss after epoch    79: 0.651\n",
            "Loss after epoch    80: 0.652\n",
            "Loss after epoch    81: 0.658\n",
            "Loss after epoch    82: 0.661\n",
            "Loss after epoch    83: 0.658\n",
            "Loss after epoch    84: 0.654\n",
            "Loss after epoch    85: 0.655\n",
            "Loss after epoch    86: 0.649\n",
            "Loss after epoch    87: 0.660\n",
            "Loss after epoch    88: 0.665\n",
            "Loss after epoch    89: 0.656\n",
            "Loss after epoch    90: 0.655\n",
            "Loss after epoch    91: 0.652\n",
            "Loss after epoch    92: 0.684\n",
            "Loss after epoch    93: 0.656\n",
            "Loss after epoch    94: 0.647\n",
            "Loss after epoch    95: 0.646\n",
            "Loss after epoch    96: 0.645\n",
            "Loss after epoch    97: 0.638\n",
            "Loss after epoch    98: 0.638\n",
            "Loss after epoch    99: 0.654\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 0 criteria1: 79 %\n",
            "------------------------------\n",
            "==================================================\n",
            "Confusion Matrix\n",
            "[[ 3  4  1]\n",
            " [ 1 34 16]\n",
            " [ 0 10 86]]\n",
            "Accuracy : 0.7935483870967742, Precision : 0.764428263214671, Recall : 0.6458333333333334, F1 : 0.6837300983029625\n",
            "==================================================\n",
            "FOLD 2 for Criteria1\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=20, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=20, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.071\n",
            "Loss after epoch     1: 1.006\n",
            "Loss after epoch     2: 0.960\n",
            "Loss after epoch     3: 0.930\n",
            "Loss after epoch     4: 0.900\n",
            "Loss after epoch     5: 0.881\n",
            "Loss after epoch     6: 0.866\n",
            "Loss after epoch     7: 0.854\n",
            "Loss after epoch     8: 0.840\n",
            "Loss after epoch     9: 0.828\n",
            "Loss after epoch    10: 0.833\n",
            "Loss after epoch    11: 0.824\n",
            "Loss after epoch    12: 0.815\n",
            "Loss after epoch    13: 0.806\n",
            "Loss after epoch    14: 0.802\n",
            "Loss after epoch    15: 0.794\n",
            "Loss after epoch    16: 0.789\n",
            "Loss after epoch    17: 0.777\n",
            "Loss after epoch    18: 0.773\n",
            "Loss after epoch    19: 0.762\n",
            "Loss after epoch    20: 0.767\n",
            "Loss after epoch    21: 0.757\n",
            "Loss after epoch    22: 0.761\n",
            "Loss after epoch    23: 0.743\n",
            "Loss after epoch    24: 0.739\n",
            "Loss after epoch    25: 0.741\n",
            "Loss after epoch    26: 0.727\n",
            "Loss after epoch    27: 0.722\n",
            "Loss after epoch    28: 0.728\n",
            "Loss after epoch    29: 0.729\n",
            "Loss after epoch    30: 0.722\n",
            "Loss after epoch    31: 0.720\n",
            "Loss after epoch    32: 0.700\n",
            "Loss after epoch    33: 0.718\n",
            "Loss after epoch    34: 0.710\n",
            "Loss after epoch    35: 0.703\n",
            "Loss after epoch    36: 0.718\n",
            "Loss after epoch    37: 0.706\n",
            "Loss after epoch    38: 0.718\n",
            "Loss after epoch    39: 0.723\n",
            "Loss after epoch    40: 0.698\n",
            "Loss after epoch    41: 0.699\n",
            "Loss after epoch    42: 0.705\n",
            "Loss after epoch    43: 0.698\n",
            "Loss after epoch    44: 0.702\n",
            "Loss after epoch    45: 0.683\n",
            "Loss after epoch    46: 0.673\n",
            "Loss after epoch    47: 0.690\n",
            "Loss after epoch    48: 0.695\n",
            "Loss after epoch    49: 0.691\n",
            "Loss after epoch    50: 0.689\n",
            "Loss after epoch    51: 0.702\n",
            "Loss after epoch    52: 0.693\n",
            "Loss after epoch    53: 0.690\n",
            "Loss after epoch    54: 0.697\n",
            "Loss after epoch    55: 0.693\n",
            "Loss after epoch    56: 0.699\n",
            "Loss after epoch    57: 0.689\n",
            "Loss after epoch    58: 0.671\n",
            "Loss after epoch    59: 0.667\n",
            "Loss after epoch    60: 0.661\n",
            "Loss after epoch    61: 0.697\n",
            "Loss after epoch    62: 0.677\n",
            "Loss after epoch    63: 0.672\n",
            "Loss after epoch    64: 0.679\n",
            "Loss after epoch    65: 0.672\n",
            "Loss after epoch    66: 0.671\n",
            "Loss after epoch    67: 0.686\n",
            "Loss after epoch    68: 0.668\n",
            "Loss after epoch    69: 0.672\n",
            "Loss after epoch    70: 0.674\n",
            "Loss after epoch    71: 0.661\n",
            "Loss after epoch    72: 0.654\n",
            "Loss after epoch    73: 0.662\n",
            "Loss after epoch    74: 0.678\n",
            "Loss after epoch    75: 0.661\n",
            "Loss after epoch    76: 0.652\n",
            "Loss after epoch    77: 0.680\n",
            "Loss after epoch    78: 0.643\n",
            "Loss after epoch    79: 0.655\n",
            "Loss after epoch    80: 0.664\n",
            "Loss after epoch    81: 0.662\n",
            "Loss after epoch    82: 0.647\n",
            "Loss after epoch    83: 0.650\n",
            "Loss after epoch    84: 0.645\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-72b535bee123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    211\u001b[0m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \"\"\"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criteria2 = pd.DataFrame(list(d2vnormdata['target']), columns = ['c1','c2','c3','c4','c5','c6'])\n",
        "criteria2 = criteria2.astype('str')\n",
        "\n",
        "c31 = LabelBinarizer().fit_transform(criteria2['c1'])\n",
        "c32 = LabelBinarizer().fit_transform(criteria2['c2'])\n",
        "c33 = LabelBinarizer().fit_transform(criteria2['c3'])\n",
        "c34 = LabelBinarizer().fit_transform(criteria2['c4'])\n",
        "c35 = LabelBinarizer().fit_transform(criteria2['c5'])\n",
        "c36 = LabelBinarizer().fit_transform(criteria2['c6'])\n",
        "\n",
        "criteria2['c1'] = list(c31)\n",
        "criteria2['c2'] = list(c32)\n",
        "criteria2['c3'] = list(c33)\n",
        "criteria2['c4'] = list(c34)\n",
        "criteria2['c5'] = list(c35)\n",
        "criteria2['c6'] = list(c36)"
      ],
      "metadata": {
        "id": "UB-Bh4kH7ZIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    k_folds = 5\n",
        "    num_epochs = 50\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # w2v_train1 = GetDataset(w2vaggdata);w2v_test1 = GetDataset(w2vaggdata)\n",
        "    # w2v_train2 = GetDataset(w2vnormdata);w2v_test2 = GetDataset(w2vnormdata)\n",
        "    # d2v_train1 = GetDataset(d2vnormdata);d2v_test1 = GetDataset(d2vnormdata)\n",
        "    # w2v_dataset1 = ConcatDataset([w2v_train1, w2v_test1])\n",
        "    # w2v_dataset2 = ConcatDataset([w2v_train2, w2v_test2])\n",
        "    # d2v_dataset1 = ConcatDataset([d2v_train1, d2v_test1])\n",
        "    for c in [1,2,3,4,5,6]:\n",
        "        train = GetDataset(d2vnormdata, criteria2, 'c'+str(c));test = GetDataset(d2vnormdata, criteria2, 'c'+str(c))\n",
        "        dataset = ConcatDataset([train, test])     \n",
        "\n",
        "        kfold = KFold(n_splits = k_folds, shuffle = True)\n",
        "\n",
        "        for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
        "            print(f'FOLD {fold+1} for Criteria{c}')\n",
        "            print('-' * 30)\n",
        "\n",
        "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "            test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "\n",
        "            trainloader = DataLoader(dataset, batch_size = 10, sampler = train_subsampler)\n",
        "            testloader = DataLoader(dataset, batch_size = 10, sampler = test_subsampler)\n",
        "\n",
        "            model = nnn().to(device)\n",
        "            model.apply(reset_weights)\n",
        "        \n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "            for epoch in range(0, num_epochs):\n",
        "\n",
        "                current_loss = 0.0\n",
        "                n = 0\n",
        "                for i, data in enumerate(trainloader, 0):\n",
        "                    inputs, targets = data\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs.to(device))\n",
        "                    loss = loss_function(outputs, targets.to(device))\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    current_loss += loss.item()\n",
        "                    n += 1\n",
        "                    \n",
        "                print('Loss after epoch %5d: %.3f'%(epoch, current_loss / n))\n",
        "            \n",
        "            print('Training process has finished. Saving trained model.')\n",
        "\n",
        "            print('Start Testing')\n",
        "            save_path = f'/content/drive/Shareddrives/NLP모델링/코드 연습/문서/model-fold-{fold}-c{c}.pth'\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "            correct, total = 0, 0\n",
        "            with torch.no_grad():\n",
        "                for i, data in enumerate(testloader, 0):\n",
        "                    inputs, targets = data\n",
        "                    outputs = model(inputs.to(device))\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    _, target = torch.max(targets.data, 1)\n",
        "                    total += targets.size(0)\n",
        "                    correct += (predicted == target.to(device)).sum().item()\n",
        "\n",
        "                print('Accuracy for fold %d criteria%d: %d %%' % (fold, c, 100.0 * correct/total))\n",
        "                print('-'*30)\n",
        "                results[fold] = 100.0 * (correct / total)\n",
        "            \n",
        "        print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS for CRITERIA{c}')\n",
        "        print('-'*30)\n",
        "        sum = 0.0\n",
        "        for key, value in results.items():\n",
        "            print(f'Fold {key} for Criteria{c}: {value} %')\n",
        "            sum += value\n",
        "        print(f'Average : {sum/len(results.items())} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "833tcTld7lS8",
        "outputId": "c03ba910-eb54-4ced-9640-68fa650474c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 1 for Criteria1\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 0.978\n",
            "Loss after epoch     1: 0.878\n",
            "Loss after epoch     2: 0.831\n",
            "Loss after epoch     3: 0.801\n",
            "Loss after epoch     4: 0.734\n",
            "Loss after epoch     5: 0.750\n",
            "Loss after epoch     6: 0.718\n",
            "Loss after epoch     7: 0.701\n",
            "Loss after epoch     8: 0.710\n",
            "Loss after epoch     9: 0.691\n",
            "Loss after epoch    10: 0.691\n",
            "Loss after epoch    11: 0.659\n",
            "Loss after epoch    12: 0.641\n",
            "Loss after epoch    13: 0.645\n",
            "Loss after epoch    14: 0.636\n",
            "Loss after epoch    15: 0.627\n",
            "Loss after epoch    16: 0.677\n",
            "Loss after epoch    17: 0.636\n",
            "Loss after epoch    18: 0.575\n",
            "Loss after epoch    19: 0.572\n",
            "Loss after epoch    20: 0.574\n",
            "Loss after epoch    21: 0.567\n",
            "Loss after epoch    22: 0.566\n",
            "Loss after epoch    23: 0.582\n",
            "Loss after epoch    24: 0.583\n",
            "Loss after epoch    25: 0.599\n",
            "Loss after epoch    26: 0.593\n",
            "Loss after epoch    27: 0.506\n",
            "Loss after epoch    28: 0.506\n",
            "Loss after epoch    29: 0.525\n",
            "Loss after epoch    30: 0.490\n",
            "Loss after epoch    31: 0.514\n",
            "Loss after epoch    32: 0.499\n",
            "Loss after epoch    33: 0.502\n",
            "Loss after epoch    34: 0.473\n",
            "Loss after epoch    35: 0.532\n",
            "Loss after epoch    36: 0.474\n",
            "Loss after epoch    37: 0.468\n",
            "Loss after epoch    38: 0.459\n",
            "Loss after epoch    39: 0.488\n",
            "Loss after epoch    40: 0.467\n",
            "Loss after epoch    41: 0.489\n",
            "Loss after epoch    42: 0.460\n",
            "Loss after epoch    43: 0.435\n",
            "Loss after epoch    44: 0.490\n",
            "Loss after epoch    45: 0.439\n",
            "Loss after epoch    46: 0.389\n",
            "Loss after epoch    47: 0.429\n",
            "Loss after epoch    48: 0.424\n",
            "Loss after epoch    49: 0.446\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 0 criteria1: 72 %\n",
            "------------------------------\n",
            "FOLD 2 for Criteria1\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 0.969\n",
            "Loss after epoch     1: 0.885\n",
            "Loss after epoch     2: 0.818\n",
            "Loss after epoch     3: 0.786\n",
            "Loss after epoch     4: 0.773\n",
            "Loss after epoch     5: 0.751\n",
            "Loss after epoch     6: 0.747\n",
            "Loss after epoch     7: 0.727\n",
            "Loss after epoch     8: 0.698\n",
            "Loss after epoch     9: 0.696\n",
            "Loss after epoch    10: 0.701\n",
            "Loss after epoch    11: 0.649\n",
            "Loss after epoch    12: 0.648\n",
            "Loss after epoch    13: 0.649\n",
            "Loss after epoch    14: 0.612\n",
            "Loss after epoch    15: 0.635\n",
            "Loss after epoch    16: 0.609\n",
            "Loss after epoch    17: 0.614\n",
            "Loss after epoch    18: 0.605\n",
            "Loss after epoch    19: 0.596\n",
            "Loss after epoch    20: 0.609\n",
            "Loss after epoch    21: 0.593\n",
            "Loss after epoch    22: 0.548\n",
            "Loss after epoch    23: 0.574\n",
            "Loss after epoch    24: 0.579\n",
            "Loss after epoch    25: 0.523\n",
            "Loss after epoch    26: 0.520\n",
            "Loss after epoch    27: 0.501\n",
            "Loss after epoch    28: 0.510\n",
            "Loss after epoch    29: 0.477\n",
            "Loss after epoch    30: 0.478\n",
            "Loss after epoch    31: 0.468\n",
            "Loss after epoch    32: 0.471\n",
            "Loss after epoch    33: 0.436\n",
            "Loss after epoch    34: 0.457\n",
            "Loss after epoch    35: 0.458\n",
            "Loss after epoch    36: 0.531\n",
            "Loss after epoch    37: 0.470\n",
            "Loss after epoch    38: 0.466\n",
            "Loss after epoch    39: 0.491\n",
            "Loss after epoch    40: 0.466\n",
            "Loss after epoch    41: 0.433\n",
            "Loss after epoch    42: 0.425\n",
            "Loss after epoch    43: 0.442\n",
            "Loss after epoch    44: 0.458\n",
            "Loss after epoch    45: 0.418\n",
            "Loss after epoch    46: 0.450\n",
            "Loss after epoch    47: 0.424\n",
            "Loss after epoch    48: 0.367\n",
            "Loss after epoch    49: 0.376\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 1 criteria1: 70 %\n",
            "------------------------------\n",
            "FOLD 3 for Criteria1\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 0.929\n",
            "Loss after epoch     1: 0.836\n",
            "Loss after epoch     2: 0.785\n",
            "Loss after epoch     3: 0.780\n",
            "Loss after epoch     4: 0.762\n",
            "Loss after epoch     5: 0.735\n",
            "Loss after epoch     6: 0.723\n",
            "Loss after epoch     7: 0.695\n",
            "Loss after epoch     8: 0.668\n",
            "Loss after epoch     9: 0.662\n",
            "Loss after epoch    10: 0.645\n",
            "Loss after epoch    11: 0.652\n",
            "Loss after epoch    12: 0.611\n",
            "Loss after epoch    13: 0.590\n",
            "Loss after epoch    14: 0.620\n",
            "Loss after epoch    15: 0.617\n",
            "Loss after epoch    16: 0.592\n",
            "Loss after epoch    17: 0.600\n",
            "Loss after epoch    18: 0.557\n",
            "Loss after epoch    19: 0.555\n",
            "Loss after epoch    20: 0.553\n",
            "Loss after epoch    21: 0.532\n",
            "Loss after epoch    22: 0.543\n",
            "Loss after epoch    23: 0.561\n",
            "Loss after epoch    24: 0.504\n",
            "Loss after epoch    25: 0.481\n",
            "Loss after epoch    26: 0.547\n",
            "Loss after epoch    27: 0.491\n",
            "Loss after epoch    28: 0.499\n",
            "Loss after epoch    29: 0.495\n",
            "Loss after epoch    30: 0.524\n",
            "Loss after epoch    31: 0.522\n",
            "Loss after epoch    32: 0.479\n",
            "Loss after epoch    33: 0.529\n",
            "Loss after epoch    34: 0.516\n",
            "Loss after epoch    35: 0.517\n",
            "Loss after epoch    36: 0.490\n",
            "Loss after epoch    37: 0.460\n",
            "Loss after epoch    38: 0.448\n",
            "Loss after epoch    39: 0.456\n",
            "Loss after epoch    40: 0.454\n",
            "Loss after epoch    41: 0.440\n",
            "Loss after epoch    42: 0.492\n",
            "Loss after epoch    43: 0.416\n",
            "Loss after epoch    44: 0.430\n",
            "Loss after epoch    45: 0.441\n",
            "Loss after epoch    46: 0.440\n",
            "Loss after epoch    47: 0.454\n",
            "Loss after epoch    48: 0.416\n",
            "Loss after epoch    49: 0.383\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 2 criteria1: 75 %\n",
            "------------------------------\n",
            "FOLD 4 for Criteria1\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.104\n",
            "Loss after epoch     1: 0.965\n",
            "Loss after epoch     2: 0.872\n",
            "Loss after epoch     3: 0.818\n",
            "Loss after epoch     4: 0.774\n",
            "Loss after epoch     5: 0.742\n",
            "Loss after epoch     6: 0.749\n",
            "Loss after epoch     7: 0.720\n",
            "Loss after epoch     8: 0.693\n",
            "Loss after epoch     9: 0.674\n",
            "Loss after epoch    10: 0.662\n",
            "Loss after epoch    11: 0.635\n",
            "Loss after epoch    12: 0.654\n",
            "Loss after epoch    13: 0.689\n",
            "Loss after epoch    14: 0.668\n",
            "Loss after epoch    15: 0.589\n",
            "Loss after epoch    16: 0.594\n",
            "Loss after epoch    17: 0.613\n",
            "Loss after epoch    18: 0.584\n",
            "Loss after epoch    19: 0.577\n",
            "Loss after epoch    20: 0.574\n",
            "Loss after epoch    21: 0.632\n",
            "Loss after epoch    22: 0.599\n",
            "Loss after epoch    23: 0.570\n",
            "Loss after epoch    24: 0.600\n",
            "Loss after epoch    25: 0.553\n",
            "Loss after epoch    26: 0.544\n",
            "Loss after epoch    27: 0.529\n",
            "Loss after epoch    28: 0.542\n",
            "Loss after epoch    29: 0.509\n",
            "Loss after epoch    30: 0.475\n",
            "Loss after epoch    31: 0.519\n",
            "Loss after epoch    32: 0.470\n",
            "Loss after epoch    33: 0.493\n",
            "Loss after epoch    34: 0.502\n",
            "Loss after epoch    35: 0.422\n",
            "Loss after epoch    36: 0.456\n",
            "Loss after epoch    37: 0.446\n",
            "Loss after epoch    38: 0.434\n",
            "Loss after epoch    39: 0.412\n",
            "Loss after epoch    40: 0.505\n",
            "Loss after epoch    41: 0.462\n",
            "Loss after epoch    42: 0.421\n",
            "Loss after epoch    43: 0.432\n",
            "Loss after epoch    44: 0.483\n",
            "Loss after epoch    45: 0.456\n",
            "Loss after epoch    46: 0.425\n",
            "Loss after epoch    47: 0.398\n",
            "Loss after epoch    48: 0.379\n",
            "Loss after epoch    49: 0.434\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 3 criteria1: 74 %\n",
            "------------------------------\n",
            "FOLD 5 for Criteria1\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.285\n",
            "Loss after epoch     1: 1.090\n",
            "Loss after epoch     2: 0.987\n",
            "Loss after epoch     3: 0.901\n",
            "Loss after epoch     4: 0.846\n",
            "Loss after epoch     5: 0.816\n",
            "Loss after epoch     6: 0.780\n",
            "Loss after epoch     7: 0.761\n",
            "Loss after epoch     8: 0.695\n",
            "Loss after epoch     9: 0.720\n",
            "Loss after epoch    10: 0.687\n",
            "Loss after epoch    11: 0.676\n",
            "Loss after epoch    12: 0.638\n",
            "Loss after epoch    13: 0.655\n",
            "Loss after epoch    14: 0.662\n",
            "Loss after epoch    15: 0.649\n",
            "Loss after epoch    16: 0.599\n",
            "Loss after epoch    17: 0.595\n",
            "Loss after epoch    18: 0.609\n",
            "Loss after epoch    19: 0.611\n",
            "Loss after epoch    20: 0.562\n",
            "Loss after epoch    21: 0.600\n",
            "Loss after epoch    22: 0.599\n",
            "Loss after epoch    23: 0.585\n",
            "Loss after epoch    24: 0.546\n",
            "Loss after epoch    25: 0.574\n",
            "Loss after epoch    26: 0.551\n",
            "Loss after epoch    27: 0.543\n",
            "Loss after epoch    28: 0.503\n",
            "Loss after epoch    29: 0.523\n",
            "Loss after epoch    30: 0.496\n",
            "Loss after epoch    31: 0.503\n",
            "Loss after epoch    32: 0.494\n",
            "Loss after epoch    33: 0.449\n",
            "Loss after epoch    34: 0.493\n",
            "Loss after epoch    35: 0.488\n",
            "Loss after epoch    36: 0.505\n",
            "Loss after epoch    37: 0.436\n",
            "Loss after epoch    38: 0.467\n",
            "Loss after epoch    39: 0.452\n",
            "Loss after epoch    40: 0.476\n",
            "Loss after epoch    41: 0.417\n",
            "Loss after epoch    42: 0.446\n",
            "Loss after epoch    43: 0.423\n",
            "Loss after epoch    44: 0.483\n",
            "Loss after epoch    45: 0.404\n",
            "Loss after epoch    46: 0.393\n",
            "Loss after epoch    47: 0.416\n",
            "Loss after epoch    48: 0.397\n",
            "Loss after epoch    49: 0.437\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 4 criteria1: 75 %\n",
            "------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS for CRITERIA1\n",
            "------------------------------\n",
            "Fold 0 for Criteria1: 72.90322580645162 %\n",
            "Fold 1 for Criteria1: 70.3225806451613 %\n",
            "Fold 2 for Criteria1: 75.97402597402598 %\n",
            "Fold 3 for Criteria1: 74.67532467532467 %\n",
            "Fold 4 for Criteria1: 75.97402597402598 %\n",
            "Average : 73.96983661499792 %\n",
            "FOLD 1 for Criteria2\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.174\n",
            "Loss after epoch     1: 1.036\n",
            "Loss after epoch     2: 0.944\n",
            "Loss after epoch     3: 0.904\n",
            "Loss after epoch     4: 0.856\n",
            "Loss after epoch     5: 0.826\n",
            "Loss after epoch     6: 0.814\n",
            "Loss after epoch     7: 0.787\n",
            "Loss after epoch     8: 0.781\n",
            "Loss after epoch     9: 0.765\n",
            "Loss after epoch    10: 0.757\n",
            "Loss after epoch    11: 0.729\n",
            "Loss after epoch    12: 0.734\n",
            "Loss after epoch    13: 0.716\n",
            "Loss after epoch    14: 0.699\n",
            "Loss after epoch    15: 0.662\n",
            "Loss after epoch    16: 0.704\n",
            "Loss after epoch    17: 0.677\n",
            "Loss after epoch    18: 0.649\n",
            "Loss after epoch    19: 0.616\n",
            "Loss after epoch    20: 0.639\n",
            "Loss after epoch    21: 0.692\n",
            "Loss after epoch    22: 0.622\n",
            "Loss after epoch    23: 0.655\n",
            "Loss after epoch    24: 0.630\n",
            "Loss after epoch    25: 0.601\n",
            "Loss after epoch    26: 0.596\n",
            "Loss after epoch    27: 0.620\n",
            "Loss after epoch    28: 0.617\n",
            "Loss after epoch    29: 0.595\n",
            "Loss after epoch    30: 0.622\n",
            "Loss after epoch    31: 0.576\n",
            "Loss after epoch    32: 0.652\n",
            "Loss after epoch    33: 0.563\n",
            "Loss after epoch    34: 0.543\n",
            "Loss after epoch    35: 0.538\n",
            "Loss after epoch    36: 0.561\n",
            "Loss after epoch    37: 0.503\n",
            "Loss after epoch    38: 0.524\n",
            "Loss after epoch    39: 0.514\n",
            "Loss after epoch    40: 0.495\n",
            "Loss after epoch    41: 0.544\n",
            "Loss after epoch    42: 0.509\n",
            "Loss after epoch    43: 0.507\n",
            "Loss after epoch    44: 0.506\n",
            "Loss after epoch    45: 0.509\n",
            "Loss after epoch    46: 0.545\n",
            "Loss after epoch    47: 0.442\n",
            "Loss after epoch    48: 0.459\n",
            "Loss after epoch    49: 0.470\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 0 criteria2: 67 %\n",
            "------------------------------\n",
            "FOLD 2 for Criteria2\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.053\n",
            "Loss after epoch     1: 0.957\n",
            "Loss after epoch     2: 0.930\n",
            "Loss after epoch     3: 0.898\n",
            "Loss after epoch     4: 0.878\n",
            "Loss after epoch     5: 0.877\n",
            "Loss after epoch     6: 0.859\n",
            "Loss after epoch     7: 0.848\n",
            "Loss after epoch     8: 0.833\n",
            "Loss after epoch     9: 0.802\n",
            "Loss after epoch    10: 0.813\n",
            "Loss after epoch    11: 0.800\n",
            "Loss after epoch    12: 0.815\n",
            "Loss after epoch    13: 0.763\n",
            "Loss after epoch    14: 0.795\n",
            "Loss after epoch    15: 0.753\n",
            "Loss after epoch    16: 0.777\n",
            "Loss after epoch    17: 0.707\n",
            "Loss after epoch    18: 0.760\n",
            "Loss after epoch    19: 0.717\n",
            "Loss after epoch    20: 0.727\n",
            "Loss after epoch    21: 0.713\n",
            "Loss after epoch    22: 0.660\n",
            "Loss after epoch    23: 0.671\n",
            "Loss after epoch    24: 0.684\n",
            "Loss after epoch    25: 0.684\n",
            "Loss after epoch    26: 0.640\n",
            "Loss after epoch    27: 0.623\n",
            "Loss after epoch    28: 0.646\n",
            "Loss after epoch    29: 0.632\n",
            "Loss after epoch    30: 0.672\n",
            "Loss after epoch    31: 0.599\n",
            "Loss after epoch    32: 0.602\n",
            "Loss after epoch    33: 0.625\n",
            "Loss after epoch    34: 0.588\n",
            "Loss after epoch    35: 0.558\n",
            "Loss after epoch    36: 0.531\n",
            "Loss after epoch    37: 0.536\n",
            "Loss after epoch    38: 0.540\n",
            "Loss after epoch    39: 0.485\n",
            "Loss after epoch    40: 0.562\n",
            "Loss after epoch    41: 0.618\n",
            "Loss after epoch    42: 0.491\n",
            "Loss after epoch    43: 0.525\n",
            "Loss after epoch    44: 0.510\n",
            "Loss after epoch    45: 0.546\n",
            "Loss after epoch    46: 0.514\n",
            "Loss after epoch    47: 0.494\n",
            "Loss after epoch    48: 0.478\n",
            "Loss after epoch    49: 0.461\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 1 criteria2: 66 %\n",
            "------------------------------\n",
            "FOLD 3 for Criteria2\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.042\n",
            "Loss after epoch     1: 0.962\n",
            "Loss after epoch     2: 0.916\n",
            "Loss after epoch     3: 0.878\n",
            "Loss after epoch     4: 0.855\n",
            "Loss after epoch     5: 0.845\n",
            "Loss after epoch     6: 0.821\n",
            "Loss after epoch     7: 0.792\n",
            "Loss after epoch     8: 0.796\n",
            "Loss after epoch     9: 0.761\n",
            "Loss after epoch    10: 0.768\n",
            "Loss after epoch    11: 0.751\n",
            "Loss after epoch    12: 0.711\n",
            "Loss after epoch    13: 0.712\n",
            "Loss after epoch    14: 0.687\n",
            "Loss after epoch    15: 0.674\n",
            "Loss after epoch    16: 0.677\n",
            "Loss after epoch    17: 0.675\n",
            "Loss after epoch    18: 0.648\n",
            "Loss after epoch    19: 0.626\n",
            "Loss after epoch    20: 0.652\n",
            "Loss after epoch    21: 0.631\n",
            "Loss after epoch    22: 0.564\n",
            "Loss after epoch    23: 0.615\n",
            "Loss after epoch    24: 0.608\n",
            "Loss after epoch    25: 0.617\n",
            "Loss after epoch    26: 0.587\n",
            "Loss after epoch    27: 0.616\n",
            "Loss after epoch    28: 0.564\n",
            "Loss after epoch    29: 0.571\n",
            "Loss after epoch    30: 0.585\n",
            "Loss after epoch    31: 0.608\n",
            "Loss after epoch    32: 0.554\n",
            "Loss after epoch    33: 0.579\n",
            "Loss after epoch    34: 0.549\n",
            "Loss after epoch    35: 0.545\n",
            "Loss after epoch    36: 0.516\n",
            "Loss after epoch    37: 0.493\n",
            "Loss after epoch    38: 0.505\n",
            "Loss after epoch    39: 0.546\n",
            "Loss after epoch    40: 0.490\n",
            "Loss after epoch    41: 0.464\n",
            "Loss after epoch    42: 0.495\n",
            "Loss after epoch    43: 0.454\n",
            "Loss after epoch    44: 0.461\n",
            "Loss after epoch    45: 0.487\n",
            "Loss after epoch    46: 0.470\n",
            "Loss after epoch    47: 0.471\n",
            "Loss after epoch    48: 0.432\n",
            "Loss after epoch    49: 0.423\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 2 criteria2: 72 %\n",
            "------------------------------\n",
            "FOLD 4 for Criteria2\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.062\n",
            "Loss after epoch     1: 0.995\n",
            "Loss after epoch     2: 0.953\n",
            "Loss after epoch     3: 0.902\n",
            "Loss after epoch     4: 0.892\n",
            "Loss after epoch     5: 0.854\n",
            "Loss after epoch     6: 0.839\n",
            "Loss after epoch     7: 0.796\n",
            "Loss after epoch     8: 0.797\n",
            "Loss after epoch     9: 0.783\n",
            "Loss after epoch    10: 0.808\n",
            "Loss after epoch    11: 0.781\n",
            "Loss after epoch    12: 0.788\n",
            "Loss after epoch    13: 0.785\n",
            "Loss after epoch    14: 0.743\n",
            "Loss after epoch    15: 0.740\n",
            "Loss after epoch    16: 0.741\n",
            "Loss after epoch    17: 0.719\n",
            "Loss after epoch    18: 0.723\n",
            "Loss after epoch    19: 0.699\n",
            "Loss after epoch    20: 0.673\n",
            "Loss after epoch    21: 0.709\n",
            "Loss after epoch    22: 0.714\n",
            "Loss after epoch    23: 0.688\n",
            "Loss after epoch    24: 0.702\n",
            "Loss after epoch    25: 0.708\n",
            "Loss after epoch    26: 0.714\n",
            "Loss after epoch    27: 0.671\n",
            "Loss after epoch    28: 0.667\n",
            "Loss after epoch    29: 0.663\n",
            "Loss after epoch    30: 0.616\n",
            "Loss after epoch    31: 0.626\n",
            "Loss after epoch    32: 0.633\n",
            "Loss after epoch    33: 0.634\n",
            "Loss after epoch    34: 0.569\n",
            "Loss after epoch    35: 0.586\n",
            "Loss after epoch    36: 0.653\n",
            "Loss after epoch    37: 0.640\n",
            "Loss after epoch    38: 0.594\n",
            "Loss after epoch    39: 0.623\n",
            "Loss after epoch    40: 0.587\n",
            "Loss after epoch    41: 0.590\n",
            "Loss after epoch    42: 0.582\n",
            "Loss after epoch    43: 0.603\n",
            "Loss after epoch    44: 0.540\n",
            "Loss after epoch    45: 0.566\n",
            "Loss after epoch    46: 0.506\n",
            "Loss after epoch    47: 0.556\n",
            "Loss after epoch    48: 0.522\n",
            "Loss after epoch    49: 0.545\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 3 criteria2: 71 %\n",
            "------------------------------\n",
            "FOLD 5 for Criteria2\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.046\n",
            "Loss after epoch     1: 0.993\n",
            "Loss after epoch     2: 0.952\n",
            "Loss after epoch     3: 0.913\n",
            "Loss after epoch     4: 0.884\n",
            "Loss after epoch     5: 0.881\n",
            "Loss after epoch     6: 0.839\n",
            "Loss after epoch     7: 0.814\n",
            "Loss after epoch     8: 0.844\n",
            "Loss after epoch     9: 0.805\n",
            "Loss after epoch    10: 0.780\n",
            "Loss after epoch    11: 0.780\n",
            "Loss after epoch    12: 0.801\n",
            "Loss after epoch    13: 0.777\n",
            "Loss after epoch    14: 0.767\n",
            "Loss after epoch    15: 0.752\n",
            "Loss after epoch    16: 0.743\n",
            "Loss after epoch    17: 0.713\n",
            "Loss after epoch    18: 0.725\n",
            "Loss after epoch    19: 0.726\n",
            "Loss after epoch    20: 0.693\n",
            "Loss after epoch    21: 0.700\n",
            "Loss after epoch    22: 0.679\n",
            "Loss after epoch    23: 0.673\n",
            "Loss after epoch    24: 0.679\n",
            "Loss after epoch    25: 0.632\n",
            "Loss after epoch    26: 0.653\n",
            "Loss after epoch    27: 0.614\n",
            "Loss after epoch    28: 0.626\n",
            "Loss after epoch    29: 0.596\n",
            "Loss after epoch    30: 0.613\n",
            "Loss after epoch    31: 0.610\n",
            "Loss after epoch    32: 0.537\n",
            "Loss after epoch    33: 0.536\n",
            "Loss after epoch    34: 0.595\n",
            "Loss after epoch    35: 0.566\n",
            "Loss after epoch    36: 0.525\n",
            "Loss after epoch    37: 0.493\n",
            "Loss after epoch    38: 0.570\n",
            "Loss after epoch    39: 0.504\n",
            "Loss after epoch    40: 0.534\n",
            "Loss after epoch    41: 0.551\n",
            "Loss after epoch    42: 0.564\n",
            "Loss after epoch    43: 0.504\n",
            "Loss after epoch    44: 0.484\n",
            "Loss after epoch    45: 0.486\n",
            "Loss after epoch    46: 0.507\n",
            "Loss after epoch    47: 0.470\n",
            "Loss after epoch    48: 0.449\n",
            "Loss after epoch    49: 0.477\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 4 criteria2: 78 %\n",
            "------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS for CRITERIA2\n",
            "------------------------------\n",
            "Fold 0 for Criteria2: 67.0967741935484 %\n",
            "Fold 1 for Criteria2: 66.45161290322581 %\n",
            "Fold 2 for Criteria2: 72.07792207792207 %\n",
            "Fold 3 for Criteria2: 71.42857142857143 %\n",
            "Fold 4 for Criteria2: 78.57142857142857 %\n",
            "Average : 71.12526183493925 %\n",
            "FOLD 1 for Criteria3\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.066\n",
            "Loss after epoch     1: 1.006\n",
            "Loss after epoch     2: 0.985\n",
            "Loss after epoch     3: 0.991\n",
            "Loss after epoch     4: 0.968\n",
            "Loss after epoch     5: 0.939\n",
            "Loss after epoch     6: 0.925\n",
            "Loss after epoch     7: 0.932\n",
            "Loss after epoch     8: 0.867\n",
            "Loss after epoch     9: 0.869\n",
            "Loss after epoch    10: 0.845\n",
            "Loss after epoch    11: 0.863\n",
            "Loss after epoch    12: 0.854\n",
            "Loss after epoch    13: 0.811\n",
            "Loss after epoch    14: 0.825\n",
            "Loss after epoch    15: 0.821\n",
            "Loss after epoch    16: 0.791\n",
            "Loss after epoch    17: 0.768\n",
            "Loss after epoch    18: 0.745\n",
            "Loss after epoch    19: 0.762\n",
            "Loss after epoch    20: 0.744\n",
            "Loss after epoch    21: 0.736\n",
            "Loss after epoch    22: 0.740\n",
            "Loss after epoch    23: 0.732\n",
            "Loss after epoch    24: 0.717\n",
            "Loss after epoch    25: 0.679\n",
            "Loss after epoch    26: 0.636\n",
            "Loss after epoch    27: 0.665\n",
            "Loss after epoch    28: 0.614\n",
            "Loss after epoch    29: 0.594\n",
            "Loss after epoch    30: 0.618\n",
            "Loss after epoch    31: 0.632\n",
            "Loss after epoch    32: 0.627\n",
            "Loss after epoch    33: 0.672\n",
            "Loss after epoch    34: 0.626\n",
            "Loss after epoch    35: 0.626\n",
            "Loss after epoch    36: 0.581\n",
            "Loss after epoch    37: 0.645\n",
            "Loss after epoch    38: 0.608\n",
            "Loss after epoch    39: 0.644\n",
            "Loss after epoch    40: 0.585\n",
            "Loss after epoch    41: 0.551\n",
            "Loss after epoch    42: 0.550\n",
            "Loss after epoch    43: 0.547\n",
            "Loss after epoch    44: 0.578\n",
            "Loss after epoch    45: 0.509\n",
            "Loss after epoch    46: 0.522\n",
            "Loss after epoch    47: 0.517\n",
            "Loss after epoch    48: 0.502\n",
            "Loss after epoch    49: 0.484\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 0 criteria3: 61 %\n",
            "------------------------------\n",
            "FOLD 2 for Criteria3\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.106\n",
            "Loss after epoch     1: 1.037\n",
            "Loss after epoch     2: 0.991\n",
            "Loss after epoch     3: 0.971\n",
            "Loss after epoch     4: 0.919\n",
            "Loss after epoch     5: 0.898\n",
            "Loss after epoch     6: 0.872\n",
            "Loss after epoch     7: 0.845\n",
            "Loss after epoch     8: 0.844\n",
            "Loss after epoch     9: 0.822\n",
            "Loss after epoch    10: 0.799\n",
            "Loss after epoch    11: 0.829\n",
            "Loss after epoch    12: 0.813\n",
            "Loss after epoch    13: 0.790\n",
            "Loss after epoch    14: 0.723\n",
            "Loss after epoch    15: 0.759\n",
            "Loss after epoch    16: 0.723\n",
            "Loss after epoch    17: 0.735\n",
            "Loss after epoch    18: 0.653\n",
            "Loss after epoch    19: 0.708\n",
            "Loss after epoch    20: 0.711\n",
            "Loss after epoch    21: 0.685\n",
            "Loss after epoch    22: 0.667\n",
            "Loss after epoch    23: 0.658\n",
            "Loss after epoch    24: 0.706\n",
            "Loss after epoch    25: 0.646\n",
            "Loss after epoch    26: 0.628\n",
            "Loss after epoch    27: 0.647\n",
            "Loss after epoch    28: 0.681\n",
            "Loss after epoch    29: 0.643\n",
            "Loss after epoch    30: 0.646\n",
            "Loss after epoch    31: 0.649\n",
            "Loss after epoch    32: 0.599\n",
            "Loss after epoch    33: 0.599\n",
            "Loss after epoch    34: 0.619\n",
            "Loss after epoch    35: 0.624\n",
            "Loss after epoch    36: 0.550\n",
            "Loss after epoch    37: 0.543\n",
            "Loss after epoch    38: 0.517\n",
            "Loss after epoch    39: 0.524\n",
            "Loss after epoch    40: 0.511\n",
            "Loss after epoch    41: 0.543\n",
            "Loss after epoch    42: 0.554\n",
            "Loss after epoch    43: 0.535\n",
            "Loss after epoch    44: 0.514\n",
            "Loss after epoch    45: 0.507\n",
            "Loss after epoch    46: 0.531\n",
            "Loss after epoch    47: 0.488\n",
            "Loss after epoch    48: 0.499\n",
            "Loss after epoch    49: 0.486\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 1 criteria3: 77 %\n",
            "------------------------------\n",
            "FOLD 3 for Criteria3\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.068\n",
            "Loss after epoch     1: 1.017\n",
            "Loss after epoch     2: 0.998\n",
            "Loss after epoch     3: 0.954\n",
            "Loss after epoch     4: 0.938\n",
            "Loss after epoch     5: 0.924\n",
            "Loss after epoch     6: 0.888\n",
            "Loss after epoch     7: 0.867\n",
            "Loss after epoch     8: 0.851\n",
            "Loss after epoch     9: 0.853\n",
            "Loss after epoch    10: 0.832\n",
            "Loss after epoch    11: 0.787\n",
            "Loss after epoch    12: 0.753\n",
            "Loss after epoch    13: 0.778\n",
            "Loss after epoch    14: 0.820\n",
            "Loss after epoch    15: 0.731\n",
            "Loss after epoch    16: 0.750\n",
            "Loss after epoch    17: 0.759\n",
            "Loss after epoch    18: 0.727\n",
            "Loss after epoch    19: 0.644\n",
            "Loss after epoch    20: 0.670\n",
            "Loss after epoch    21: 0.677\n",
            "Loss after epoch    22: 0.702\n",
            "Loss after epoch    23: 0.681\n",
            "Loss after epoch    24: 0.686\n",
            "Loss after epoch    25: 0.635\n",
            "Loss after epoch    26: 0.669\n",
            "Loss after epoch    27: 0.651\n",
            "Loss after epoch    28: 0.654\n",
            "Loss after epoch    29: 0.671\n",
            "Loss after epoch    30: 0.661\n",
            "Loss after epoch    31: 0.639\n",
            "Loss after epoch    32: 0.639\n",
            "Loss after epoch    33: 0.543\n",
            "Loss after epoch    34: 0.572\n",
            "Loss after epoch    35: 0.525\n",
            "Loss after epoch    36: 0.538\n",
            "Loss after epoch    37: 0.555\n",
            "Loss after epoch    38: 0.548\n",
            "Loss after epoch    39: 0.531\n",
            "Loss after epoch    40: 0.528\n",
            "Loss after epoch    41: 0.519\n",
            "Loss after epoch    42: 0.510\n",
            "Loss after epoch    43: 0.537\n",
            "Loss after epoch    44: 0.476\n",
            "Loss after epoch    45: 0.489\n",
            "Loss after epoch    46: 0.540\n",
            "Loss after epoch    47: 0.480\n",
            "Loss after epoch    48: 0.502\n",
            "Loss after epoch    49: 0.494\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 2 criteria3: 68 %\n",
            "------------------------------\n",
            "FOLD 4 for Criteria3\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.093\n",
            "Loss after epoch     1: 1.039\n",
            "Loss after epoch     2: 0.985\n",
            "Loss after epoch     3: 0.970\n",
            "Loss after epoch     4: 0.931\n",
            "Loss after epoch     5: 0.907\n",
            "Loss after epoch     6: 0.921\n",
            "Loss after epoch     7: 0.900\n",
            "Loss after epoch     8: 0.854\n",
            "Loss after epoch     9: 0.828\n",
            "Loss after epoch    10: 0.835\n",
            "Loss after epoch    11: 0.795\n",
            "Loss after epoch    12: 0.796\n",
            "Loss after epoch    13: 0.827\n",
            "Loss after epoch    14: 0.829\n",
            "Loss after epoch    15: 0.820\n",
            "Loss after epoch    16: 0.777\n",
            "Loss after epoch    17: 0.765\n",
            "Loss after epoch    18: 0.737\n",
            "Loss after epoch    19: 0.711\n",
            "Loss after epoch    20: 0.765\n",
            "Loss after epoch    21: 0.719\n",
            "Loss after epoch    22: 0.687\n",
            "Loss after epoch    23: 0.697\n",
            "Loss after epoch    24: 0.728\n",
            "Loss after epoch    25: 0.697\n",
            "Loss after epoch    26: 0.664\n",
            "Loss after epoch    27: 0.672\n",
            "Loss after epoch    28: 0.686\n",
            "Loss after epoch    29: 0.645\n",
            "Loss after epoch    30: 0.604\n",
            "Loss after epoch    31: 0.615\n",
            "Loss after epoch    32: 0.625\n",
            "Loss after epoch    33: 0.620\n",
            "Loss after epoch    34: 0.595\n",
            "Loss after epoch    35: 0.590\n",
            "Loss after epoch    36: 0.622\n",
            "Loss after epoch    37: 0.580\n",
            "Loss after epoch    38: 0.580\n",
            "Loss after epoch    39: 0.561\n",
            "Loss after epoch    40: 0.559\n",
            "Loss after epoch    41: 0.534\n",
            "Loss after epoch    42: 0.580\n",
            "Loss after epoch    43: 0.558\n",
            "Loss after epoch    44: 0.517\n",
            "Loss after epoch    45: 0.524\n",
            "Loss after epoch    46: 0.547\n",
            "Loss after epoch    47: 0.512\n",
            "Loss after epoch    48: 0.483\n",
            "Loss after epoch    49: 0.471\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 3 criteria3: 61 %\n",
            "------------------------------\n",
            "FOLD 5 for Criteria3\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.092\n",
            "Loss after epoch     1: 1.040\n",
            "Loss after epoch     2: 1.009\n",
            "Loss after epoch     3: 0.978\n",
            "Loss after epoch     4: 0.983\n",
            "Loss after epoch     5: 0.952\n",
            "Loss after epoch     6: 0.955\n",
            "Loss after epoch     7: 0.949\n",
            "Loss after epoch     8: 0.919\n",
            "Loss after epoch     9: 0.919\n",
            "Loss after epoch    10: 0.875\n",
            "Loss after epoch    11: 0.857\n",
            "Loss after epoch    12: 0.869\n",
            "Loss after epoch    13: 0.849\n",
            "Loss after epoch    14: 0.816\n",
            "Loss after epoch    15: 0.814\n",
            "Loss after epoch    16: 0.802\n",
            "Loss after epoch    17: 0.750\n",
            "Loss after epoch    18: 0.756\n",
            "Loss after epoch    19: 0.757\n",
            "Loss after epoch    20: 0.795\n",
            "Loss after epoch    21: 0.727\n",
            "Loss after epoch    22: 0.733\n",
            "Loss after epoch    23: 0.771\n",
            "Loss after epoch    24: 0.734\n",
            "Loss after epoch    25: 0.723\n",
            "Loss after epoch    26: 0.719\n",
            "Loss after epoch    27: 0.726\n",
            "Loss after epoch    28: 0.702\n",
            "Loss after epoch    29: 0.738\n",
            "Loss after epoch    30: 0.708\n",
            "Loss after epoch    31: 0.707\n",
            "Loss after epoch    32: 0.684\n",
            "Loss after epoch    33: 0.660\n",
            "Loss after epoch    34: 0.614\n",
            "Loss after epoch    35: 0.616\n",
            "Loss after epoch    36: 0.635\n",
            "Loss after epoch    37: 0.663\n",
            "Loss after epoch    38: 0.571\n",
            "Loss after epoch    39: 0.590\n",
            "Loss after epoch    40: 0.634\n",
            "Loss after epoch    41: 0.623\n",
            "Loss after epoch    42: 0.588\n",
            "Loss after epoch    43: 0.632\n",
            "Loss after epoch    44: 0.585\n",
            "Loss after epoch    45: 0.625\n",
            "Loss after epoch    46: 0.560\n",
            "Loss after epoch    47: 0.539\n",
            "Loss after epoch    48: 0.557\n",
            "Loss after epoch    49: 0.549\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 4 criteria3: 71 %\n",
            "------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS for CRITERIA3\n",
            "------------------------------\n",
            "Fold 0 for Criteria3: 61.29032258064516 %\n",
            "Fold 1 for Criteria3: 77.41935483870968 %\n",
            "Fold 2 for Criteria3: 68.18181818181817 %\n",
            "Fold 3 for Criteria3: 61.68831168831169 %\n",
            "Fold 4 for Criteria3: 71.42857142857143 %\n",
            "Average : 68.00167574361123 %\n",
            "FOLD 1 for Criteria4\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.003\n",
            "Loss after epoch     1: 0.881\n",
            "Loss after epoch     2: 0.806\n",
            "Loss after epoch     3: 0.786\n",
            "Loss after epoch     4: 0.768\n",
            "Loss after epoch     5: 0.735\n",
            "Loss after epoch     6: 0.699\n",
            "Loss after epoch     7: 0.661\n",
            "Loss after epoch     8: 0.662\n",
            "Loss after epoch     9: 0.659\n",
            "Loss after epoch    10: 0.613\n",
            "Loss after epoch    11: 0.616\n",
            "Loss after epoch    12: 0.659\n",
            "Loss after epoch    13: 0.625\n",
            "Loss after epoch    14: 0.612\n",
            "Loss after epoch    15: 0.590\n",
            "Loss after epoch    16: 0.597\n",
            "Loss after epoch    17: 0.626\n",
            "Loss after epoch    18: 0.555\n",
            "Loss after epoch    19: 0.565\n",
            "Loss after epoch    20: 0.608\n",
            "Loss after epoch    21: 0.584\n",
            "Loss after epoch    22: 0.554\n",
            "Loss after epoch    23: 0.571\n",
            "Loss after epoch    24: 0.549\n",
            "Loss after epoch    25: 0.507\n",
            "Loss after epoch    26: 0.546\n",
            "Loss after epoch    27: 0.505\n",
            "Loss after epoch    28: 0.541\n",
            "Loss after epoch    29: 0.505\n",
            "Loss after epoch    30: 0.522\n",
            "Loss after epoch    31: 0.510\n",
            "Loss after epoch    32: 0.487\n",
            "Loss after epoch    33: 0.450\n",
            "Loss after epoch    34: 0.508\n",
            "Loss after epoch    35: 0.463\n",
            "Loss after epoch    36: 0.470\n",
            "Loss after epoch    37: 0.481\n",
            "Loss after epoch    38: 0.477\n",
            "Loss after epoch    39: 0.438\n",
            "Loss after epoch    40: 0.467\n",
            "Loss after epoch    41: 0.429\n",
            "Loss after epoch    42: 0.480\n",
            "Loss after epoch    43: 0.478\n",
            "Loss after epoch    44: 0.477\n",
            "Loss after epoch    45: 0.421\n",
            "Loss after epoch    46: 0.453\n",
            "Loss after epoch    47: 0.386\n",
            "Loss after epoch    48: 0.383\n",
            "Loss after epoch    49: 0.380\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 0 criteria4: 73 %\n",
            "------------------------------\n",
            "FOLD 2 for Criteria4\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 0.928\n",
            "Loss after epoch     1: 0.821\n",
            "Loss after epoch     2: 0.764\n",
            "Loss after epoch     3: 0.760\n",
            "Loss after epoch     4: 0.741\n",
            "Loss after epoch     5: 0.718\n",
            "Loss after epoch     6: 0.703\n",
            "Loss after epoch     7: 0.689\n",
            "Loss after epoch     8: 0.684\n",
            "Loss after epoch     9: 0.656\n",
            "Loss after epoch    10: 0.674\n",
            "Loss after epoch    11: 0.673\n",
            "Loss after epoch    12: 0.668\n",
            "Loss after epoch    13: 0.624\n",
            "Loss after epoch    14: 0.619\n",
            "Loss after epoch    15: 0.666\n",
            "Loss after epoch    16: 0.611\n",
            "Loss after epoch    17: 0.573\n",
            "Loss after epoch    18: 0.571\n",
            "Loss after epoch    19: 0.618\n",
            "Loss after epoch    20: 0.601\n",
            "Loss after epoch    21: 0.575\n",
            "Loss after epoch    22: 0.554\n",
            "Loss after epoch    23: 0.541\n",
            "Loss after epoch    24: 0.551\n",
            "Loss after epoch    25: 0.546\n",
            "Loss after epoch    26: 0.508\n",
            "Loss after epoch    27: 0.487\n",
            "Loss after epoch    28: 0.531\n",
            "Loss after epoch    29: 0.576\n",
            "Loss after epoch    30: 0.505\n",
            "Loss after epoch    31: 0.517\n",
            "Loss after epoch    32: 0.483\n",
            "Loss after epoch    33: 0.543\n",
            "Loss after epoch    34: 0.534\n",
            "Loss after epoch    35: 0.494\n",
            "Loss after epoch    36: 0.521\n",
            "Loss after epoch    37: 0.498\n",
            "Loss after epoch    38: 0.438\n",
            "Loss after epoch    39: 0.465\n",
            "Loss after epoch    40: 0.444\n",
            "Loss after epoch    41: 0.470\n",
            "Loss after epoch    42: 0.431\n",
            "Loss after epoch    43: 0.442\n",
            "Loss after epoch    44: 0.454\n",
            "Loss after epoch    45: 0.439\n",
            "Loss after epoch    46: 0.458\n",
            "Loss after epoch    47: 0.411\n",
            "Loss after epoch    48: 0.431\n",
            "Loss after epoch    49: 0.429\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 1 criteria4: 70 %\n",
            "------------------------------\n",
            "FOLD 3 for Criteria4\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.026\n",
            "Loss after epoch     1: 0.908\n",
            "Loss after epoch     2: 0.855\n",
            "Loss after epoch     3: 0.805\n",
            "Loss after epoch     4: 0.763\n",
            "Loss after epoch     5: 0.749\n",
            "Loss after epoch     6: 0.715\n",
            "Loss after epoch     7: 0.699\n",
            "Loss after epoch     8: 0.702\n",
            "Loss after epoch     9: 0.689\n",
            "Loss after epoch    10: 0.650\n",
            "Loss after epoch    11: 0.641\n",
            "Loss after epoch    12: 0.634\n",
            "Loss after epoch    13: 0.606\n",
            "Loss after epoch    14: 0.580\n",
            "Loss after epoch    15: 0.602\n",
            "Loss after epoch    16: 0.560\n",
            "Loss after epoch    17: 0.558\n",
            "Loss after epoch    18: 0.608\n",
            "Loss after epoch    19: 0.609\n",
            "Loss after epoch    20: 0.573\n",
            "Loss after epoch    21: 0.575\n",
            "Loss after epoch    22: 0.546\n",
            "Loss after epoch    23: 0.564\n",
            "Loss after epoch    24: 0.487\n",
            "Loss after epoch    25: 0.531\n",
            "Loss after epoch    26: 0.500\n",
            "Loss after epoch    27: 0.504\n",
            "Loss after epoch    28: 0.511\n",
            "Loss after epoch    29: 0.515\n",
            "Loss after epoch    30: 0.464\n",
            "Loss after epoch    31: 0.507\n",
            "Loss after epoch    32: 0.467\n",
            "Loss after epoch    33: 0.482\n",
            "Loss after epoch    34: 0.446\n",
            "Loss after epoch    35: 0.458\n",
            "Loss after epoch    36: 0.438\n",
            "Loss after epoch    37: 0.453\n",
            "Loss after epoch    38: 0.416\n",
            "Loss after epoch    39: 0.465\n",
            "Loss after epoch    40: 0.440\n",
            "Loss after epoch    41: 0.418\n",
            "Loss after epoch    42: 0.416\n",
            "Loss after epoch    43: 0.422\n",
            "Loss after epoch    44: 0.401\n",
            "Loss after epoch    45: 0.377\n",
            "Loss after epoch    46: 0.381\n",
            "Loss after epoch    47: 0.385\n",
            "Loss after epoch    48: 0.417\n",
            "Loss after epoch    49: 0.364\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 2 criteria4: 77 %\n",
            "------------------------------\n",
            "FOLD 4 for Criteria4\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.052\n",
            "Loss after epoch     1: 0.937\n",
            "Loss after epoch     2: 0.850\n",
            "Loss after epoch     3: 0.806\n",
            "Loss after epoch     4: 0.793\n",
            "Loss after epoch     5: 0.749\n",
            "Loss after epoch     6: 0.754\n",
            "Loss after epoch     7: 0.721\n",
            "Loss after epoch     8: 0.722\n",
            "Loss after epoch     9: 0.707\n",
            "Loss after epoch    10: 0.670\n",
            "Loss after epoch    11: 0.677\n",
            "Loss after epoch    12: 0.666\n",
            "Loss after epoch    13: 0.663\n",
            "Loss after epoch    14: 0.674\n",
            "Loss after epoch    15: 0.632\n",
            "Loss after epoch    16: 0.627\n",
            "Loss after epoch    17: 0.607\n",
            "Loss after epoch    18: 0.601\n",
            "Loss after epoch    19: 0.623\n",
            "Loss after epoch    20: 0.628\n",
            "Loss after epoch    21: 0.616\n",
            "Loss after epoch    22: 0.568\n",
            "Loss after epoch    23: 0.581\n",
            "Loss after epoch    24: 0.571\n",
            "Loss after epoch    25: 0.532\n",
            "Loss after epoch    26: 0.563\n",
            "Loss after epoch    27: 0.529\n",
            "Loss after epoch    28: 0.541\n",
            "Loss after epoch    29: 0.579\n",
            "Loss after epoch    30: 0.541\n",
            "Loss after epoch    31: 0.570\n",
            "Loss after epoch    32: 0.525\n",
            "Loss after epoch    33: 0.484\n",
            "Loss after epoch    34: 0.530\n",
            "Loss after epoch    35: 0.489\n",
            "Loss after epoch    36: 0.471\n",
            "Loss after epoch    37: 0.539\n",
            "Loss after epoch    38: 0.537\n",
            "Loss after epoch    39: 0.472\n",
            "Loss after epoch    40: 0.476\n",
            "Loss after epoch    41: 0.446\n",
            "Loss after epoch    42: 0.462\n",
            "Loss after epoch    43: 0.415\n",
            "Loss after epoch    44: 0.448\n",
            "Loss after epoch    45: 0.509\n",
            "Loss after epoch    46: 0.413\n",
            "Loss after epoch    47: 0.438\n",
            "Loss after epoch    48: 0.454\n",
            "Loss after epoch    49: 0.417\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 3 criteria4: 79 %\n",
            "------------------------------\n",
            "FOLD 5 for Criteria4\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.000\n",
            "Loss after epoch     1: 0.873\n",
            "Loss after epoch     2: 0.809\n",
            "Loss after epoch     3: 0.770\n",
            "Loss after epoch     4: 0.717\n",
            "Loss after epoch     5: 0.746\n",
            "Loss after epoch     6: 0.720\n",
            "Loss after epoch     7: 0.697\n",
            "Loss after epoch     8: 0.680\n",
            "Loss after epoch     9: 0.646\n",
            "Loss after epoch    10: 0.635\n",
            "Loss after epoch    11: 0.650\n",
            "Loss after epoch    12: 0.649\n",
            "Loss after epoch    13: 0.608\n",
            "Loss after epoch    14: 0.639\n",
            "Loss after epoch    15: 0.615\n",
            "Loss after epoch    16: 0.611\n",
            "Loss after epoch    17: 0.584\n",
            "Loss after epoch    18: 0.543\n",
            "Loss after epoch    19: 0.557\n",
            "Loss after epoch    20: 0.560\n",
            "Loss after epoch    21: 0.599\n",
            "Loss after epoch    22: 0.586\n",
            "Loss after epoch    23: 0.538\n",
            "Loss after epoch    24: 0.583\n",
            "Loss after epoch    25: 0.564\n",
            "Loss after epoch    26: 0.575\n",
            "Loss after epoch    27: 0.531\n",
            "Loss after epoch    28: 0.544\n",
            "Loss after epoch    29: 0.483\n",
            "Loss after epoch    30: 0.522\n",
            "Loss after epoch    31: 0.496\n",
            "Loss after epoch    32: 0.506\n",
            "Loss after epoch    33: 0.482\n",
            "Loss after epoch    34: 0.489\n",
            "Loss after epoch    35: 0.524\n",
            "Loss after epoch    36: 0.490\n",
            "Loss after epoch    37: 0.498\n",
            "Loss after epoch    38: 0.481\n",
            "Loss after epoch    39: 0.499\n",
            "Loss after epoch    40: 0.497\n",
            "Loss after epoch    41: 0.449\n",
            "Loss after epoch    42: 0.413\n",
            "Loss after epoch    43: 0.451\n",
            "Loss after epoch    44: 0.433\n",
            "Loss after epoch    45: 0.471\n",
            "Loss after epoch    46: 0.453\n",
            "Loss after epoch    47: 0.412\n",
            "Loss after epoch    48: 0.421\n",
            "Loss after epoch    49: 0.378\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 4 criteria4: 74 %\n",
            "------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS for CRITERIA4\n",
            "------------------------------\n",
            "Fold 0 for Criteria4: 73.54838709677419 %\n",
            "Fold 1 for Criteria4: 70.3225806451613 %\n",
            "Fold 2 for Criteria4: 77.92207792207793 %\n",
            "Fold 3 for Criteria4: 79.87012987012987 %\n",
            "Fold 4 for Criteria4: 74.02597402597402 %\n",
            "Average : 75.13782991202348 %\n",
            "FOLD 1 for Criteria5\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.156\n",
            "Loss after epoch     1: 1.038\n",
            "Loss after epoch     2: 0.973\n",
            "Loss after epoch     3: 0.916\n",
            "Loss after epoch     4: 0.890\n",
            "Loss after epoch     5: 0.862\n",
            "Loss after epoch     6: 0.818\n",
            "Loss after epoch     7: 0.811\n",
            "Loss after epoch     8: 0.800\n",
            "Loss after epoch     9: 0.777\n",
            "Loss after epoch    10: 0.787\n",
            "Loss after epoch    11: 0.773\n",
            "Loss after epoch    12: 0.732\n",
            "Loss after epoch    13: 0.754\n",
            "Loss after epoch    14: 0.770\n",
            "Loss after epoch    15: 0.738\n",
            "Loss after epoch    16: 0.692\n",
            "Loss after epoch    17: 0.671\n",
            "Loss after epoch    18: 0.702\n",
            "Loss after epoch    19: 0.650\n",
            "Loss after epoch    20: 0.642\n",
            "Loss after epoch    21: 0.655\n",
            "Loss after epoch    22: 0.654\n",
            "Loss after epoch    23: 0.651\n",
            "Loss after epoch    24: 0.658\n",
            "Loss after epoch    25: 0.645\n",
            "Loss after epoch    26: 0.630\n",
            "Loss after epoch    27: 0.651\n",
            "Loss after epoch    28: 0.599\n",
            "Loss after epoch    29: 0.598\n",
            "Loss after epoch    30: 0.625\n",
            "Loss after epoch    31: 0.627\n",
            "Loss after epoch    32: 0.574\n",
            "Loss after epoch    33: 0.600\n",
            "Loss after epoch    34: 0.520\n",
            "Loss after epoch    35: 0.546\n",
            "Loss after epoch    36: 0.553\n",
            "Loss after epoch    37: 0.528\n",
            "Loss after epoch    38: 0.514\n",
            "Loss after epoch    39: 0.493\n",
            "Loss after epoch    40: 0.559\n",
            "Loss after epoch    41: 0.611\n",
            "Loss after epoch    42: 0.494\n",
            "Loss after epoch    43: 0.469\n",
            "Loss after epoch    44: 0.480\n",
            "Loss after epoch    45: 0.500\n",
            "Loss after epoch    46: 0.535\n",
            "Loss after epoch    47: 0.511\n",
            "Loss after epoch    48: 0.516\n",
            "Loss after epoch    49: 0.517\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 0 criteria5: 70 %\n",
            "------------------------------\n",
            "FOLD 2 for Criteria5\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.035\n",
            "Loss after epoch     1: 0.961\n",
            "Loss after epoch     2: 0.924\n",
            "Loss after epoch     3: 0.888\n",
            "Loss after epoch     4: 0.881\n",
            "Loss after epoch     5: 0.881\n",
            "Loss after epoch     6: 0.829\n",
            "Loss after epoch     7: 0.790\n",
            "Loss after epoch     8: 0.776\n",
            "Loss after epoch     9: 0.764\n",
            "Loss after epoch    10: 0.747\n",
            "Loss after epoch    11: 0.750\n",
            "Loss after epoch    12: 0.727\n",
            "Loss after epoch    13: 0.691\n",
            "Loss after epoch    14: 0.710\n",
            "Loss after epoch    15: 0.671\n",
            "Loss after epoch    16: 0.672\n",
            "Loss after epoch    17: 0.703\n",
            "Loss after epoch    18: 0.631\n",
            "Loss after epoch    19: 0.678\n",
            "Loss after epoch    20: 0.701\n",
            "Loss after epoch    21: 0.640\n",
            "Loss after epoch    22: 0.617\n",
            "Loss after epoch    23: 0.632\n",
            "Loss after epoch    24: 0.656\n",
            "Loss after epoch    25: 0.602\n",
            "Loss after epoch    26: 0.591\n",
            "Loss after epoch    27: 0.616\n",
            "Loss after epoch    28: 0.549\n",
            "Loss after epoch    29: 0.584\n",
            "Loss after epoch    30: 0.541\n",
            "Loss after epoch    31: 0.555\n",
            "Loss after epoch    32: 0.519\n",
            "Loss after epoch    33: 0.475\n",
            "Loss after epoch    34: 0.492\n",
            "Loss after epoch    35: 0.460\n",
            "Loss after epoch    36: 0.496\n",
            "Loss after epoch    37: 0.495\n",
            "Loss after epoch    38: 0.434\n",
            "Loss after epoch    39: 0.494\n",
            "Loss after epoch    40: 0.490\n",
            "Loss after epoch    41: 0.516\n",
            "Loss after epoch    42: 0.514\n",
            "Loss after epoch    43: 0.401\n",
            "Loss after epoch    44: 0.481\n",
            "Loss after epoch    45: 0.537\n",
            "Loss after epoch    46: 0.498\n",
            "Loss after epoch    47: 0.457\n",
            "Loss after epoch    48: 0.418\n",
            "Loss after epoch    49: 0.411\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 1 criteria5: 72 %\n",
            "------------------------------\n",
            "FOLD 3 for Criteria5\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.010\n",
            "Loss after epoch     1: 0.926\n",
            "Loss after epoch     2: 0.909\n",
            "Loss after epoch     3: 0.885\n",
            "Loss after epoch     4: 0.861\n",
            "Loss after epoch     5: 0.824\n",
            "Loss after epoch     6: 0.809\n",
            "Loss after epoch     7: 0.775\n",
            "Loss after epoch     8: 0.745\n",
            "Loss after epoch     9: 0.718\n",
            "Loss after epoch    10: 0.740\n",
            "Loss after epoch    11: 0.753\n",
            "Loss after epoch    12: 0.707\n",
            "Loss after epoch    13: 0.664\n",
            "Loss after epoch    14: 0.671\n",
            "Loss after epoch    15: 0.703\n",
            "Loss after epoch    16: 0.699\n",
            "Loss after epoch    17: 0.675\n",
            "Loss after epoch    18: 0.667\n",
            "Loss after epoch    19: 0.655\n",
            "Loss after epoch    20: 0.616\n",
            "Loss after epoch    21: 0.651\n",
            "Loss after epoch    22: 0.651\n",
            "Loss after epoch    23: 0.640\n",
            "Loss after epoch    24: 0.641\n",
            "Loss after epoch    25: 0.608\n",
            "Loss after epoch    26: 0.576\n",
            "Loss after epoch    27: 0.611\n",
            "Loss after epoch    28: 0.560\n",
            "Loss after epoch    29: 0.577\n",
            "Loss after epoch    30: 0.583\n",
            "Loss after epoch    31: 0.568\n",
            "Loss after epoch    32: 0.552\n",
            "Loss after epoch    33: 0.536\n",
            "Loss after epoch    34: 0.511\n",
            "Loss after epoch    35: 0.528\n",
            "Loss after epoch    36: 0.494\n",
            "Loss after epoch    37: 0.528\n",
            "Loss after epoch    38: 0.476\n",
            "Loss after epoch    39: 0.511\n",
            "Loss after epoch    40: 0.543\n",
            "Loss after epoch    41: 0.527\n",
            "Loss after epoch    42: 0.510\n",
            "Loss after epoch    43: 0.494\n",
            "Loss after epoch    44: 0.508\n",
            "Loss after epoch    45: 0.552\n",
            "Loss after epoch    46: 0.548\n",
            "Loss after epoch    47: 0.507\n",
            "Loss after epoch    48: 0.465\n",
            "Loss after epoch    49: 0.490\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 2 criteria5: 64 %\n",
            "------------------------------\n",
            "FOLD 4 for Criteria5\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.079\n",
            "Loss after epoch     1: 1.004\n",
            "Loss after epoch     2: 0.963\n",
            "Loss after epoch     3: 0.918\n",
            "Loss after epoch     4: 0.911\n",
            "Loss after epoch     5: 0.884\n",
            "Loss after epoch     6: 0.895\n",
            "Loss after epoch     7: 0.880\n",
            "Loss after epoch     8: 0.852\n",
            "Loss after epoch     9: 0.825\n",
            "Loss after epoch    10: 0.799\n",
            "Loss after epoch    11: 0.783\n",
            "Loss after epoch    12: 0.764\n",
            "Loss after epoch    13: 0.774\n",
            "Loss after epoch    14: 0.766\n",
            "Loss after epoch    15: 0.725\n",
            "Loss after epoch    16: 0.710\n",
            "Loss after epoch    17: 0.718\n",
            "Loss after epoch    18: 0.673\n",
            "Loss after epoch    19: 0.710\n",
            "Loss after epoch    20: 0.660\n",
            "Loss after epoch    21: 0.642\n",
            "Loss after epoch    22: 0.680\n",
            "Loss after epoch    23: 0.646\n",
            "Loss after epoch    24: 0.627\n",
            "Loss after epoch    25: 0.649\n",
            "Loss after epoch    26: 0.626\n",
            "Loss after epoch    27: 0.635\n",
            "Loss after epoch    28: 0.646\n",
            "Loss after epoch    29: 0.662\n",
            "Loss after epoch    30: 0.619\n",
            "Loss after epoch    31: 0.603\n",
            "Loss after epoch    32: 0.585\n",
            "Loss after epoch    33: 0.612\n",
            "Loss after epoch    34: 0.607\n",
            "Loss after epoch    35: 0.557\n",
            "Loss after epoch    36: 0.531\n",
            "Loss after epoch    37: 0.563\n",
            "Loss after epoch    38: 0.597\n",
            "Loss after epoch    39: 0.548\n",
            "Loss after epoch    40: 0.526\n",
            "Loss after epoch    41: 0.562\n",
            "Loss after epoch    42: 0.416\n",
            "Loss after epoch    43: 0.542\n",
            "Loss after epoch    44: 0.538\n",
            "Loss after epoch    45: 0.505\n",
            "Loss after epoch    46: 0.507\n",
            "Loss after epoch    47: 0.462\n",
            "Loss after epoch    48: 0.487\n",
            "Loss after epoch    49: 0.440\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 3 criteria5: 73 %\n",
            "------------------------------\n",
            "FOLD 5 for Criteria5\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.044\n",
            "Loss after epoch     1: 0.966\n",
            "Loss after epoch     2: 0.920\n",
            "Loss after epoch     3: 0.882\n",
            "Loss after epoch     4: 0.860\n",
            "Loss after epoch     5: 0.826\n",
            "Loss after epoch     6: 0.816\n",
            "Loss after epoch     7: 0.815\n",
            "Loss after epoch     8: 0.795\n",
            "Loss after epoch     9: 0.755\n",
            "Loss after epoch    10: 0.744\n",
            "Loss after epoch    11: 0.746\n",
            "Loss after epoch    12: 0.729\n",
            "Loss after epoch    13: 0.765\n",
            "Loss after epoch    14: 0.729\n",
            "Loss after epoch    15: 0.760\n",
            "Loss after epoch    16: 0.716\n",
            "Loss after epoch    17: 0.671\n",
            "Loss after epoch    18: 0.682\n",
            "Loss after epoch    19: 0.662\n",
            "Loss after epoch    20: 0.691\n",
            "Loss after epoch    21: 0.659\n",
            "Loss after epoch    22: 0.619\n",
            "Loss after epoch    23: 0.613\n",
            "Loss after epoch    24: 0.612\n",
            "Loss after epoch    25: 0.611\n",
            "Loss after epoch    26: 0.567\n",
            "Loss after epoch    27: 0.602\n",
            "Loss after epoch    28: 0.499\n",
            "Loss after epoch    29: 0.547\n",
            "Loss after epoch    30: 0.517\n",
            "Loss after epoch    31: 0.538\n",
            "Loss after epoch    32: 0.553\n",
            "Loss after epoch    33: 0.485\n",
            "Loss after epoch    34: 0.468\n",
            "Loss after epoch    35: 0.562\n",
            "Loss after epoch    36: 0.493\n",
            "Loss after epoch    37: 0.462\n",
            "Loss after epoch    38: 0.455\n",
            "Loss after epoch    39: 0.425\n",
            "Loss after epoch    40: 0.510\n",
            "Loss after epoch    41: 0.490\n",
            "Loss after epoch    42: 0.559\n",
            "Loss after epoch    43: 0.472\n",
            "Loss after epoch    44: 0.449\n",
            "Loss after epoch    45: 0.436\n",
            "Loss after epoch    46: 0.473\n",
            "Loss after epoch    47: 0.525\n",
            "Loss after epoch    48: 0.474\n",
            "Loss after epoch    49: 0.418\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 4 criteria5: 72 %\n",
            "------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS for CRITERIA5\n",
            "------------------------------\n",
            "Fold 0 for Criteria5: 70.3225806451613 %\n",
            "Fold 1 for Criteria5: 72.90322580645162 %\n",
            "Fold 2 for Criteria5: 64.28571428571429 %\n",
            "Fold 3 for Criteria5: 73.37662337662337 %\n",
            "Fold 4 for Criteria5: 72.72727272727273 %\n",
            "Average : 70.72308336824467 %\n",
            "FOLD 1 for Criteria6\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 0.902\n",
            "Loss after epoch     1: 0.708\n",
            "Loss after epoch     2: 0.559\n",
            "Loss after epoch     3: 0.505\n",
            "Loss after epoch     4: 0.479\n",
            "Loss after epoch     5: 0.454\n",
            "Loss after epoch     6: 0.450\n",
            "Loss after epoch     7: 0.446\n",
            "Loss after epoch     8: 0.450\n",
            "Loss after epoch     9: 0.430\n",
            "Loss after epoch    10: 0.418\n",
            "Loss after epoch    11: 0.390\n",
            "Loss after epoch    12: 0.398\n",
            "Loss after epoch    13: 0.384\n",
            "Loss after epoch    14: 0.368\n",
            "Loss after epoch    15: 0.376\n",
            "Loss after epoch    16: 0.370\n",
            "Loss after epoch    17: 0.345\n",
            "Loss after epoch    18: 0.332\n",
            "Loss after epoch    19: 0.337\n",
            "Loss after epoch    20: 0.327\n",
            "Loss after epoch    21: 0.311\n",
            "Loss after epoch    22: 0.319\n",
            "Loss after epoch    23: 0.324\n",
            "Loss after epoch    24: 0.292\n",
            "Loss after epoch    25: 0.280\n",
            "Loss after epoch    26: 0.310\n",
            "Loss after epoch    27: 0.290\n",
            "Loss after epoch    28: 0.298\n",
            "Loss after epoch    29: 0.302\n",
            "Loss after epoch    30: 0.281\n",
            "Loss after epoch    31: 0.292\n",
            "Loss after epoch    32: 0.259\n",
            "Loss after epoch    33: 0.276\n",
            "Loss after epoch    34: 0.276\n",
            "Loss after epoch    35: 0.295\n",
            "Loss after epoch    36: 0.282\n",
            "Loss after epoch    37: 0.249\n",
            "Loss after epoch    38: 0.217\n",
            "Loss after epoch    39: 0.235\n",
            "Loss after epoch    40: 0.231\n",
            "Loss after epoch    41: 0.268\n",
            "Loss after epoch    42: 0.237\n",
            "Loss after epoch    43: 0.236\n",
            "Loss after epoch    44: 0.216\n",
            "Loss after epoch    45: 0.237\n",
            "Loss after epoch    46: 0.239\n",
            "Loss after epoch    47: 0.223\n",
            "Loss after epoch    48: 0.217\n",
            "Loss after epoch    49: 0.203\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 0 criteria6: 90 %\n",
            "------------------------------\n",
            "FOLD 2 for Criteria6\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 0.987\n",
            "Loss after epoch     1: 0.753\n",
            "Loss after epoch     2: 0.606\n",
            "Loss after epoch     3: 0.514\n",
            "Loss after epoch     4: 0.469\n",
            "Loss after epoch     5: 0.457\n",
            "Loss after epoch     6: 0.438\n",
            "Loss after epoch     7: 0.438\n",
            "Loss after epoch     8: 0.412\n",
            "Loss after epoch     9: 0.435\n",
            "Loss after epoch    10: 0.428\n",
            "Loss after epoch    11: 0.415\n",
            "Loss after epoch    12: 0.395\n",
            "Loss after epoch    13: 0.418\n",
            "Loss after epoch    14: 0.381\n",
            "Loss after epoch    15: 0.403\n",
            "Loss after epoch    16: 0.382\n",
            "Loss after epoch    17: 0.373\n",
            "Loss after epoch    18: 0.358\n",
            "Loss after epoch    19: 0.333\n",
            "Loss after epoch    20: 0.346\n",
            "Loss after epoch    21: 0.329\n",
            "Loss after epoch    22: 0.367\n",
            "Loss after epoch    23: 0.365\n",
            "Loss after epoch    24: 0.344\n",
            "Loss after epoch    25: 0.330\n",
            "Loss after epoch    26: 0.353\n",
            "Loss after epoch    27: 0.324\n",
            "Loss after epoch    28: 0.327\n",
            "Loss after epoch    29: 0.304\n",
            "Loss after epoch    30: 0.314\n",
            "Loss after epoch    31: 0.325\n",
            "Loss after epoch    32: 0.333\n",
            "Loss after epoch    33: 0.345\n",
            "Loss after epoch    34: 0.320\n",
            "Loss after epoch    35: 0.295\n",
            "Loss after epoch    36: 0.280\n",
            "Loss after epoch    37: 0.279\n",
            "Loss after epoch    38: 0.276\n",
            "Loss after epoch    39: 0.276\n",
            "Loss after epoch    40: 0.285\n",
            "Loss after epoch    41: 0.254\n",
            "Loss after epoch    42: 0.261\n",
            "Loss after epoch    43: 0.312\n",
            "Loss after epoch    44: 0.283\n",
            "Loss after epoch    45: 0.267\n",
            "Loss after epoch    46: 0.286\n",
            "Loss after epoch    47: 0.285\n",
            "Loss after epoch    48: 0.270\n",
            "Loss after epoch    49: 0.270\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 1 criteria6: 87 %\n",
            "------------------------------\n",
            "FOLD 3 for Criteria6\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.269\n",
            "Loss after epoch     1: 0.966\n",
            "Loss after epoch     2: 0.751\n",
            "Loss after epoch     3: 0.608\n",
            "Loss after epoch     4: 0.527\n",
            "Loss after epoch     5: 0.469\n",
            "Loss after epoch     6: 0.452\n",
            "Loss after epoch     7: 0.433\n",
            "Loss after epoch     8: 0.416\n",
            "Loss after epoch     9: 0.410\n",
            "Loss after epoch    10: 0.422\n",
            "Loss after epoch    11: 0.394\n",
            "Loss after epoch    12: 0.371\n",
            "Loss after epoch    13: 0.375\n",
            "Loss after epoch    14: 0.363\n",
            "Loss after epoch    15: 0.388\n",
            "Loss after epoch    16: 0.362\n",
            "Loss after epoch    17: 0.354\n",
            "Loss after epoch    18: 0.344\n",
            "Loss after epoch    19: 0.314\n",
            "Loss after epoch    20: 0.347\n",
            "Loss after epoch    21: 0.308\n",
            "Loss after epoch    22: 0.323\n",
            "Loss after epoch    23: 0.340\n",
            "Loss after epoch    24: 0.366\n",
            "Loss after epoch    25: 0.338\n",
            "Loss after epoch    26: 0.352\n",
            "Loss after epoch    27: 0.343\n",
            "Loss after epoch    28: 0.314\n",
            "Loss after epoch    29: 0.328\n",
            "Loss after epoch    30: 0.350\n",
            "Loss after epoch    31: 0.316\n",
            "Loss after epoch    32: 0.288\n",
            "Loss after epoch    33: 0.289\n",
            "Loss after epoch    34: 0.315\n",
            "Loss after epoch    35: 0.306\n",
            "Loss after epoch    36: 0.332\n",
            "Loss after epoch    37: 0.294\n",
            "Loss after epoch    38: 0.292\n",
            "Loss after epoch    39: 0.282\n",
            "Loss after epoch    40: 0.289\n",
            "Loss after epoch    41: 0.279\n",
            "Loss after epoch    42: 0.306\n",
            "Loss after epoch    43: 0.252\n",
            "Loss after epoch    44: 0.285\n",
            "Loss after epoch    45: 0.282\n",
            "Loss after epoch    46: 0.251\n",
            "Loss after epoch    47: 0.237\n",
            "Loss after epoch    48: 0.212\n",
            "Loss after epoch    49: 0.238\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 2 criteria6: 84 %\n",
            "------------------------------\n",
            "FOLD 4 for Criteria6\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.353\n",
            "Loss after epoch     1: 1.030\n",
            "Loss after epoch     2: 0.816\n",
            "Loss after epoch     3: 0.676\n",
            "Loss after epoch     4: 0.564\n",
            "Loss after epoch     5: 0.491\n",
            "Loss after epoch     6: 0.460\n",
            "Loss after epoch     7: 0.445\n",
            "Loss after epoch     8: 0.427\n",
            "Loss after epoch     9: 0.419\n",
            "Loss after epoch    10: 0.438\n",
            "Loss after epoch    11: 0.401\n",
            "Loss after epoch    12: 0.393\n",
            "Loss after epoch    13: 0.401\n",
            "Loss after epoch    14: 0.398\n",
            "Loss after epoch    15: 0.390\n",
            "Loss after epoch    16: 0.440\n",
            "Loss after epoch    17: 0.400\n",
            "Loss after epoch    18: 0.388\n",
            "Loss after epoch    19: 0.394\n",
            "Loss after epoch    20: 0.392\n",
            "Loss after epoch    21: 0.338\n",
            "Loss after epoch    22: 0.337\n",
            "Loss after epoch    23: 0.336\n",
            "Loss after epoch    24: 0.312\n",
            "Loss after epoch    25: 0.342\n",
            "Loss after epoch    26: 0.361\n",
            "Loss after epoch    27: 0.347\n",
            "Loss after epoch    28: 0.367\n",
            "Loss after epoch    29: 0.334\n",
            "Loss after epoch    30: 0.349\n",
            "Loss after epoch    31: 0.333\n",
            "Loss after epoch    32: 0.333\n",
            "Loss after epoch    33: 0.297\n",
            "Loss after epoch    34: 0.289\n",
            "Loss after epoch    35: 0.307\n",
            "Loss after epoch    36: 0.301\n",
            "Loss after epoch    37: 0.275\n",
            "Loss after epoch    38: 0.299\n",
            "Loss after epoch    39: 0.251\n",
            "Loss after epoch    40: 0.247\n",
            "Loss after epoch    41: 0.265\n",
            "Loss after epoch    42: 0.277\n",
            "Loss after epoch    43: 0.273\n",
            "Loss after epoch    44: 0.277\n",
            "Loss after epoch    45: 0.266\n",
            "Loss after epoch    46: 0.234\n",
            "Loss after epoch    47: 0.240\n",
            "Loss after epoch    48: 0.263\n",
            "Loss after epoch    49: 0.268\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 3 criteria6: 87 %\n",
            "------------------------------\n",
            "FOLD 5 for Criteria6\n",
            "------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=100, out_features=64, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=64, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=16, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=16, out_features=8, bias=True)\n",
            "Reset trainable parameters of layer = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=8, out_features=3, bias=True)\n",
            "Loss after epoch     0: 1.173\n",
            "Loss after epoch     1: 0.888\n",
            "Loss after epoch     2: 0.721\n",
            "Loss after epoch     3: 0.605\n",
            "Loss after epoch     4: 0.529\n",
            "Loss after epoch     5: 0.480\n",
            "Loss after epoch     6: 0.451\n",
            "Loss after epoch     7: 0.437\n",
            "Loss after epoch     8: 0.417\n",
            "Loss after epoch     9: 0.433\n",
            "Loss after epoch    10: 0.431\n",
            "Loss after epoch    11: 0.429\n",
            "Loss after epoch    12: 0.403\n",
            "Loss after epoch    13: 0.405\n",
            "Loss after epoch    14: 0.400\n",
            "Loss after epoch    15: 0.385\n",
            "Loss after epoch    16: 0.378\n",
            "Loss after epoch    17: 0.394\n",
            "Loss after epoch    18: 0.389\n",
            "Loss after epoch    19: 0.358\n",
            "Loss after epoch    20: 0.373\n",
            "Loss after epoch    21: 0.358\n",
            "Loss after epoch    22: 0.370\n",
            "Loss after epoch    23: 0.364\n",
            "Loss after epoch    24: 0.371\n",
            "Loss after epoch    25: 0.326\n",
            "Loss after epoch    26: 0.348\n",
            "Loss after epoch    27: 0.353\n",
            "Loss after epoch    28: 0.346\n",
            "Loss after epoch    29: 0.325\n",
            "Loss after epoch    30: 0.324\n",
            "Loss after epoch    31: 0.320\n",
            "Loss after epoch    32: 0.326\n",
            "Loss after epoch    33: 0.350\n",
            "Loss after epoch    34: 0.345\n",
            "Loss after epoch    35: 0.323\n",
            "Loss after epoch    36: 0.309\n",
            "Loss after epoch    37: 0.310\n",
            "Loss after epoch    38: 0.294\n",
            "Loss after epoch    39: 0.279\n",
            "Loss after epoch    40: 0.295\n",
            "Loss after epoch    41: 0.289\n",
            "Loss after epoch    42: 0.311\n",
            "Loss after epoch    43: 0.299\n",
            "Loss after epoch    44: 0.275\n",
            "Loss after epoch    45: 0.248\n",
            "Loss after epoch    46: 0.256\n",
            "Loss after epoch    47: 0.258\n",
            "Loss after epoch    48: 0.259\n",
            "Loss after epoch    49: 0.266\n",
            "Training process has finished. Saving trained model.\n",
            "Start Testing\n",
            "Accuracy for fold 4 criteria6: 87 %\n",
            "------------------------------\n",
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS for CRITERIA6\n",
            "------------------------------\n",
            "Fold 0 for Criteria6: 90.96774193548387 %\n",
            "Fold 1 for Criteria6: 87.74193548387098 %\n",
            "Fold 2 for Criteria6: 84.4155844155844 %\n",
            "Fold 3 for Criteria6: 87.66233766233766 %\n",
            "Fold 4 for Criteria6: 87.01298701298701 %\n",
            "Average : 87.56011730205279 %\n"
          ]
        }
      ]
    }
  ]
}